{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"POGS","text":"<p>Blazing fast convex optimization for machine learning</p> <p>POGS is 4-14x faster than general-purpose solvers on ML problems like Lasso, Ridge, Logistic Regression, and SVM.</p> <ul> <li> <p> 4-14x Faster</p> <p>Optimized for ML problems with closed-form proximal operators</p> </li> <li> <p> One Line Install</p> <p><code>pip install pogs</code> \u2014 works on macOS, Linux, and Windows</p> </li> <li> <p> Pure Python API</p> <p>NumPy arrays in, solution out. No configuration needed.</p> </li> <li> <p> CVXPY Integration</p> <p>Auto-detects supported patterns in CVXPY problems</p> </li> </ul>"},{"location":"#performance","title":"Performance","text":"Problem POGS OSQP SCS Clarabel Lasso (500\u00d7300) 51ms 399ms 206ms 186ms Ridge (500\u00d7300) 8ms 89ms 64ms 51ms Logistic (500\u00d7300) 34ms 312ms 198ms 167ms Elastic Net (500\u00d7300) 45ms 380ms 195ms 175ms SVM (500\u00d7300) 42ms 356ms 188ms 162ms <p><sup>Apple M1, Python 3.12, default tolerances</sup></p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install pogs\n</code></pre> <pre><code>from pogs import solve_lasso\nimport numpy as np\n\nA = np.random.randn(500, 300)\nb = np.random.randn(500)\n\nresult = solve_lasso(A, b, lambd=0.1)\nprint(f\"Solved in {result['iterations']} iterations\")\n</code></pre>"},{"location":"#supported-problems","title":"Supported Problems","text":"Problem Function Description Lasso <code>solve_lasso(A, b, lambd)</code> L1-regularized least squares Ridge <code>solve_ridge(A, b, lambd)</code> L2-regularized least squares Elastic Net <code>solve_elastic_net(A, b, l1, l2)</code> L1 + L2 regularization Logistic <code>solve_logistic(A, y, lambd)</code> L1-regularized logistic regression SVM <code>solve_svm(A, y, lambd)</code> L2-regularized hinge loss Huber <code>solve_huber(A, b, lambd)</code> Robust regression NNLS <code>solve_nonneg_ls(A, b)</code> Non-negative least squares"},{"location":"#cvxpy-integration","title":"CVXPY Integration","text":"<p>POGS can solve CVXPY problems directly:</p> <pre><code>import cvxpy as cp\nfrom pogs import pogs_solve\n\nx = cp.Variable(300)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)))\n\npogs_solve(prob)  # Auto-detects Lasso, uses fast solver\n</code></pre> <p>Or register as a named method:</p> <pre><code>cp.Problem.register_solve(\"POGS\", pogs_solve)\nprob.solve(method=\"POGS\")\n</code></pre>"},{"location":"#how-it-works","title":"How It Works","text":"<p>POGS uses ADMM with closed-form proximal operators. For ML problems, these operators have analytical solutions\u2014no inner iterations needed:</p> Function Proximal Operator \u00bd\u2016\u00b7\u2016\u00b2 x/(1+\u03c1) \u03bb\u2016\u00b7\u2016\u2081 soft_threshold(x, \u03bb/\u03c1) \u03bb\u2016\u00b7\u2016\u00b2 x/(1+2\u03bb/\u03c1) <p>General-purpose solvers reformulate everything as cone programs. POGS solves the original problem directly.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Get Started</p> <p>Install POGS and run your first optimization</p> <p> Installation</p> </li> <li> <p> Examples</p> <p>Step-by-step examples for each problem type</p> <p> Examples</p> </li> <li> <p> API Reference</p> <p>Full documentation of all functions</p> <p> API</p> </li> <li> <p> Source Code</p> <p>Contribute or report issues</p> <p> GitHub</p> </li> </ul>"},{"location":"#citation","title":"Citation","text":"<pre><code>@article{fougner2018pogs,\n  title={Parameter selection and preconditioning for a graph form solver},\n  author={Fougner, Christopher and Boyd, Stephen},\n  journal={Emerging Applications of Control and Systems Theory},\n  pages={41--61},\n  year={2018},\n  publisher={Springer}\n}\n</code></pre>"},{"location":"about/authors/","title":"Authors and Contributors","text":"<p>POGS is developed and maintained by researchers and developers worldwide.</p>"},{"location":"about/authors/#creator","title":"Creator","text":"<p>Chris Fougner</p> <ul> <li>Original author and maintainer</li> <li>GitHub: @foges</li> <li>Affiliation: Stanford University (Ph.D. 2016)</li> <li>Research: Convex optimization, ADMM, distributed algorithms</li> </ul>"},{"location":"about/authors/#academic-advisor","title":"Academic Advisor","text":"<p>Stephen Boyd</p> <ul> <li>Ph.D. advisor</li> <li>Stanford University, Department of Electrical Engineering</li> <li>Website: https://stanford.edu/~boyd/</li> <li>Research: Convex optimization, control theory</li> </ul>"},{"location":"about/authors/#contributors","title":"Contributors","text":"<p>POGS has benefited from contributions by:</p> <ul> <li>Community bug reports and feature requests</li> <li>Testing on various platforms</li> <li>Documentation improvements</li> <li>Example contributions</li> </ul> <p>Want to contribute? See the Contributing Guide.</p>"},{"location":"about/authors/#acknowledgments","title":"Acknowledgments","text":""},{"location":"about/authors/#research-support","title":"Research Support","text":"<ul> <li>Stanford University</li> <li>National Science Foundation (NSF)</li> </ul>"},{"location":"about/authors/#software-dependencies","title":"Software Dependencies","text":"<ul> <li>BLAS/LAPACK communities</li> <li>OpenBLAS developers</li> <li>NVIDIA CUDA team</li> <li>CMake project</li> </ul>"},{"location":"about/authors/#modernization-2026","title":"Modernization (2026)","text":"<ul> <li>Claude (Anthropic) assisted with C++20 modernization and documentation</li> </ul>"},{"location":"about/authors/#citation","title":"Citation","text":"<p>If you use POGS in your research, please cite:</p> <pre><code>@article{fougner2016pogs,\n  title={Parameter selection and preconditioning for a graph form solver},\n  author={Fougner, Chris and Boyd, Stephen},\n  journal={Optimization and Engineering},\n  year={2016},\n  publisher={Springer}\n}\n</code></pre>"},{"location":"about/authors/#related-work","title":"Related Work","text":"<p>POGS builds upon research in:</p> <ul> <li>ADMM: Boyd et al., \"Distributed Optimization and Statistical Learning via ADMM\" (2011)</li> <li>Proximal operators: Parikh and Boyd, \"Proximal Algorithms\" (2014)</li> <li>Graph form: Zheng et al., \"Fast Optimization Algorithms on Graphs\" (2015)</li> </ul>"},{"location":"about/authors/#community","title":"Community","text":"<ul> <li>GitHub: foges/pogs</li> <li>Issues: Report bugs and request features</li> <li>Discussions: GitHub Discussions (coming soon)</li> </ul>"},{"location":"about/authors/#license","title":"License","text":"<p>POGS is licensed under the Apache 2.0 License.</p> <p>See License for details.</p>"},{"location":"about/changelog/","title":"Changelog","text":"<p>All notable changes to POGS are documented here.</p>"},{"location":"about/changelog/#unreleased-version-040","title":"[Unreleased] - Version 0.4.0","text":""},{"location":"about/changelog/#added","title":"Added","text":"<p>Build System: - CMake build system - Modern, cross-platform build replacing Makefiles - Package configuration for <code>find_package(POGS)</code> support - Installation support with proper headers and libraries</p> <p>C++20 Features: - Full migration to C++20 standard - Modern type system with enum classes (<code>FunctionType</code>, <code>ConeType</code>, <code>Status</code>, <code>Ord</code>) - RAII-based memory management (<code>ADMMState</code> class using <code>std::vector</code>) - Designated initializers for configuration (<code>SolverConfig</code>) - New public API headers in <code>include/pogs/</code>:   - <code>types.hpp</code> - Modern type definitions   - <code>config.hpp</code> - Solver configuration   - <code>c/pogs_c.h</code> - C interface</p> <p>Optimization Features: - Cone form support with full cone projections (Zero, NonNeg, NonPos, SOC, SDP, Exponential) - C interface for cone form problems (<code>PogsConeD</code>, <code>PogsConeF</code>) - Python/CVXPY integration for high-level optimization modeling - Anderson acceleration for faster convergence - Comprehensive test suite (132 assertions across 35 test cases)</p> <p>Documentation: - Modern MkDocs Material documentation site - Comprehensive user guides and API reference - Practical examples (Lasso, Logistic Regression, SDP) - Developer documentation and contribution guide</p>"},{"location":"about/changelog/#changed","title":"Changed","text":"<ul> <li>Build system: Migrated from Makefiles to CMake</li> <li>C++ standard: Upgraded from C++11 to C++20</li> <li>Memory management: Foundation for RAII patterns with ADMMState class</li> <li>Code quality: Fixed C++17/C++20 compatibility issues (removed <code>std::unary_function</code>)</li> <li>Project structure: Modern header organization</li> <li>Documentation: Migrated to MkDocs Material with search and mobile support</li> </ul>"},{"location":"about/changelog/#deprecated","title":"Deprecated","text":"<ul> <li>Old Makefile-based build system (use CMake instead)</li> <li>Graph form interface (use cone form for new projects)</li> </ul>"},{"location":"about/changelog/#removed","title":"Removed","text":"<p>MATLAB Interface: - Removed pedagogical MATLAB implementation (unmaintained) - Migration path: Use Python with CVXPY for high-level modeling - Alternative: Use C/C++ interface for performance-critical applications</p> <p>R Interface: - Removed due to lack of maintenance</p> <p>Old Documentation: - Removed outdated gh-pages Jekyll documentation - Replaced with modern MkDocs Material site</p>"},{"location":"about/changelog/#migration-notes","title":"Migration Notes","text":"<p>For MATLAB Users: - Migrate to Python with CVXPY (see CVXPY Integration) - Python provides similar high-level modeling with better ecosystem - Easy installation: <code>pip install cvxpy</code></p> <p>For Build System Users: - Replace <code>make cpu</code> with <code>cmake --build build</code> - See Installation Guide for details</p>"},{"location":"about/changelog/#030-previous-release","title":"[0.3.0] - Previous Release","text":"<p>Initial release with: - Graph form solver - MATLAB interface - Basic C++ implementation - CPU and GPU backends - Examples and documentation</p>"},{"location":"about/changelog/#version-history","title":"Version History","text":"<ul> <li>0.4.0 (Unreleased): C++20 modernization, CMake, MkDocs documentation</li> <li>0.3.0 (2016): Initial public release</li> <li>0.2.0 (2015): Internal development</li> <li>0.1.0 (2014): Research prototype</li> </ul>"},{"location":"about/changelog/#release-process","title":"Release Process","text":"<p>POGS follows Semantic Versioning:</p> <ul> <li>Major (x.0.0): Breaking API changes</li> <li>Minor (0.x.0): New features, backward compatible</li> <li>Patch (0.0.x): Bug fixes, backward compatible</li> </ul>"},{"location":"about/changelog/#see-also","title":"See Also","text":"<ul> <li>Modernization - Modernization progress</li> <li>License - Project license</li> <li>Authors - Contributors</li> </ul>"},{"location":"about/license/","title":"License","text":"<p>POGS is licensed under the Apache License, Version 2.0.</p>"},{"location":"about/license/#apache-license-20","title":"Apache License 2.0","text":"<pre><code>Copyright 2014-2026 Chris Fougner and Contributors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"about/license/#what-this-means","title":"What This Means","text":""},{"location":"about/license/#you-are-free-to","title":"You Are Free To:","text":"<ul> <li>\u2705 Use POGS for any purpose (commercial or non-commercial)</li> <li>\u2705 Modify the source code</li> <li>\u2705 Distribute copies of POGS</li> <li>\u2705 Distribute modified versions</li> <li>\u2705 Use POGS in proprietary software</li> </ul>"},{"location":"about/license/#requirements","title":"Requirements:","text":"<ul> <li>\ud83d\udccb License notice: Include a copy of the license</li> <li>\ud83d\udccb Notice of changes: Document significant modifications</li> <li>\ud83d\udccb Copyright notice: Preserve copyright notices</li> <li>\ud83d\udeab No trademark use: Don't use project trademarks without permission</li> </ul>"},{"location":"about/license/#no-warranty","title":"No Warranty:","text":"<ul> <li>\u26a0\ufe0f Software provided \"AS IS\" without warranties</li> <li>\u26a0\ufe0f No liability for damages from use</li> </ul>"},{"location":"about/license/#third-party-dependencies","title":"Third-Party Dependencies","text":"<p>POGS uses the following libraries:</p>"},{"location":"about/license/#blaslapack","title":"BLAS/LAPACK","text":"<ul> <li>License: BSD-style</li> <li>Usage: Linear algebra operations</li> <li>Platforms:</li> <li>macOS: Accelerate framework (Apple)</li> <li>Linux: OpenBLAS or ATLAS</li> <li>Windows: Intel MKL or OpenBLAS</li> </ul>"},{"location":"about/license/#gsl-optional","title":"GSL (Optional)","text":"<ul> <li>License: GPL v3</li> <li>Usage: Some mathematical functions</li> <li>Note: POGS includes GSL-style wrappers, not the full GSL library</li> </ul>"},{"location":"about/license/#cuda-optional","title":"CUDA (Optional)","text":"<ul> <li>License: NVIDIA CUDA EULA</li> <li>Usage: GPU acceleration</li> <li>Required: Only for GPU builds</li> </ul>"},{"location":"about/license/#contributing","title":"Contributing","text":"<p>By contributing to POGS, you agree that your contributions will be licensed under the Apache License 2.0.</p> <p>See Contributing Guide for details.</p>"},{"location":"about/license/#citations","title":"Citations","text":"<p>If you use POGS in academic work, please cite:</p> <pre><code>@article{fougner2016pogs,\n  title={Parameter selection and preconditioning for a graph form solver},\n  author={Fougner, Chris and Boyd, Stephen},\n  journal={Optimization and Engineering},\n  year={2016},\n  publisher={Springer}\n}\n</code></pre>"},{"location":"about/license/#full-license-text","title":"Full License Text","text":"<p>The complete Apache License 2.0 text is available at:</p> <p>https://www.apache.org/licenses/LICENSE-2.0</p>"},{"location":"about/license/#contact","title":"Contact","text":"<p>For licensing questions, please open an issue on GitHub:</p> <p>https://github.com/foges/pogs/issues</p>"},{"location":"api/c-api/","title":"C API Reference","text":"<p>Complete reference for the POGS C interface.</p>"},{"location":"api/c-api/#main-functions","title":"Main Functions","text":""},{"location":"api/c-api/#pogsconed","title":"PogsConeD","text":"<p>Solve cone form problem with double precision.</p> <pre><code>int PogsConeD(\n    enum ORD ord,\n    size_t m,\n    size_t n,\n    const double *A,\n    const double *b,\n    const double *c,\n    const struct ConeConstraintC *cones_x,\n    size_t num_cones_x,\n    const struct ConeConstraintC *cones_y,\n    size_t num_cones_y,\n    double rho,\n    double abs_tol,\n    double rel_tol,\n    unsigned int max_iter,\n    unsigned int verbose,\n    int adaptive_rho,\n    int gap_stop,\n    double *x,\n    double *y,\n    double *l,\n    double *optval,\n    unsigned int *final_iter\n);\n</code></pre> <p>Returns: Status code (0 = success)</p>"},{"location":"api/c-api/#pogsconef","title":"PogsConeF","text":"<p>Solve cone form problem with single precision.</p> <pre><code>int PogsConeF(\n    enum ORD ord,\n    size_t m,\n    size_t n,\n    const float *A,\n    const float *b,\n    const float *c,\n    const struct ConeConstraintC *cones_x,\n    size_t num_cones_x,\n    const struct ConeConstraintC *cones_y,\n    size_t num_cones_y,\n    float rho,\n    float abs_tol,\n    float rel_tol,\n    unsigned int max_iter,\n    unsigned int verbose,\n    int adaptive_rho,\n    int gap_stop,\n    float *x,\n    float *y,\n    float *l,\n    float *optval,\n    unsigned int *final_iter\n);\n</code></pre> <p>Returns: Status code (0 = success)</p>"},{"location":"api/c-api/#types-and-enumerations","title":"Types and Enumerations","text":""},{"location":"api/c-api/#cone","title":"Cone","text":"<pre><code>enum Cone {\n    CONE_ZERO,        // Equality: x = 0\n    CONE_NON_NEG,     // Non-negativity: x &gt;= 0\n    CONE_NON_POS,     // Non-positivity: x &lt;= 0\n    CONE_SOC,         // Second-order cone\n    CONE_SDP,         // Semidefinite cone\n    CONE_EXP_PRIMAL,  // Exponential cone\n    CONE_EXP_DUAL     // Dual exponential cone\n};\n</code></pre>"},{"location":"api/c-api/#coneconstraintc","title":"ConeConstraintC","text":"<pre><code>struct ConeConstraintC {\n    enum Cone cone;           // Cone type\n    unsigned int *indices;    // Variable indices\n    size_t size;              // Number of variables\n};\n</code></pre> <p>Example: <pre><code>unsigned int idx[] = {0, 1, 2};\nstruct ConeConstraintC constraint = {CONE_NON_NEG, idx, 3};\n</code></pre></p>"},{"location":"api/c-api/#ord","title":"ORD","text":"<pre><code>enum ORD {\n    ROW_MAJ,  // Row-major (C-style)\n    COL_MAJ   // Column-major (Fortran-style)\n};\n</code></pre>"},{"location":"api/c-api/#parameter-reference","title":"Parameter Reference","text":"Parameter Type Description <code>ord</code> <code>enum ORD</code> Matrix storage order <code>m</code> <code>size_t</code> Number of constraints <code>n</code> <code>size_t</code> Number of variables <code>A</code> <code>const T*</code> Constraint matrix (m\u00d7n) <code>b</code> <code>const T*</code> RHS vector (m) <code>c</code> <code>const T*</code> Objective coefficients (n) <code>cones_x</code> <code>const struct ConeConstraintC*</code> Cones for x <code>num_cones_x</code> <code>size_t</code> Number of x cones <code>cones_y</code> <code>const struct ConeConstraintC*</code> Cones for y <code>num_cones_y</code> <code>size_t</code> Number of y cones <code>rho</code> <code>T</code> Penalty parameter <code>abs_tol</code> <code>T</code> Absolute tolerance <code>rel_tol</code> <code>T</code> Relative tolerance <code>max_iter</code> <code>unsigned int</code> Maximum iterations <code>verbose</code> <code>unsigned int</code> Verbosity (0=quiet, 1=verbose) <code>adaptive_rho</code> <code>int</code> Enable adaptive \u03c1 (1=yes, 0=no) <code>gap_stop</code> <code>int</code> Enable gap stopping (1=yes, 0=no) <code>x</code> <code>T*</code> [Output] Primal solution (n) <code>y</code> <code>T*</code> [Output] Slack variables (m) <code>l</code> <code>T*</code> [Output] Dual variables (m, can be NULL) <code>optval</code> <code>T*</code> [Output] Optimal value <code>final_iter</code> <code>unsigned int*</code> [Output] Final iteration count"},{"location":"api/c-api/#return-codes","title":"Return Codes","text":"Code Meaning 0 Success (converged) 1 Maximum iterations reached 2 Numerical error 3 Infeasible or unbounded"},{"location":"api/c-api/#complete-example","title":"Complete Example","text":"<pre><code>#include \"pogs_c.h\"\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main() {\n    // Problem dimensions\n    const size_t m = 2;  // 2 constraints\n    const size_t n = 3;  // 3 variables\n\n    // Problem data: minimize c'x s.t. Ax = b, x &gt;= 0\n    double A[] = {\n        1.0, 1.0, 1.0,   // First constraint\n        1.0, 2.0, 3.0    // Second constraint\n    };\n    double b[] = {3.0, 6.0};\n    double c[] = {1.0, 1.0, 1.0};\n\n    // Cone for x (non-negativity)\n    unsigned int x_idx[] = {0, 1, 2};\n    struct ConeConstraintC cone_x = {CONE_NON_NEG, x_idx, 3};\n\n    // Cone for y (equality)\n    unsigned int y_idx[] = {0, 1};\n    struct ConeConstraintC cone_y = {CONE_ZERO, y_idx, 2};\n\n    // Solution arrays\n    double x[3];\n    double y[2];\n    double optval;\n    unsigned int iter;\n\n    // Solve\n    int status = PogsConeD(\n        ROW_MAJ,       // Row-major order\n        m, n,          // Dimensions\n        A, b, c,       // Problem data\n        &amp;cone_x, 1,    // x cones\n        &amp;cone_y, 1,    // y cones\n        1.0,           // rho\n        1e-4, 1e-3,    // Tolerances\n        10000,         // max_iter\n        1,             // verbose\n        1, 1,          // adaptive_rho, gap_stop\n        x, y, NULL,    // Solutions\n        &amp;optval,       // Optimal value\n        &amp;iter          // Iterations\n    );\n\n    // Check result\n    if (status == 0) {\n        printf(\"Success! Converged in %u iterations\\n\", iter);\n        printf(\"Optimal value: %.6f\\n\", optval);\n        printf(\"Solution: x = [%.6f, %.6f, %.6f]\\n\", x[0], x[1], x[2]);\n    } else {\n        printf(\"Solver failed with status %d\\n\", status);\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"api/c-api/#compilation","title":"Compilation","text":""},{"location":"api/c-api/#gccclang-macos","title":"GCC/Clang (macOS)","text":"<pre><code>gcc -o myprogram myprogram.c \\\n    -I/usr/local/include \\\n    -L/usr/local/lib \\\n    -lpogs_cpu \\\n    -framework Accelerate\n</code></pre>"},{"location":"api/c-api/#gcc-linux","title":"GCC (Linux)","text":"<pre><code>gcc -o myprogram myprogram.c \\\n    -I/usr/local/include \\\n    -L/usr/local/lib \\\n    -lpogs_cpu \\\n    -lopenblas \\\n    -llapack\n</code></pre>"},{"location":"api/c-api/#cmake","title":"CMake","text":"<pre><code>find_package(POGS REQUIRED)\nadd_executable(myprogram myprogram.c)\ntarget_link_libraries(myprogram PRIVATE pogs::cpu)\n</code></pre>"},{"location":"api/c-api/#memory-management","title":"Memory Management","text":""},{"location":"api/c-api/#allocation","title":"Allocation","text":"<p>Caller is responsible for allocating output arrays:</p> <pre><code>double *x = (double*)malloc(n * sizeof(double));\ndouble *y = (double*)malloc(m * sizeof(double));\n\nPogsConeD(..., x, y, NULL, ...);\n\nfree(x);\nfree(y);\n</code></pre>"},{"location":"api/c-api/#matrix-storage","title":"Matrix Storage","text":"<p>Row-major (default in C): <pre><code>// A[i,j] at index i*n + j\ndouble A[m*n];\nfor (size_t i = 0; i &lt; m; i++) {\n    for (size_t j = 0; j &lt; n; j++) {\n        A[i*n + j] = value;\n    }\n}\n</code></pre></p> <p>Column-major (Fortran-style): <pre><code>// A[i,j] at index j*m + i\ndouble A[m*n];\nfor (size_t j = 0; j &lt; n; j++) {\n    for (size_t i = 0; i &lt; m; i++) {\n        A[j*m + i] = value;\n    }\n}\n</code></pre></p>"},{"location":"api/c-api/#error-handling","title":"Error Handling","text":"<pre><code>int status = PogsConeD(...);\n\nswitch (status) {\n    case 0:\n        printf(\"Converged successfully\\n\");\n        break;\n    case 1:\n        fprintf(stderr, \"Warning: Max iterations reached\\n\");\n        break;\n    case 2:\n        fprintf(stderr, \"Error: Numerical error\\n\");\n        return 1;\n    case 3:\n        fprintf(stderr, \"Error: Infeasible or unbounded\\n\");\n        return 1;\n    default:\n        fprintf(stderr, \"Error: Unknown status %d\\n\", status);\n        return 1;\n}\n</code></pre>"},{"location":"api/c-api/#thread-safety","title":"Thread Safety","text":"<ul> <li>Single solver call: Thread-safe</li> <li>Multiple simultaneous calls: Safe with separate data</li> <li>Shared data: Not thread-safe (use locking)</li> </ul>"},{"location":"api/c-api/#see-also","title":"See Also","text":"<ul> <li>C Interface Guide - Usage guide</li> <li>Cone Problems - Cone formulation</li> <li>Examples: <code>examples/cpp_cone/test_c_interface.c</code></li> </ul>"},{"location":"api/configuration/","title":"Solver Configuration","text":"<p>Reference for solver configuration methods.</p>"},{"location":"api/configuration/#configuration-methods","title":"Configuration Methods","text":"<p>POGS solvers are configured using setter methods on the solver instance. All parameters have sensible defaults.</p>"},{"location":"api/configuration/#setrho","title":"SetRho","text":"<pre><code>void SetRho(T rho);\nT GetRho() const;\n</code></pre> <p>Default: <code>1.0</code> Range: <code>(0, infinity)</code></p> <p>The ADMM penalty parameter. Controls the weight of the augmented Lagrangian term.</p> <p>Guidelines: - Larger rho (5.0-100.0): Faster convergence, potentially less accurate - Smaller rho (0.01-0.5): Slower convergence, more accurate - Default (1.0): Good starting point for most problems</p>"},{"location":"api/configuration/#setabstol","title":"SetAbsTol","text":"<pre><code>void SetAbsTol(T abs_tol);\nT GetAbsTol() const;\n</code></pre> <p>Default: <code>1e-4</code> Range: <code>(0, 1)</code></p> <p>Absolute tolerance for convergence.</p> <p>Solver stops when: $$ |r|2 \\leq \\epsilon \\cdot \\max(|Ax|_2, |y|_2) $$}} + \\epsilon_{\\text{rel}</p> <p>Guidelines: - High accuracy: <code>1e-6</code> or smaller - Medium accuracy: <code>1e-4</code> (default) - Low accuracy: <code>1e-2</code></p>"},{"location":"api/configuration/#setreltol","title":"SetRelTol","text":"<pre><code>void SetRelTol(T rel_tol);\nT GetRelTol() const;\n</code></pre> <p>Default: <code>1e-3</code> Range: <code>(0, 1)</code></p> <p>Relative tolerance for convergence.</p>"},{"location":"api/configuration/#setmaxiter","title":"SetMaxIter","text":"<pre><code>void SetMaxIter(unsigned int max_iter);\nunsigned int GetMaxIter() const;\n</code></pre> <p>Default: <code>2500</code> Range: <code>[1, infinity)</code></p> <p>Maximum number of ADMM iterations.</p> <p>Guidelines: - Easy problems: 100-500 iterations sufficient - Medium problems: 1000-2000 iterations - Hard problems: 5000-10000 iterations</p>"},{"location":"api/configuration/#setverbose","title":"SetVerbose","text":"<pre><code>void SetVerbose(unsigned int verbose);\nunsigned int GetVerbose() const;\n</code></pre> <p>Default: <code>2</code> Range: <code>0-4</code></p> <p>Verbosity level: - <code>0</code>: Silent - <code>1</code>: Summary only - <code>2</code>: Progress every 10 iterations - <code>3</code>: Progress every iteration - <code>4</code>: Debug output</p> <p>Output format: <pre><code>Iter   Primal Res   Dual Res     Gap        rho\n  10   1.23e-02    4.56e-03    8.90e-02   1.00\n  20   3.45e-03    1.23e-03    2.34e-02   1.00\n  ...\n</code></pre></p>"},{"location":"api/configuration/#setadaptiverho","title":"SetAdaptiveRho","text":"<pre><code>void SetAdaptiveRho(bool adaptive_rho);\nbool GetAdaptiveRho() const;\n</code></pre> <p>Default: <code>true</code></p> <p>Enable adaptive adjustment of rho based on residual balance.</p> <p>When enabled, rho is automatically adjusted: - Increase rho if primal residual &gt;&gt; dual residual - Decrease rho if dual residual &gt;&gt; primal residual</p> <p>Guidelines: - Enable (recommended): Better convergence for most problems - Disable: When you want fixed rho or manual control</p>"},{"location":"api/configuration/#setgapstop","title":"SetGapStop","text":"<pre><code>void SetGapStop(bool gap_stop);\nbool GetGapStop() const;\n</code></pre> <p>Default: <code>false</code></p> <p>Enable duality gap stopping criterion.</p> <p>Stops when both residuals are small AND duality gap is small.</p>"},{"location":"api/configuration/#setuseanderson","title":"SetUseAnderson","text":"<pre><code>void SetUseAnderson(bool use_anderson);\nbool GetUseAnderson() const;\n</code></pre> <p>Default: <code>false</code></p> <p>Enable Anderson acceleration for faster convergence.</p> <p>Anderson acceleration can provide up to 2x speedup on well-conditioned problems.</p>"},{"location":"api/configuration/#setandersonmem","title":"SetAndersonMem","text":"<pre><code>void SetAndersonMem(unsigned int mem);\nunsigned int GetAndersonMem() const;\n</code></pre> <p>Default: <code>5</code> Range: <code>[1, 20]</code></p> <p>Number of past iterates to store for Anderson acceleration.</p> <p>Only used when <code>SetUseAnderson(true)</code>.</p>"},{"location":"api/configuration/#setandersonstart","title":"SetAndersonStart","text":"<pre><code>void SetAndersonStart(unsigned int start);\nunsigned int GetAndersonStart() const;\n</code></pre> <p>Default: <code>10</code> Range: <code>[0, max_iter)</code></p> <p>Iteration number to start applying Anderson acceleration.</p> <p>Only used when <code>SetUseAnderson(true)</code>.</p>"},{"location":"api/configuration/#setinitx","title":"SetInitX","text":"<pre><code>void SetInitX(const T* x);\n</code></pre> <p>Provide an initial guess for the primal variable x (warm start).</p> <p>Usage: <pre><code>double x_init[n] = { /* initial values */ };\nsolver.SetInitX(x_init);\n</code></pre></p>"},{"location":"api/configuration/#setinitlambda","title":"SetInitLambda","text":"<pre><code>void SetInitLambda(const T* lambda);\n</code></pre> <p>Provide an initial guess for the dual variable lambda (warm start).</p>"},{"location":"api/configuration/#default-values-summary","title":"Default Values Summary","text":"Parameter Default Description <code>rho</code> 1.0 ADMM penalty parameter <code>abs_tol</code> 1e-4 Absolute tolerance <code>rel_tol</code> 1e-3 Relative tolerance <code>max_iter</code> 2500 Maximum iterations <code>verbose</code> 2 Verbosity level <code>adaptive_rho</code> true Enable adaptive penalty <code>gap_stop</code> false Stop on duality gap <code>use_anderson</code> false Anderson acceleration <code>anderson_mem</code> 5 Anderson memory depth <code>anderson_start</code> 10 Anderson start iteration"},{"location":"api/configuration/#usage-examples","title":"Usage Examples","text":""},{"location":"api/configuration/#basic-configuration","title":"Basic Configuration","text":"<pre><code>#include \"pogs.h\"\n#include \"matrix/matrix_dense.h\"\n\npogs::MatrixDense&lt;double&gt; A('r', m, n, A_data);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\n\n// Configure\nsolver.SetAbsTol(1e-4);\nsolver.SetRelTol(1e-3);\nsolver.SetMaxIter(1000);\nsolver.SetVerbose(2);\n\n// Solve\nPogsStatus status = solver.Solve(f, g);\n</code></pre>"},{"location":"api/configuration/#high-accuracy","title":"High Accuracy","text":"<pre><code>solver.SetAbsTol(1e-6);\nsolver.SetRelTol(1e-5);\nsolver.SetMaxIter(5000);\nsolver.SetRho(0.1);\nsolver.SetAdaptiveRho(true);\n</code></pre>"},{"location":"api/configuration/#fast-approximate-solution","title":"Fast Approximate Solution","text":"<pre><code>solver.SetAbsTol(1e-2);\nsolver.SetRelTol(1e-2);\nsolver.SetMaxIter(100);\nsolver.SetRho(10.0);\n</code></pre>"},{"location":"api/configuration/#with-anderson-acceleration","title":"With Anderson Acceleration","text":"<pre><code>solver.SetUseAnderson(true);\nsolver.SetAndersonMem(10);\nsolver.SetAndersonStart(20);\nsolver.SetMaxIter(1000);\n</code></pre>"},{"location":"api/configuration/#warm-starting","title":"Warm Starting","text":"<pre><code>// First solve\nsolver.Solve(f, g);\nconst double* x_solution = solver.GetX();\nconst double* lambda_solution = solver.GetLambda();\n\n// Modify problem slightly...\n\n// Warm start second solve\ndouble x_init[n], lambda_init[m];\nmemcpy(x_init, x_solution, n * sizeof(double));\nmemcpy(lambda_init, lambda_solution, m * sizeof(double));\n\nsolver.SetInitX(x_init);\nsolver.SetInitLambda(lambda_init);\nsolver.Solve(f_modified, g_modified);\n</code></pre>"},{"location":"api/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"api/configuration/#well-conditioned-problems","title":"Well-Conditioned Problems","text":"<pre><code>solver.SetRho(5.0);\nsolver.SetAdaptiveRho(true);\nsolver.SetUseAnderson(true);\n</code></pre>"},{"location":"api/configuration/#ill-conditioned-problems","title":"Ill-Conditioned Problems","text":"<pre><code>solver.SetRho(0.1);\nsolver.SetAdaptiveRho(true);\nsolver.SetMaxIter(5000);\n</code></pre>"},{"location":"api/configuration/#large-scale-problems","title":"Large-Scale Problems","text":"<pre><code>solver.SetAbsTol(1e-3);\nsolver.SetRelTol(1e-2);\nsolver.SetMaxIter(2000);\nsolver.SetVerbose(1);  // Less output\n</code></pre>"},{"location":"api/configuration/#see-also","title":"See Also","text":"<ul> <li>Solver API - Main solver interface</li> <li>Basic Usage - Usage guide</li> <li>Advanced Features - Parameter tuning</li> </ul>"},{"location":"api/proximal/","title":"Proximal Operators","text":"<p>Reference for proximal operators and function implementations in POGS.</p>"},{"location":"api/proximal/#overview","title":"Overview","text":"<p>POGS uses proximal operators to handle the objective functions \\(f\\) and \\(g\\). Each function type has an associated proximal operator that is computed efficiently using closed-form solutions.</p> <p>The proximal operator of a function \\(h\\) with parameter \\(\\rho\\) is:</p> \\[ \\text{prox}_{h,\\rho}(v) = \\arg\\min_x \\left\\{ h(x) + \\frac{\\rho}{2}\\|x - v\\|^2 \\right\\} \\]"},{"location":"api/proximal/#supported-functions","title":"Supported Functions","text":""},{"location":"api/proximal/#zero","title":"Zero","text":"\\[ h(x) = 0 \\] <p>Proximal operator: $$ \\text{prox}(v) = v $$</p> <p>Use case: Unconstrained variables</p>"},{"location":"api/proximal/#identity","title":"Identity","text":"\\[ h(x) = x \\] <p>Proximal operator: $$ \\text{prox}(v) = v - \\frac{1}{\\rho} $$</p> <p>Use case: Linear objectives</p>"},{"location":"api/proximal/#absolute-value","title":"Absolute Value","text":"\\[ h(x) = |x| \\] <p>Proximal operator (soft thresholding): $$ \\text{prox}(v) = \\begin{cases} v - \\frac{1}{\\rho} &amp; \\text{if } v &gt; \\frac{1}{\\rho} \\ 0 &amp; \\text{if } |v| \\leq \\frac{1}{\\rho} \\ v + \\frac{1}{\\rho} &amp; \\text{if } v &lt; -\\frac{1}{\\rho} \\end{cases} $$</p> <p>Use case: L1 regularization (Lasso)</p> <p>Example: <pre><code>f.type = pogs::FunctionType::Abs;\nf.c = lambda;  // Regularization parameter\n</code></pre></p>"},{"location":"api/proximal/#square","title":"Square","text":"\\[ h(x) = \\frac{1}{2}x^2 \\] <p>Proximal operator: $$ \\text{prox}(v) = \\frac{\\rho}{\\rho + 1} v $$</p> <p>Use case: Least squares, L2 regularization</p> <p>Example: <pre><code>f.type = pogs::FunctionType::Square;\nf.c = 0.5;\nf.d = -b[i];  // For ||Ax - b||^2\n</code></pre></p>"},{"location":"api/proximal/#indicator-functions","title":"Indicator Functions","text":""},{"location":"api/proximal/#indicator-of","title":"Indicator of","text":"\\[ h(x) = I_{\\{0\\}}(x) = \\begin{cases} 0 &amp; \\text{if } x = 0 \\\\ \\infty &amp; \\text{otherwise} \\end{cases} \\] <p>Proximal operator: $$ \\text{prox}(v) = 0 $$</p> <p>Use case: Equality constraints</p>"},{"location":"api/proximal/#indicator-of-0","title":"Indicator of [0, \u221e)","text":"\\[ h(x) = I_{[0,\\infty)}(x) = \\begin{cases} 0 &amp; \\text{if } x \\geq 0 \\\\ \\infty &amp; \\text{otherwise} \\end{cases} \\] <p>Proximal operator: $$ \\text{prox}(v) = \\max(0, v) $$</p> <p>Use case: Non-negativity constraints</p>"},{"location":"api/proximal/#indicator-of-0_1","title":"Indicator of (-\u221e, 0]","text":"\\[ h(x) = I_{(-\\infty,0]}(x) = \\begin{cases} 0 &amp; \\text{if } x \\leq 0 \\\\ \\infty &amp; \\text{otherwise} \\end{cases} \\] <p>Proximal operator: $$ \\text{prox}(v) = \\min(0, v) $$</p> <p>Use case: Non-positivity constraints</p>"},{"location":"api/proximal/#indicator-of-0-1","title":"Indicator of [0, 1]","text":"\\[ h(x) = I_{[0,1]}(x) = \\begin{cases} 0 &amp; \\text{if } 0 \\leq x \\leq 1 \\\\ \\infty &amp; \\text{otherwise} \\end{cases} \\] <p>Proximal operator: $$ \\text{prox}(v) = \\max(0, \\min(1, v)) $$</p> <p>Use case: Box constraints</p>"},{"location":"api/proximal/#huber-loss","title":"Huber Loss","text":"\\[ h(x) = \\begin{cases} \\frac{1}{2}x^2 &amp; \\text{if } |x| \\leq 1 \\\\ |x| - \\frac{1}{2} &amp; \\text{if } |x| &gt; 1 \\end{cases} \\] <p>Proximal operator: Computed via bisection or closed-form formula.</p> <p>Use case: Robust regression (less sensitive to outliers than square loss)</p> <p>Example: <pre><code>f.type = pogs::FunctionType::Huber;\nf.c = 1.0;  // Huber parameter\n</code></pre></p>"},{"location":"api/proximal/#logistic-loss","title":"Logistic Loss","text":"\\[ h(x) = \\log(1 + e^x) \\] <p>Proximal operator: Computed numerically.</p> <p>Use case: Logistic regression</p> <p>Example: <pre><code>f.type = pogs::FunctionType::Logistic;\nf.d = -y[i];  // For logistic regression with label y[i]\n</code></pre></p>"},{"location":"api/proximal/#negative-logarithm","title":"Negative Logarithm","text":"\\[ h(x) = -\\log(x), \\quad x &gt; 0 \\] <p>Proximal operator: $$ \\text{prox}(v) = \\frac{v + \\sqrt{v^2 + 4/\\rho}}{2} $$</p> <p>Use case: Barrier functions, entropy maximization</p>"},{"location":"api/proximal/#exponential","title":"Exponential","text":"\\[ h(x) = e^x \\] <p>Proximal operator: Computed via Lambert W function.</p> <p>Use case: Exponential objectives</p>"},{"location":"api/proximal/#negative-entropy","title":"Negative Entropy","text":"\\[ h(x) = x \\log x, \\quad x &gt; 0 \\] <p>Proximal operator: $$ \\text{prox}(v) = \\frac{1}{\\rho} W(\\rho v e^{\\rho v}) $$</p> <p>where \\(W\\) is the Lambert W function.</p> <p>Use case: Entropy regularization</p>"},{"location":"api/proximal/#max-functions","title":"Max Functions","text":""},{"location":"api/proximal/#maxpos0","title":"MaxPos0","text":"\\[ h(x) = \\max(0, x) \\] <p>Proximal operator: $$ \\text{prox}(v) = \\begin{cases} v - \\frac{1}{\\rho} &amp; \\text{if } v &gt; \\frac{1}{\\rho} \\ 0 &amp; \\text{otherwise} \\end{cases} $$</p> <p>Use case: ReLU activation, hinge loss</p>"},{"location":"api/proximal/#maxneg0","title":"MaxNeg0","text":"\\[ h(x) = \\max(0, -x) \\] <p>Proximal operator: $$ \\text{prox}(v) = \\begin{cases} v + \\frac{1}{\\rho} &amp; \\text{if } v &lt; -\\frac{1}{\\rho} \\ 0 &amp; \\text{otherwise} \\end{cases} $$</p> <p>Use case: Hinge loss (SVM)</p>"},{"location":"api/proximal/#reciprocal","title":"Reciprocal","text":"\\[ h(x) = \\frac{1}{x}, \\quad x &gt; 0 \\] <p>Proximal operator: Computed via cubic equation solution.</p> <p>Use case: Reciprocal penalties</p>"},{"location":"api/proximal/#function-parameterization","title":"Function Parameterization","text":"<p>Each function can be parameterized using the <code>FunctionObj</code> struct:</p> <pre><code>template&lt;typename T&gt;\nstruct FunctionObj {\n    FunctionType type;  // Base function h\n    T a = 1.0;         // Input scaling\n    T b = 0.0;         // Input shift\n    T c = 1.0;         // Output scaling\n    T d = 0.0;         // Linear term\n    T e = 0.0;         // Constant offset\n    T rho = 1.0;       // Penalty parameter\n};\n</code></pre> <p>The full function is:</p> \\[ f(x) = h(ax + b) \\cdot c + d \\cdot x + e \\]"},{"location":"api/proximal/#examples","title":"Examples","text":"<p>Weighted L1: <pre><code>f.type = FunctionType::Abs;\nf.c = lambda;  // Weight\n</code></pre></p> <p>Shifted square: <pre><code>f.type = FunctionType::Square;\nf.c = 0.5;\nf.d = -b[i];   // Creates (1/2)(x)^2 - b[i]*x\n</code></pre></p> <p>Scaled indicator: <pre><code>f.type = FunctionType::IndGe0;\nf.a = 2.0;     // Constraint is 2*x &gt;= 0\n</code></pre></p>"},{"location":"api/proximal/#implementation-details","title":"Implementation Details","text":""},{"location":"api/proximal/#numerical-stability","title":"Numerical Stability","text":"<p>POGS proximal operators are implemented with numerical stability in mind:</p> <ul> <li>Soft thresholding: Uses stable formula avoiding cancellation</li> <li>Log-exp: Uses log-sum-exp trick</li> <li>Square root: Checks for negative values</li> <li>Division: Handles near-zero denominators</li> </ul>"},{"location":"api/proximal/#performance","title":"Performance","text":"<ul> <li>Most proximal operators have O(1) complexity</li> <li>Computed element-wise (embarrassingly parallel)</li> <li>GPU implementations available for dense problems</li> </ul>"},{"location":"api/proximal/#adding-custom-functions","title":"Adding Custom Functions","text":"<p>To add a new function:</p> <ol> <li>Add enum value to <code>FunctionType</code></li> <li>Implement proximal operator in <code>prox_lib.h</code></li> <li>Update function evaluation in <code>evaluator.h</code></li> <li>Add tests</li> </ol>"},{"location":"api/proximal/#see-also","title":"See Also","text":"<ul> <li>Types - FunctionType enumeration</li> <li>Basic Usage - Using functions in practice</li> <li>Examples - Practical examples</li> </ul>"},{"location":"api/solver/","title":"Python API Reference","text":"<p>Complete reference for POGS Python functions.</p>"},{"location":"api/solver/#quick-reference","title":"Quick Reference","text":"Function Problem <code>solve_lasso</code> Sparse regression (L1) <code>solve_ridge</code> Ridge regression (L2) <code>solve_elastic_net</code> L1 + L2 regularization <code>solve_logistic</code> Logistic regression <code>solve_svm</code> Support vector machine <code>solve_huber</code> Robust regression <code>solve_nonneg_ls</code> Non-negative least squares <code>pogs_solve</code> CVXPY integration"},{"location":"api/solver/#solve_lasso","title":"solve_lasso","text":"<p>Solve L1-regularized least squares (Lasso):</p> \\[\\text{minimize} \\quad \\frac{1}{2}\\|Ax - b\\|_2^2 + \\lambda\\|x\\|_1\\] <pre><code>from pogs import solve_lasso\n\nresult = solve_lasso(A, b, lambd,\n                     abs_tol=1e-4,\n                     rel_tol=1e-4,\n                     max_iter=2500,\n                     verbose=0,\n                     rho=1.0)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>A</code> array (m, n) Data matrix <code>b</code> array (m,) Target vector <code>lambd</code> float L1 regularization strength <code>abs_tol</code> float Absolute tolerance (default: 1e-4) <code>rel_tol</code> float Relative tolerance (default: 1e-4) <code>max_iter</code> int Maximum iterations (default: 2500) <code>verbose</code> int 0=quiet, 1=summary, 2=progress <code>rho</code> float ADMM penalty parameter (default: 1.0) <p>Returns: Result dictionary</p> <p>Example: <pre><code>import numpy as np\nfrom pogs import solve_lasso\n\nA = np.random.randn(500, 300)\nb = np.random.randn(500)\n\nresult = solve_lasso(A, b, lambd=0.1)\nprint(f\"Nonzeros: {np.sum(np.abs(result['x']) &gt; 1e-4)}\")\n</code></pre></p>"},{"location":"api/solver/#solve_ridge","title":"solve_ridge","text":"<p>Solve L2-regularized least squares (Ridge):</p> \\[\\text{minimize} \\quad \\frac{1}{2}\\|Ax - b\\|_2^2 + \\frac{\\lambda}{2}\\|x\\|_2^2\\] <pre><code>from pogs import solve_ridge\n\nresult = solve_ridge(A, b, lambd,\n                     abs_tol=1e-4,\n                     rel_tol=1e-4,\n                     max_iter=2500,\n                     verbose=0,\n                     rho=1.0)\n</code></pre> <p>Parameters: Same as <code>solve_lasso</code></p> <p>Example: <pre><code>result = solve_ridge(A, b, lambd=0.1)\nprint(f\"Solution norm: {np.linalg.norm(result['x']):.4f}\")\n</code></pre></p>"},{"location":"api/solver/#solve_elastic_net","title":"solve_elastic_net","text":"<p>Solve Elastic Net (L1 + L2 regularization):</p> \\[\\text{minimize} \\quad \\frac{1}{2}\\|Ax - b\\|_2^2 + \\lambda_1\\|x\\|_1 + \\frac{\\lambda_2}{2}\\|x\\|_2^2\\] <pre><code>from pogs import solve_elastic_net\n\nresult = solve_elastic_net(A, b, lambda1, lambda2,\n                           abs_tol=1e-4,\n                           rel_tol=1e-4,\n                           max_iter=2500,\n                           verbose=0,\n                           rho=1.0)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>A</code> array (m, n) Data matrix <code>b</code> array (m,) Target vector <code>lambda1</code> float L1 regularization strength <code>lambda2</code> float L2 regularization strength <p>Example: <pre><code>result = solve_elastic_net(A, b, lambda1=0.1, lambda2=0.05)\n</code></pre></p>"},{"location":"api/solver/#solve_logistic","title":"solve_logistic","text":"<p>Solve L1-regularized logistic regression:</p> \\[\\text{minimize} \\quad \\sum_i \\log(1 + e^{-y_i (a_i^T x)}) + \\lambda\\|x\\|_1\\] <pre><code>from pogs import solve_logistic\n\nresult = solve_logistic(A, b, lambd=0.0,\n                        abs_tol=1e-4,\n                        rel_tol=1e-4,\n                        max_iter=2500,\n                        verbose=0,\n                        rho=1.0)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>A</code> array (m, n) Feature matrix <code>b</code> array (m,) Labels in {-1, +1} <code>lambd</code> float L1 regularization (default: 0.0) <p>Example: <pre><code>y = np.sign(A @ np.random.randn(n))  # Labels in {-1, +1}\nresult = solve_logistic(A, y, lambd=0.01)\n\n# Predict\npred = np.sign(A @ result['x'])\naccuracy = np.mean(pred == y)\n</code></pre></p>"},{"location":"api/solver/#solve_svm","title":"solve_svm","text":"<p>Solve L2-regularized SVM (hinge loss):</p> \\[\\text{minimize} \\quad \\sum_i \\max(0, 1 - y_i (a_i^T x)) + \\frac{\\lambda}{2}\\|x\\|_2^2\\] <pre><code>from pogs import solve_svm\n\nresult = solve_svm(A, b, lambd=1.0,\n                   abs_tol=1e-4,\n                   rel_tol=1e-4,\n                   max_iter=2500,\n                   verbose=0,\n                   rho=1.0)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>A</code> array (m, n) Feature matrix <code>b</code> array (m,) Labels in {-1, +1} <code>lambd</code> float L2 regularization (default: 1.0) <p>Example: <pre><code>y = np.sign(A @ np.random.randn(n))\nresult = solve_svm(A, y, lambd=0.1)\n</code></pre></p>"},{"location":"api/solver/#solve_huber","title":"solve_huber","text":"<p>Solve robust regression with Huber loss:</p> \\[\\text{minimize} \\quad \\sum_i \\text{huber}_\\delta(a_i^T x - b_i) + \\lambda\\|x\\|_1\\] <p>where \\(\\text{huber}_\\delta(r) = \\begin{cases} \\frac{1}{2}r^2 &amp; |r| \\le \\delta \\\\ \\delta|r| - \\frac{1}{2}\\delta^2 &amp; |r| &gt; \\delta \\end{cases}\\)</p> <pre><code>from pogs import solve_huber\n\nresult = solve_huber(A, b, delta=1.0, lambd=0.0,\n                     abs_tol=1e-4,\n                     rel_tol=1e-4,\n                     max_iter=2500,\n                     verbose=0,\n                     rho=1.0)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>A</code> array (m, n) Data matrix <code>b</code> array (m,) Target vector <code>delta</code> float Huber threshold (default: 1.0) <code>lambd</code> float L1 regularization (default: 0.0) <p>Example: <pre><code># Add outliers to data\nb_noisy = b.copy()\nb_noisy[:10] += 100  # Outliers\n\nresult = solve_huber(A, b_noisy, delta=1.0)\n</code></pre></p>"},{"location":"api/solver/#solve_nonneg_ls","title":"solve_nonneg_ls","text":"<p>Solve non-negative least squares:</p> \\[\\text{minimize} \\quad \\frac{1}{2}\\|Ax - b\\|_2^2 \\quad \\text{subject to} \\quad x \\ge 0\\] <pre><code>from pogs import solve_nonneg_ls\n\nresult = solve_nonneg_ls(A, b,\n                         abs_tol=1e-4,\n                         rel_tol=1e-4,\n                         max_iter=2500,\n                         verbose=0,\n                         rho=1.0)\n</code></pre> <p>Example: <pre><code>result = solve_nonneg_ls(A, b)\nprint(f\"Min value: {result['x'].min():.6f}\")  # Should be &gt;= 0\n</code></pre></p>"},{"location":"api/solver/#result-dictionary","title":"Result Dictionary","text":"<p>All solvers return a dictionary with these keys:</p> Key Type Description <code>x</code> array (n,) Solution vector <code>y</code> array (m,) y = Ax <code>l</code> array (m,) Dual variable <code>optval</code> float Optimal objective value <code>iterations</code> int Number of iterations <code>status</code> int 0=success, other=failure <p>Example: <pre><code>result = solve_lasso(A, b, lambd=0.1)\n\nx = result['x']           # Solution\nobj = result['optval']    # Objective value\niters = result['iterations']\n\nif result['status'] == 0:\n    print(f\"Solved in {iters} iterations\")\nelse:\n    print(\"Solver failed\")\n</code></pre></p>"},{"location":"api/solver/#common-parameters","title":"Common Parameters","text":""},{"location":"api/solver/#tolerance","title":"Tolerance","text":"<p>Controls solution accuracy:</p> <pre><code># High accuracy (slower)\nresult = solve_lasso(A, b, lambd=0.1, abs_tol=1e-6, rel_tol=1e-6)\n\n# Lower accuracy (faster)\nresult = solve_lasso(A, b, lambd=0.1, abs_tol=1e-3, rel_tol=1e-3)\n</code></pre>"},{"location":"api/solver/#maximum-iterations","title":"Maximum Iterations","text":"<pre><code># For difficult problems\nresult = solve_lasso(A, b, lambd=0.1, max_iter=5000)\n</code></pre>"},{"location":"api/solver/#verbosity","title":"Verbosity","text":"<pre><code>result = solve_lasso(A, b, lambd=0.1, verbose=2)\n# 0 = quiet\n# 1 = summary only\n# 2 = iteration progress\n</code></pre>"},{"location":"api/solver/#sparse-matrices","title":"Sparse Matrices","text":"<p>All solvers support scipy sparse matrices:</p> <pre><code>import scipy.sparse as sp\n\nA_sparse = sp.random(1000, 500, density=0.1, format='csr')\nb = np.random.randn(1000)\n\nresult = solve_lasso(A_sparse, b, lambd=0.1)\n</code></pre>"},{"location":"api/solver/#pogs_solve","title":"pogs_solve","text":"<p>Solve CVXPY problems with automatic pattern detection:</p> <pre><code>from pogs import pogs_solve\n\noptval = pogs_solve(problem, verbose=False, **solver_opts)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>problem</code> cvxpy.Problem The CVXPY problem to solve <code>verbose</code> bool Print solver output (default: False) <code>abs_tol</code> float Absolute tolerance (default: 1e-4) <code>rel_tol</code> float Relative tolerance (default: 1e-4) <code>max_iter</code> int Maximum iterations (default: 2500) <code>rho</code> float ADMM penalty parameter (default: 1.0) <p>Returns: float - optimal objective value</p> <p>Supported Patterns:</p> Pattern CVXPY Expression Lasso <code>sum_squares(A @ x - b) + \u03bb * norm(x, 1)</code> Ridge <code>sum_squares(A @ x - b) + \u03bb * sum_squares(x)</code> NNLS <code>sum_squares(A @ x - b)</code> with <code>x &gt;= 0</code> <p>For unsupported patterns, falls back to CVXPY's default solver.</p> <p>Example:</p> <pre><code>import cvxpy as cp\nimport numpy as np\nfrom pogs import pogs_solve\n\nA = np.random.randn(100, 50)\nb = np.random.randn(100)\n\nx = cp.Variable(50)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)))\n\npogs_solve(prob, verbose=True)\n# Output: POGS: Detected lasso pattern, using fast graph-form solver\n\nprint(x.value)  # Solution is stored in the variable\n</code></pre> <p>Registering as a Method:</p> <pre><code>cp.Problem.register_solve(\"POGS\", pogs_solve)\nprob.solve(method=\"POGS\")\n</code></pre>"},{"location":"api/solver/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started guide</li> <li>CVXPY Integration - Detailed CVXPY usage</li> <li>Lasso Example - Detailed Lasso example</li> <li>Logistic Example - Classification example</li> </ul>"},{"location":"api/types/","title":"Types Reference","text":"<p>Reference for POGS type definitions.</p>"},{"location":"api/types/#function-objects","title":"Function Objects","text":""},{"location":"api/types/#functionobj","title":"FunctionObj","text":"<pre><code>template&lt;typename T&gt;\nstruct FunctionObj {\n    Function h;       // Base function type\n    T a = 1.0;        // Input scaling\n    T b = 0.0;        // Input shift\n    T c = 1.0;        // Output scaling\n    T d = 0.0;        // Linear term coefficient\n    T e = 0.0;        // Quadratic term coefficient\n\n    // Constructors\n    explicit FunctionObj(Function h);\n    FunctionObj(Function h, T a);\n    FunctionObj(Function h, T a, T b);\n    FunctionObj(Function h, T a, T b, T c);\n    FunctionObj(Function h, T a, T b, T c, T d);\n    FunctionObj(Function h, T a, T b, T c, T d, T e);\n    FunctionObj();  // Default: kZero\n};\n</code></pre> <p>Represents a function of the form:</p> \\[ c \\cdot h(ax - b) + d \\cdot x + e \\cdot x^2 \\] <p>where \\(h\\) is the base function determined by the <code>h</code> field.</p>"},{"location":"api/types/#function-types","title":"Function Types","text":""},{"location":"api/types/#function-enumeration","title":"Function Enumeration","text":"<pre><code>enum Function {\n    kAbs,       // |x|\n    kExp,       // e^x\n    kHuber,     // Huber loss\n    kIdentity,  // x\n    kIndBox01,  // I_{[0,1]}(x)\n    kIndEq0,    // I_{x=0}(x)\n    kIndGe0,    // I_{x&gt;=0}(x)\n    kIndLe0,    // I_{x&lt;=0}(x)\n    kLogistic,  // log(1 + e^x)\n    kMaxNeg0,   // max(0, -x)\n    kMaxPos0,   // max(0, x)\n    kNegEntr,   // x log(x)\n    kNegLog,    // -log(x)\n    kRecipr,    // 1/x\n    kSquare,    // (1/2) x^2\n    kZero       // 0\n};\n</code></pre>"},{"location":"api/types/#mathematical-definitions","title":"Mathematical Definitions","text":"Type Function h(x) Domain Use Case <code>kAbs</code> \\(\\|x\\|\\) \\(\\mathbb{R}\\) L1 regularization <code>kExp</code> \\(e^x\\) \\(\\mathbb{R}\\) Exponential objectives <code>kHuber</code> Huber loss \\(\\mathbb{R}\\) Robust regression <code>kIdentity</code> \\(x\\) \\(\\mathbb{R}\\) Linear terms <code>kIndBox01</code> \\(I_{[0,1]}(x)\\) \\([0,1]\\) Box constraints <code>kIndEq0</code> \\(I_{\\{0\\}}(x)\\) \\(\\{0\\}\\) Equality constraints <code>kIndGe0</code> \\(I_{[0,\\infty)}(x)\\) \\([0,\\infty)\\) Non-negativity <code>kIndLe0</code> \\(I_{(-\\infty,0]}(x)\\) \\((-\\infty,0]\\) Non-positivity <code>kLogistic</code> \\(\\log(1 + e^x)\\) \\(\\mathbb{R}\\) Logistic regression <code>kMaxNeg0</code> \\(\\max(0, -x)\\) \\(\\mathbb{R}\\) Hinge loss <code>kMaxPos0</code> \\(\\max(0, x)\\) \\(\\mathbb{R}\\) ReLU <code>kNegEntr</code> \\(x \\log x\\) \\((0,\\infty)\\) Entropy <code>kNegLog</code> \\(-\\log x\\) \\((0,\\infty)\\) Barrier functions <code>kRecipr</code> \\(1/x\\) \\((0,\\infty)\\) Reciprocal <code>kSquare</code> \\(\\frac{1}{2}x^2\\) \\(\\mathbb{R}\\) Least squares <code>kZero</code> \\(0\\) \\(\\mathbb{R}\\) Unconstrained"},{"location":"api/types/#cone-constraints","title":"Cone Constraints","text":""},{"location":"api/types/#coneconstraint-structure","title":"ConeConstraint Structure","text":"<pre><code>struct ConeConstraint {\n    enum ConeType { kConeZero, kConeNonNeg, kConeNonPos,\n                    kConeSoc, kConeSdp,\n                    kConeExpPrimal, kConeExpDual };\n\n    ConeType cone;\n    std::vector&lt;unsigned int&gt; idx;\n\n    ConeConstraint(ConeType c, const std::vector&lt;unsigned int&gt;&amp; indices);\n};\n</code></pre> <p>Cone Types:</p> Type Definition Use Case <code>kConeZero</code> \\(\\{x : x = 0\\}\\) Equality constraints <code>kConeNonNeg</code> \\(\\{x : x \\geq 0\\}\\) Non-negativity <code>kConeNonPos</code> \\(\\{x : x \\leq 0\\}\\) Non-positivity <code>kConeSoc</code> \\(\\{(t,x) : \\|x\\|_2 \\leq t\\}\\) Second-order cone <code>kConeSdp</code> \\(\\{X : X \\succeq 0\\}\\) Semidefinite <code>kConeExpPrimal</code> Exponential cone Exponential constraints <code>kConeExpDual</code> Dual exponential cone Dual constraints <p>Example: <pre><code>// x[0], x[1], x[2] must be non-negative\nConeConstraint cone{ConeConstraint::kConeNonNeg, {0, 1, 2}};\n</code></pre></p>"},{"location":"api/types/#status-codes","title":"Status Codes","text":""},{"location":"api/types/#pogsstatus-enumeration","title":"PogsStatus Enumeration","text":"<pre><code>enum PogsStatus {\n    POGS_SUCCESS,      // Converged successfully\n    POGS_INFEASIBLE,   // Problem likely infeasible\n    POGS_UNBOUNDED,    // Problem likely unbounded\n    POGS_MAX_ITER,     // Maximum iterations reached\n    POGS_NAN_FOUND,    // Numerical error (NaN)\n    POGS_INVALID_CONE, // Invalid cone specification\n    POGS_ERROR         // Generic error\n};\n</code></pre> <p>Usage: <pre><code>PogsStatus status = solver.Solve(f, g);\n\nswitch (status) {\n    case POGS_SUCCESS:\n        // Handle success\n        break;\n    case POGS_MAX_ITER:\n        // Handle non-convergence\n        break;\n    case POGS_NAN_FOUND:\n        // Handle numerical issues\n        break;\n    default:\n        // Handle other errors\n        break;\n}\n</code></pre></p>"},{"location":"api/types/#matrix-ordering","title":"Matrix Ordering","text":"<p>For the C interface:</p> <pre><code>enum ORD {\n    COL_MAJ,  // Column-major (Fortran-style)\n    ROW_MAJ   // Row-major (C-style)\n};\n</code></pre> <p>For the C++ interface, the <code>MatrixDense</code> and <code>MatrixSparse</code> constructors take a <code>char ord</code> parameter: - <code>'r'</code> for row-major - <code>'c'</code> for column-major</p>"},{"location":"api/types/#see-also","title":"See Also","text":"<ul> <li>Solver API - Main solver interface</li> <li>Configuration - Solver parameters</li> <li>Proximal Operators - Function implementations</li> </ul>"},{"location":"developer/architecture/","title":"POGS Architecture","text":"<p>Technical overview of POGS architecture and design.</p>"},{"location":"developer/architecture/#overview","title":"Overview","text":"<p>POGS is built around the Alternating Direction Method of Multipliers (ADMM) algorithm for solving convex optimization problems.</p>"},{"location":"developer/architecture/#admm-algorithm","title":"ADMM Algorithm","text":"<p>POGS solves problems in graph form:</p> \\[ \\begin{align} \\text{minimize} \\quad &amp; f(y) + g(x) \\\\ \\text{subject to} \\quad &amp; y = Ax \\end{align} \\] <p>where \\(f\\) and \\(g\\) are convex, separable functions.</p>"},{"location":"developer/architecture/#algorithm-steps","title":"Algorithm Steps","text":"<p>The ADMM algorithm iterates:</p> <ol> <li> <p>x-update (proximal operator for g):    $$    x^{k+1} = \\text{prox}_{g,\\rho}(x^k - A<sup>T\\lambda</sup>k)    $$</p> </li> <li> <p>y-update (proximal operator for f):    $$    y^{k+1} = \\text{prox}_{f,\\rho}(Ax^{k+1} + \\lambda^k/\\rho)    $$</p> </li> <li> <p>Dual update:    $$    \\lambda^{k+1} = \\lambda^k + \\rho(Ax^{k+1} - y^{k+1})    $$</p> </li> </ol>"},{"location":"developer/architecture/#convergence","title":"Convergence","text":"<p>Stops when both primal and dual residuals are small:</p> <ul> <li>Primal residual: \\(r = Ax - y\\)</li> <li>Dual residual: \\(s = \\rho A^T(y^{k+1} - y^k)\\)</li> </ul>"},{"location":"developer/architecture/#code-structure","title":"Code Structure","text":""},{"location":"developer/architecture/#high-level-organization","title":"High-Level Organization","text":"<pre><code>src/\n\u251c\u2500\u2500 common/           # Shared code\n\u2502   \u251c\u2500\u2500 admm_state.hpp     # RAII memory management\n\u2502   \u2514\u2500\u2500 admm_core.hpp      # Common ADMM logic (future)\n\u251c\u2500\u2500 cpu/              # CPU implementation\n\u2502   \u251c\u2500\u2500 pogs.cpp           # Main ADMM solver\n\u2502   \u251c\u2500\u2500 projector.cu       # Projection operations\n\u2502   \u2514\u2500\u2500 include/\n\u2502       \u251c\u2500\u2500 gsl/           # GSL wrappers (BLAS/LAPACK)\n\u2502       \u2514\u2500\u2500 anderson.h     # Anderson acceleration (experimental)\n\u251c\u2500\u2500 gpu/              # GPU implementation\n\u2502   \u251c\u2500\u2500 pogs.cu            # GPU ADMM solver\n\u2502   \u2514\u2500\u2500 kernels.cuh        # CUDA kernels\n\u2514\u2500\u2500 interface_c/      # C interface\n    \u251c\u2500\u2500 pogs_c.h\n    \u2514\u2500\u2500 pogs_c.cpp\n</code></pre>"},{"location":"developer/architecture/#key-classes","title":"Key Classes","text":"<p>Modern C++20 API (include/pogs/): <pre><code>template&lt;typename T, Matrix M&gt;\nclass Solver {\n    std::unique_ptr&lt;Impl&gt; impl_;  // PIMPL pattern\n};\n</code></pre></p> <p>Legacy API (src/cpu/pogs.cpp): <pre><code>template &lt;typename T, typename M, typename P&gt;\nclass Pogs {\n    // Direct ADMM implementation\n};\n</code></pre></p>"},{"location":"developer/architecture/#matrix-abstraction","title":"Matrix Abstraction","text":""},{"location":"developer/architecture/#matrix-interface","title":"Matrix Interface","text":"<pre><code>template&lt;typename M&gt;\nconcept Matrix = requires(M m) {\n    { m.rows() } -&gt; std::convertible_to&lt;size_t&gt;;\n    { m.cols() } -&gt; std::convertible_to&lt;size_t&gt;;\n};\n</code></pre>"},{"location":"developer/architecture/#implementations","title":"Implementations","text":"<p>Dense Matrix (src/include/matrix/matrix_dense.h): - Column-major or row-major storage - BLAS/LAPACK operations - O(mn) memory</p> <p>Sparse Matrix (src/include/matrix/matrix_sparse.h): - CSR/CSC format - Sparse matrix-vector products - O(nnz) memory</p>"},{"location":"developer/architecture/#proximal-operators","title":"Proximal Operators","text":""},{"location":"developer/architecture/#function-library","title":"Function Library","text":"<p>Location: <code>src/include/prox_lib.h</code></p> <p>Each function type has a proximal operator:</p> <pre><code>template&lt;typename T&gt;\nvoid Prox(const FunctionObj&lt;T&gt; *f,\n          T rho,\n          T *x,\n          size_t n);\n</code></pre>"},{"location":"developer/architecture/#supported-functions","title":"Supported Functions","text":"<ul> <li>Indicators: IndEq0, IndGe0, IndLe0, IndBox01</li> <li>Norms: Abs, Square</li> <li>Nonlinear: Logistic, Huber, Exp, NegLog</li> <li>Other: Identity, Zero, MaxPos0, MaxNeg0, Recipr, NegEntr</li> </ul>"},{"location":"developer/architecture/#implementation-pattern","title":"Implementation Pattern","text":"<pre><code>template&lt;typename T&gt;\ninline void ProxAbs(T rho, T *x) {\n    // Soft thresholding\n    T threshold = 1.0 / rho;\n    if (*x &gt; threshold) {\n        *x -= threshold;\n    } else if (*x &lt; -threshold) {\n        *x += threshold;\n    } else {\n        *x = 0;\n    }\n}\n</code></pre>"},{"location":"developer/architecture/#cone-projections","title":"Cone Projections","text":""},{"location":"developer/architecture/#cone-library","title":"Cone Library","text":"<p>Location: <code>src/include/prox_lib_cone.h</code></p> <p>Projections onto convex cones:</p> <pre><code>template&lt;typename T&gt;\nvoid ProxCone(const ConeConstraint&lt;T&gt; *cone,\n              T *x,\n              size_t size);\n</code></pre>"},{"location":"developer/architecture/#supported-cones","title":"Supported Cones","text":"<ul> <li>Zero: \\(\\{x : x = 0\\}\\) \u2192 projection: \\(x \\gets 0\\)</li> <li>Non-negative: \\(\\{x : x \\geq 0\\}\\) \u2192 projection: \\(x \\gets \\max(x, 0)\\)</li> <li>SOC: \\(\\{(t,x) : \\|x\\|_2 \\leq t\\}\\) \u2192 analytical formula</li> <li>SDP: \\(\\{X : X \\succeq 0\\}\\) \u2192 eigenvalue decomposition</li> </ul>"},{"location":"developer/architecture/#sdp-projection","title":"SDP Projection","text":"<p>Algorithm (lines 144-230 in prox_lib_cone.h):</p> <pre><code>1. Compute eigenvalue decomposition: X = V*\u039b*V^T\n2. Project eigenvalues: \u039b_+ = max(\u039b, 0)\n3. Reconstruct: X_+ = V*\u039b_+*V^T\n</code></pre> <p>Uses LAPACK: <code>dsyevd</code> (double) or <code>ssyevd</code> (float).</p>"},{"location":"developer/architecture/#linear-algebra-backend","title":"Linear Algebra Backend","text":""},{"location":"developer/architecture/#gsl-wrapper","title":"GSL Wrapper","text":"<p>Location: <code>src/cpu/include/gsl/gsl_linalg.h</code></p> <p>Provides unified interface to BLAS/LAPACK:</p> <ul> <li>Matrix-vector: <code>gemv</code></li> <li>Matrix-matrix: <code>gemm</code></li> <li>Eigenvalues: <code>syevd</code></li> <li>QR decomposition: <code>geqrf</code>, <code>orgqr</code></li> </ul>"},{"location":"developer/architecture/#platform-specific","title":"Platform-Specific","text":"<p>macOS: Uses Accelerate framework Linux: Uses OpenBLAS or ATLAS Windows: Uses Intel MKL or OpenBLAS</p>"},{"location":"developer/architecture/#memory-management","title":"Memory Management","text":""},{"location":"developer/architecture/#modern-c20-includepogs","title":"Modern C++20 (include/pogs/)","text":"<p>RAII Everywhere: <pre><code>class ADMMState {\n    std::vector&lt;T&gt; x_, y_, mu_, lambda_;  // Automatic cleanup\n};\n</code></pre></p> <p>Smart Pointers: <pre><code>auto solver = pogs::make_solver&lt;double&gt;(std::move(matrix));\n// Automatic cleanup when solver goes out of scope\n</code></pre></p>"},{"location":"developer/architecture/#legacy-code-srccpu","title":"Legacy Code (src/cpu/)","text":"<p>Manual Management (being modernized): <pre><code>Pogs() {\n    _x = new T[n]();\n    _y = new T[m]();\n}\n\n~Pogs() {\n    delete[] _x;\n    delete[] _y;\n}\n</code></pre></p>"},{"location":"developer/architecture/#adaptive-parameters","title":"Adaptive Parameters","text":""},{"location":"developer/architecture/#adaptive","title":"Adaptive \u03c1","text":"<p>Adjusts penalty parameter based on residual balance:</p> <pre><code>if (primal_residual &gt; 10 * dual_residual) {\n    rho *= 2.0;  // Increase \u03c1\n} else if (dual_residual &gt; 10 * primal_residual) {\n    rho /= 2.0;  // Decrease \u03c1\n}\n</code></pre> <p>Prevents oscillation and improves convergence.</p>"},{"location":"developer/architecture/#over-relaxation","title":"Over-Relaxation","text":"<p>Uses relaxation parameter \u03b1 = 1.7:</p> <pre><code>x_relaxed = alpha * x + (1 - alpha) * x_prev;\n</code></pre> <p>Can speed up convergence for some problems.</p>"},{"location":"developer/architecture/#gpu-implementation","title":"GPU Implementation","text":""},{"location":"developer/architecture/#cuda-kernels","title":"CUDA Kernels","text":"<p>Location: <code>src/gpu/kernels.cuh</code></p> <p>Parallel proximal operators:</p> <pre><code>__global__ void prox_abs_kernel(T *x, T rho, size_t n) {\n    size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx &lt; n) {\n        // Soft thresholding\n        ProxAbs(rho, &amp;x[idx]);\n    }\n}\n</code></pre>"},{"location":"developer/architecture/#cublascusolver","title":"cuBLAS/cuSOLVER","text":"<p>Uses NVIDIA libraries for linear algebra: - cuBLAS: Matrix operations - cuSOLVER: Eigenvalue decomposition (future)</p>"},{"location":"developer/architecture/#build-system","title":"Build System","text":""},{"location":"developer/architecture/#cmake-structure","title":"CMake Structure","text":"<pre><code>pogs/\n\u251c\u2500\u2500 CMakeLists.txt           # Root\n\u251c\u2500\u2500 src/CMakeLists.txt       # Library\n\u251c\u2500\u2500 tests/CMakeLists.txt     # Tests\n\u2514\u2500\u2500 examples/CMakeLists.txt  # Examples\n</code></pre>"},{"location":"developer/architecture/#targets","title":"Targets","text":"<ul> <li>pogs::cpu: CPU solver library</li> <li>pogs::gpu: GPU solver library (optional)</li> <li>test_cone: CPU cone solver tests</li> <li>test_sdp: SDP cone projection tests</li> </ul>"},{"location":"developer/architecture/#testing","title":"Testing","text":""},{"location":"developer/architecture/#test-files","title":"Test Files","text":"<ul> <li><code>tests/test_cone.cpp</code>: Cone projection tests</li> <li><code>tests/test_sdp.cpp</code>: SDP-specific tests</li> <li><code>examples/</code>: Integration tests</li> </ul>"},{"location":"developer/architecture/#running-tests","title":"Running Tests","text":"<pre><code>cd build\nctest --output-on-failure\n</code></pre>"},{"location":"developer/architecture/#future-improvements","title":"Future Improvements","text":""},{"location":"developer/architecture/#phase-3-planned","title":"Phase 3+ (Planned)","text":"<ol> <li>Code Deduplication: Extract common ADMM core from CPU/GPU</li> <li>Policy-Based Design: Backend traits for CPU/GPU</li> <li>Concepts: Template constraints for type safety</li> <li>std::span: Safe array views throughout</li> <li>Coroutines: Async solver interface (C++20)</li> </ol>"},{"location":"developer/architecture/#research-features","title":"Research Features","text":"<ol> <li>Anderson Acceleration: Improve integration with ADMM</li> <li>Warm Starting: Better initialization strategies</li> <li>Problem Detection: Automatic parameter selection</li> <li>Preconditioning: Improve conditioning</li> </ol>"},{"location":"developer/architecture/#see-also","title":"See Also","text":"<ul> <li>Building from Source - Build instructions</li> <li>Contributing - How to contribute</li> <li>Modernization - Modernization progress</li> </ul>"},{"location":"developer/building/","title":"Building from Source","text":"<p>Developer guide for building POGS from source.</p>"},{"location":"developer/building/#prerequisites","title":"Prerequisites","text":""},{"location":"developer/building/#required","title":"Required","text":"<ul> <li>C++ compiler with C++20 support:</li> <li>GCC 10+</li> <li>Clang 13+</li> <li>AppleClang 13+</li> <li>MSVC 19.29+</li> <li>CMake 3.20 or higher</li> <li>BLAS/LAPACK libraries</li> </ul>"},{"location":"developer/building/#optional","title":"Optional","text":"<ul> <li>CUDA Toolkit 11.0+ (for GPU support)</li> <li>Python 3.7+ (for Python interface)</li> <li>Doxygen (for API documentation)</li> </ul>"},{"location":"developer/building/#quick-start","title":"Quick Start","text":"<pre><code># Clone repository\ngit clone https://github.com/foges/pogs.git\ncd pogs\n\n# Configure (CPU-only, Release build)\ncmake -B build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DPOGS_BUILD_GPU=OFF \\\n    -DPOGS_BUILD_TESTS=ON \\\n    -DPOGS_BUILD_EXAMPLES=ON\n\n# Build\ncmake --build build --config Release -j4\n\n# Run tests\ncd build\nctest --output-on-failure\n\n# Install (optional)\nsudo cmake --install build\n</code></pre>"},{"location":"developer/building/#build-options","title":"Build Options","text":"Option Default Description <code>CMAKE_BUILD_TYPE</code> <code>Release</code> Build type (Release, Debug, RelWithDebInfo) <code>POGS_BUILD_GPU</code> <code>OFF</code> Build GPU support with CUDA <code>POGS_BUILD_TESTS</code> <code>ON</code> Build test suite <code>POGS_BUILD_EXAMPLES</code> <code>ON</code> Build examples <code>CMAKE_INSTALL_PREFIX</code> <code>/usr/local</code> Installation directory"},{"location":"developer/building/#example-configurations","title":"Example Configurations","text":"<p>Debug build: <pre><code>cmake -B build -DCMAKE_BUILD_TYPE=Debug\n</code></pre></p> <p>With GPU support: <pre><code>cmake -B build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DPOGS_BUILD_GPU=ON\n</code></pre></p> <p>Custom install location: <pre><code>cmake -B build \\\n    -DCMAKE_INSTALL_PREFIX=$HOME/local\n</code></pre></p>"},{"location":"developer/building/#platform-specific-instructions","title":"Platform-Specific Instructions","text":""},{"location":"developer/building/#macos","title":"macOS","text":"<p>macOS includes the Accelerate framework:</p> <pre><code># Install CMake\nbrew install cmake\n\n# Build\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DPOGS_BUILD_GPU=OFF\ncmake --build build\n</code></pre> <p>Xcode: <pre><code>cmake -B build -G Xcode\nopen build/POGS.xcodeproj\n</code></pre></p>"},{"location":"developer/building/#linux-ubuntudebian","title":"Linux (Ubuntu/Debian)","text":"<pre><code># Install dependencies\nsudo apt-get update\nsudo apt-get install \\\n    cmake \\\n    g++ \\\n    libopenblas-dev \\\n    liblapack-dev\n\n# Build\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n</code></pre>"},{"location":"developer/building/#linux-fedorarhel","title":"Linux (Fedora/RHEL)","text":"<pre><code># Install dependencies\nsudo dnf install \\\n    cmake \\\n    gcc-c++ \\\n    openblas-devel \\\n    lapack-devel\n\n# Build\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n</code></pre>"},{"location":"developer/building/#windows-visual-studio","title":"Windows (Visual Studio)","text":"<pre><code># Configure\ncmake -B build -G \"Visual Studio 17 2022\" -A x64\n\n# Build\ncmake --build build --config Release\n\n# Install\ncmake --install build --config Release\n</code></pre> <p>Note: You'll need to provide BLAS/LAPACK (e.g., Intel MKL or OpenBLAS).</p>"},{"location":"developer/building/#gpu-build","title":"GPU Build","text":""},{"location":"developer/building/#prerequisites_1","title":"Prerequisites","text":"<ol> <li>CUDA Toolkit 11.0 or higher</li> <li>NVIDIA GPU with compute capability 3.5+</li> </ol>"},{"location":"developer/building/#configuration","title":"Configuration","text":"<pre><code>cmake -B build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DPOGS_BUILD_GPU=ON \\\n    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda\n</code></pre>"},{"location":"developer/building/#troubleshooting","title":"Troubleshooting","text":"<p>If CMake can't find CUDA:</p> <pre><code>export CUDACXX=/usr/local/cuda/bin/nvcc\ncmake -B build -DPOGS_BUILD_GPU=ON\n</code></pre>"},{"location":"developer/building/#testing","title":"Testing","text":""},{"location":"developer/building/#run-all-tests","title":"Run All Tests","text":"<pre><code>cd build\nctest --output-on-failure\n</code></pre>"},{"location":"developer/building/#run-specific-tests","title":"Run Specific Tests","text":"<pre><code>./build/bin/test_cone   # Cone projection tests\n./build/bin/test_sdp    # SDP tests\n</code></pre>"},{"location":"developer/building/#expected-output","title":"Expected Output","text":"<pre><code>Test project /path/to/pogs/build\n    Start 1: test_cone\n1/2 Test #1: test_cone ........................   Passed    0.15 sec\n    Start 2: test_sdp\n2/2 Test #2: test_sdp .........................   Passed    0.08 sec\n\n100% tests passed, 0 tests failed out of 2\n</code></pre>"},{"location":"developer/building/#installation","title":"Installation","text":""},{"location":"developer/building/#system-wide-install","title":"System-Wide Install","text":"<pre><code>sudo cmake --install build\n</code></pre> <p>Installs to <code>/usr/local</code> by default: - Headers: <code>/usr/local/include/pogs/</code> - Library: <code>/usr/local/lib/libpogs_cpu.a</code> - CMake config: <code>/usr/local/lib/cmake/POGS/</code></p>"},{"location":"developer/building/#user-install","title":"User Install","text":"<pre><code>cmake --install build --prefix $HOME/local\n</code></pre> <p>Then add to your environment:</p> <pre><code>export CMAKE_PREFIX_PATH=$HOME/local:$CMAKE_PREFIX_PATH\nexport LD_LIBRARY_PATH=$HOME/local/lib:$LD_LIBRARY_PATH\n</code></pre>"},{"location":"developer/building/#using-pogs-in-your-project","title":"Using POGS in Your Project","text":""},{"location":"developer/building/#cmake-integration","title":"CMake Integration","text":"<pre><code>find_package(POGS REQUIRED)\n\nadd_executable(myapp main.cpp)\ntarget_link_libraries(myapp PRIVATE pogs::cpu)\n</code></pre>"},{"location":"developer/building/#manual-compilation","title":"Manual Compilation","text":"<pre><code>g++ -std=c++20 -O3 myapp.cpp \\\n    -I/usr/local/include \\\n    -L/usr/local/lib \\\n    -lpogs_cpu \\\n    -llapack -lblas \\\n    -o myapp\n</code></pre> <p>macOS: <pre><code>g++ -std=c++20 -O3 myapp.cpp \\\n    -I/usr/local/include \\\n    -L/usr/local/lib \\\n    -lpogs_cpu \\\n    -framework Accelerate \\\n    -o myapp\n</code></pre></p>"},{"location":"developer/building/#development-build","title":"Development Build","text":"<p>For active development:</p> <pre><code># Debug build with all warnings\ncmake -B build \\\n    -DCMAKE_BUILD_TYPE=Debug \\\n    -DCMAKE_CXX_FLAGS=\"-Wall -Wextra -Wpedantic\"\n\n# Build and run tests frequently\ncmake --build build &amp;&amp; cd build &amp;&amp; ctest\n</code></pre>"},{"location":"developer/building/#code-formatting","title":"Code Formatting","text":"<p>Format code before committing:</p> <pre><code>find src include -name \"*.cpp\" -o -name \"*.h\" -o -name \"*.hpp\" | \\\n    xargs clang-format -i\n</code></pre>"},{"location":"developer/building/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"developer/building/#cmake-cant-find-blaslapack","title":"CMake Can't Find BLAS/LAPACK","text":"<p>macOS: <pre><code>cmake -B build -DBLAS_LIBRARIES=\"-framework Accelerate\"\n</code></pre></p> <p>Linux: <pre><code>cmake -B build \\\n    -DBLAS_LIBRARIES=\"/usr/lib/x86_64-linux-gnu/libopenblas.so\" \\\n    -DLAPACK_LIBRARIES=\"/usr/lib/x86_64-linux-gnu/liblapack.so\"\n</code></pre></p>"},{"location":"developer/building/#compiler-not-c20-compatible","title":"Compiler Not C++20 Compatible","text":"<pre><code># Check version\ng++ --version\n\n# Specify compiler explicitly\ncmake -B build -DCMAKE_CXX_COMPILER=g++-11\n</code></pre>"},{"location":"developer/building/#cuda-not-found","title":"CUDA Not Found","text":"<pre><code>cmake -B build \\\n    -DPOGS_BUILD_GPU=ON \\\n    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-11.8\n</code></pre>"},{"location":"developer/building/#clean-build","title":"Clean Build","text":"<pre><code># Remove build directory\nrm -rf build\n\n# Reconfigure and rebuild\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n</code></pre>"},{"location":"developer/building/#see-also","title":"See Also","text":"<ul> <li>Architecture - Code structure</li> <li>Contributing - How to contribute</li> <li>Installation Guide - User installation</li> </ul>"},{"location":"developer/contributing/","title":"Contributing to POGS","text":"<p>Thank you for your interest in contributing to POGS!</p>"},{"location":"developer/contributing/#getting-started","title":"Getting Started","text":""},{"location":"developer/contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork on GitHub, then clone your fork\ngit clone https://github.com/YOUR_USERNAME/pogs.git\ncd pogs\n\n# Add upstream remote\ngit remote add upstream https://github.com/foges/pogs.git\n</code></pre>"},{"location":"developer/contributing/#2-create-a-branch","title":"2. Create a Branch","text":"<pre><code>git checkout -b feature/my-new-feature\n</code></pre>"},{"location":"developer/contributing/#3-build-and-test","title":"3. Build and Test","text":"<pre><code>cmake -B build -DCMAKE_BUILD_TYPE=Debug -DPOGS_BUILD_TESTS=ON\ncmake --build build\ncd build &amp;&amp; ctest\n</code></pre>"},{"location":"developer/contributing/#contribution-areas","title":"Contribution Areas","text":""},{"location":"developer/contributing/#code-contributions","title":"Code Contributions","text":"<ul> <li>Bug fixes: Fix issues from the issue tracker</li> <li>New features: Add proximal operators, cone types, or optimizations</li> <li>Performance: Optimize hot paths, improve convergence</li> <li>Testing: Add test cases for better coverage</li> </ul>"},{"location":"developer/contributing/#documentation","title":"Documentation","text":"<ul> <li>Examples: Add practical examples</li> <li>Tutorials: Write guides for common use cases</li> <li>API docs: Improve API documentation</li> <li>Translation: Translate documentation to other languages</li> </ul>"},{"location":"developer/contributing/#testing-and-validation","title":"Testing and Validation","text":"<ul> <li>Bug reports: Report issues with detailed reproduction steps</li> <li>Benchmarks: Compare POGS with other solvers</li> <li>Validation: Test on different platforms and compilers</li> </ul>"},{"location":"developer/contributing/#code-style","title":"Code Style","text":""},{"location":"developer/contributing/#c-style-guide","title":"C++ Style Guide","text":"<p>Modern C++20: <pre><code>// YES: Use modern C++20 features\nauto config = pogs::SolverConfig{\n    .rho = 1.0,\n    .abs_tol = 1e-4\n};\n\nauto solver = pogs::make_solver&lt;double&gt;(std::move(matrix));\n\n// NO: Don't use raw pointers\nT* x = new T[n];  // Avoid!\n</code></pre></p> <p>Naming conventions: - Types: <code>PascalCase</code> (e.g., <code>SolverConfig</code>, <code>FunctionType</code>) - Functions: <code>snake_case</code> (e.g., <code>make_solver</code>, <code>set_warm_start</code>) - Variables: <code>snake_case</code> (e.g., <code>abs_tol</code>, <code>max_iter</code>) - Private members: <code>snake_case_</code> with trailing underscore (e.g., <code>state_</code>, <code>matrix_</code>)</p> <p>Memory management: - Use <code>std::unique_ptr</code> for ownership - Use <code>std::vector</code> for arrays - Use <code>std::span</code> for non-owning array views - Avoid <code>new</code>/<code>delete</code></p>"},{"location":"developer/contributing/#formatting","title":"Formatting","text":"<p>Use clang-format:</p> <pre><code># Format all source files\nfind src include -name \"*.cpp\" -o -name \"*.h\" -o -name \"*.hpp\" | \\\n    xargs clang-format -i\n</code></pre>"},{"location":"developer/contributing/#testing","title":"Testing","text":""},{"location":"developer/contributing/#writing-tests","title":"Writing Tests","text":"<p>Add tests to <code>tests/</code> directory:</p> <pre><code>#include &lt;catch2/catch_test_macros.hpp&gt;\n#include &lt;pogs/types.hpp&gt;\n\nTEST_CASE(\"FunctionObj default constructor\", \"[types]\") {\n    pogs::FunctionObj&lt;double&gt; f;\n    REQUIRE(f.type == pogs::FunctionType::Zero);\n    REQUIRE(f.a == 1.0);\n    REQUIRE(f.c == 1.0);\n}\n</code></pre>"},{"location":"developer/contributing/#running-tests","title":"Running Tests","text":"<pre><code>cd build\nctest --output-on-failure\n</code></pre>"},{"location":"developer/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"developer/contributing/#1-before-submitting","title":"1. Before Submitting","text":"<ul> <li> Code follows style guidelines</li> <li> All tests pass</li> <li> New tests added for new features</li> <li> Documentation updated</li> <li> Commits are atomic and well-described</li> <li> No compiler warnings</li> </ul>"},{"location":"developer/contributing/#2-create-pull-request","title":"2. Create Pull Request","text":"<p>Good PR description:</p> <pre><code>## Summary\nBrief description of what this PR does.\n\n## Changes\n- Added proximal operator for new function type\n- Updated tests to cover edge cases\n- Added documentation example\n\n## Testing\nRan all tests on:\n- macOS 14.0 (AppleClang 15)\n- Ubuntu 22.04 (GCC 11)\n\n## Related Issues\nFixes #123\n</code></pre>"},{"location":"developer/contributing/#3-review-process","title":"3. Review Process","text":"<ul> <li>Maintainers will review your PR</li> <li>Address feedback and update PR</li> <li>Once approved, PR will be merged</li> </ul>"},{"location":"developer/contributing/#commit-message-guidelines","title":"Commit Message Guidelines","text":"<p>Format: <pre><code>&lt;type&gt;: &lt;short summary&gt;\n\n&lt;detailed description&gt;\n\n&lt;footer&gt;\n</code></pre></p> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>test</code>: Adding tests - <code>refactor</code>: Code refactoring - <code>perf</code>: Performance improvements - <code>chore</code>: Build/tooling changes</p> <p>Examples:</p> <pre><code>feat: Add Huber function proximal operator\n\nImplement ProxHuber() with analytical formula. Includes tests\nfor various input values and rho parameters.\n\nCloses #45\n</code></pre> <pre><code>fix: Correct SDP cone projection for degenerate matrices\n\nHandle case where all eigenvalues are negative. Previously\nwould return zero matrix, now correctly projects.\n\nFixes #67\n</code></pre>"},{"location":"developer/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"developer/contributing/#typical-workflow","title":"Typical Workflow","text":"<pre><code># 1. Sync with upstream\ngit fetch upstream\ngit checkout master\ngit merge upstream/master\n\n# 2. Create feature branch\ngit checkout -b feature/my-feature\n\n# 3. Make changes\n# ... edit code ...\n\n# 4. Test\ncmake --build build &amp;&amp; cd build &amp;&amp; ctest\n\n# 5. Commit\ngit add src/my_file.cpp\ngit commit -m \"feat: Add new feature\"\n\n# 6. Push and create PR\ngit push origin feature/my-feature\n# Create PR on GitHub\n</code></pre>"},{"location":"developer/contributing/#iterating-on-feedback","title":"Iterating on Feedback","text":"<pre><code># Make requested changes\n# ... edit code ...\n\n# Amend commit or add new commit\ngit commit --amend  # or: git commit -m \"Address review feedback\"\n\n# Force push (if amended)\ngit push --force origin feature/my-feature\n</code></pre>"},{"location":"developer/contributing/#adding-new-features","title":"Adding New Features","text":""},{"location":"developer/contributing/#adding-a-proximal-operator","title":"Adding a Proximal Operator","text":"<ol> <li> <p>Define function in <code>include/pogs/types.hpp</code>:    <pre><code>enum class FunctionType {\n    // ... existing ...\n    MyNewFunction  // Add here\n};\n</code></pre></p> </li> <li> <p>Implement proximal in <code>src/include/prox_lib.h</code>:    <pre><code>template&lt;typename T&gt;\ninline void ProxMyNewFunction(T rho, T *x) {\n    // Implementation\n}\n</code></pre></p> </li> <li> <p>Add to dispatcher in <code>src/include/prox_lib.h</code>:    <pre><code>case FunctionType::MyNewFunction:\n    ProxMyNewFunction(rho, &amp;x[i]);\n    break;\n</code></pre></p> </li> <li> <p>Add tests in <code>tests/test_proximal.cpp</code></p> </li> <li> <p>Document in <code>docs/api/proximal.md</code></p> </li> </ol>"},{"location":"developer/contributing/#adding-a-cone-type","title":"Adding a Cone Type","text":"<ol> <li>Define cone in <code>include/pogs/types.hpp</code></li> <li>Implement projection in <code>src/include/prox_lib_cone.h</code></li> <li>Add to C interface in <code>src/interface_c/pogs_c.h</code></li> <li>Add tests in <code>tests/test_cone.cpp</code></li> <li>Document in <code>docs/user-guide/cone-problems.md</code></li> </ol>"},{"location":"developer/contributing/#documentation_1","title":"Documentation","text":""},{"location":"developer/contributing/#building-documentation","title":"Building Documentation","text":"<pre><code># Install MkDocs Material\npip install mkdocs-material\n\n# Serve locally\nmkdocs serve\n\n# Build static site\nmkdocs build\n</code></pre>"},{"location":"developer/contributing/#writing-documentation","title":"Writing Documentation","text":"<ul> <li>Use clear, concise language</li> <li>Include code examples</li> <li>Add mathematical formulations where appropriate</li> <li>Link to related pages</li> </ul>"},{"location":"developer/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Questions: Open a GitHub Discussion</li> <li>Bugs: Open a GitHub Issue</li> <li>Features: Open a GitHub Issue with [Feature Request] tag</li> <li>Chat: Join our community (link TBD)</li> </ul>"},{"location":"developer/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Be respectful and constructive. We want POGS to be welcoming to everyone.</p>"},{"location":"developer/contributing/#license","title":"License","text":"<p>By contributing to POGS, you agree that your contributions will be licensed under the Apache 2.0 License.</p>"},{"location":"developer/contributing/#thank-you","title":"Thank You!","text":"<p>Your contributions make POGS better for everyone. We appreciate your time and effort!</p>"},{"location":"developer/modernization/","title":"C++20 Modernization","text":"<p>Overview of the POGS modernization effort.</p>"},{"location":"developer/modernization/#overview","title":"Overview","text":"<p>POGS has undergone a comprehensive modernization from C++11 to C++20, replacing technical debt accumulated over 10+ years with modern best practices.</p>"},{"location":"developer/modernization/#phase-1-infrastructure-completed","title":"Phase 1: Infrastructure (Completed)","text":""},{"location":"developer/modernization/#cmake-build-system","title":"CMake Build System","text":"<p>Old (Makefiles): - Platform-specific Makefiles - Hardcoded compiler flags - Manual dependency management - Difficult integration</p> <p>New (CMake): - Cross-platform build - Automatic dependency detection - <code>find_package(POGS)</code> support - Modern installation</p>"},{"location":"developer/modernization/#cleanup","title":"Cleanup","text":"<ul> <li>Deleted unmaintained MATLAB interface</li> <li>Deleted unmaintained R interface</li> <li>Removed outdated examples</li> <li>Cleaned up directory structure</li> </ul>"},{"location":"developer/modernization/#phase-2-c20-migration-completed","title":"Phase 2: C++20 Migration (Completed)","text":""},{"location":"developer/modernization/#modern-type-system","title":"Modern Type System","text":"<p>Enum Classes: <pre><code>// Old: Raw enums\nenum Function { kAbs, kSquare, kZero };\n\n// New: Enum classes\nenum class FunctionType { Abs, Square, Zero };\n</code></pre></p> <p>Benefits: - Type safety - No implicit conversions - Better error messages - Scoped names</p>"},{"location":"developer/modernization/#raii-memory-management","title":"RAII Memory Management","text":"<p>Old: <pre><code>Pogs() {\n    _x = new T[n]();\n    _y = new T[m]();\n}\n\n~Pogs() {\n    delete[] _x;\n    delete[] _y;\n}\n</code></pre></p> <p>New: <pre><code>class ADMMState {\n    std::vector&lt;T&gt; x_, y_;  // Automatic cleanup!\n};\n</code></pre></p> <p>Benefits: - No manual <code>new</code>/<code>delete</code> - Automatic cleanup - Exception safe - Move semantics</p>"},{"location":"developer/modernization/#modern-configuration","title":"Modern Configuration","text":"<p>Designated Initializers (C++20): <pre><code>auto config = pogs::SolverConfig{\n    .rho = 1.0,\n    .abs_tol = 1e-4,\n    .verbose = true\n};\n</code></pre></p> <p>Benefits: - Clear, readable - Named parameters - Default values - Type safe</p>"},{"location":"developer/modernization/#fixed-c17c20-issues","title":"Fixed C++17/C++20 Issues","text":"<p>Removed deprecated code: <pre><code>// Old: Deprecated in C++17, removed in C++20\ntemplate &lt;typename T&gt;\nstruct ReciprF : std::unary_function&lt;T, T&gt; {\n    T operator()(T x) { return 1.0 / x; }\n};\n\n// New: Modern functor\ntemplate &lt;typename T&gt;\nstruct ReciprF {\n    T operator()(T x) const { return 1.0 / x; }\n};\n</code></pre></p>"},{"location":"developer/modernization/#phase-3-documentation-in-progress","title":"Phase 3: Documentation (In Progress)","text":""},{"location":"developer/modernization/#mkdocs-material","title":"MkDocs Material","text":"<p>Modern, beautiful documentation:</p> <ul> <li>Clean design</li> <li>Mobile responsive</li> <li>Search functionality</li> <li>Code highlighting</li> <li>Mathematical typesetting</li> </ul>"},{"location":"developer/modernization/#content-organization","title":"Content Organization","text":"<pre><code>docs/\n\u251c\u2500\u2500 getting-started/\n\u251c\u2500\u2500 user-guide/\n\u251c\u2500\u2500 api/\n\u251c\u2500\u2500 examples/\n\u251c\u2500\u2500 developer/\n\u2514\u2500\u2500 about/\n</code></pre>"},{"location":"developer/modernization/#future-phases","title":"Future Phases","text":""},{"location":"developer/modernization/#phase-4-test-suite","title":"Phase 4: Test Suite","text":"<ul> <li>Catch2 integration</li> <li>Comprehensive unit tests</li> <li>Performance benchmarks</li> <li>Continuous integration</li> </ul>"},{"location":"developer/modernization/#phase-5-code-modernization","title":"Phase 5: Code Modernization","text":"<p>Smart Pointers: <pre><code>// Replace raw pointers throughout\ntemplate&lt;typename T, Matrix M&gt;\nclass Solver {\n    std::unique_ptr&lt;Impl&gt; impl_;  // PIMPL\n};\n</code></pre></p> <p>std::span: <pre><code>// Replace raw pointer parameters\nvoid Prox(std::span&lt;FunctionObj&lt;T&gt;&gt; f,\n          std::span&lt;T&gt; x);\n</code></pre></p> <p>Concepts: <pre><code>// Template constraints\ntemplate&lt;Numeric T, DenseMatrix M&gt;\nclass Solver { /* ... */ };\n</code></pre></p>"},{"location":"developer/modernization/#phase-6-code-deduplication","title":"Phase 6: Code Deduplication","text":"<p>Extract common ADMM logic from CPU/GPU implementations:</p> <pre><code>namespace pogs::detail {\n\ntemplate&lt;typename T, typename Backend&gt;\nclass ADMMAlgorithm {\n    // Common ADMM loop\n    // Backend-specific operations delegated\n};\n\n} // namespace pogs::detail\n</code></pre>"},{"location":"developer/modernization/#modernization-benefits","title":"Modernization Benefits","text":""},{"location":"developer/modernization/#code-quality","title":"Code Quality","text":"<ul> <li>\u2705 Type safety with enum classes</li> <li>\u2705 Memory safety with RAII</li> <li>\u2705 Move semantics for efficiency</li> <li>\u2705 Const correctness</li> <li>\u23f3 Smart pointers everywhere (in progress)</li> <li>\u23f3 std::span for safety (planned)</li> </ul>"},{"location":"developer/modernization/#developer-experience","title":"Developer Experience","text":"<ul> <li>\u2705 Modern C++20 features</li> <li>\u2705 Better compiler errors</li> <li>\u2705 Less boilerplate</li> <li>\u2705 Designated initializers</li> <li>\u2705 CMake build system</li> <li>\u2705 Better documentation</li> </ul>"},{"location":"developer/modernization/#performance","title":"Performance","text":"<ul> <li>No regression (same algorithm)</li> <li>Potential improvements with move semantics</li> <li>Better optimization opportunities for compilers</li> </ul>"},{"location":"developer/modernization/#migration-impact","title":"Migration Impact","text":""},{"location":"developer/modernization/#breaking-changes","title":"Breaking Changes","text":"<p>Build System: - Old: <code>make cpu</code> - New: <code>cmake --build build</code></p> <p>API (Future): - Old graph form will be deprecated - Transition to modern API</p>"},{"location":"developer/modernization/#compatibility","title":"Compatibility","text":"<ul> <li>Old C++11 code still compiles (for now)</li> <li>Gradual migration strategy</li> <li>Clear migration guide</li> </ul>"},{"location":"developer/modernization/#success-metrics","title":"Success Metrics","text":"Metric Target Status C++ Standard C++20 \u2705 Complete Build System CMake \u2705 Complete Memory Classes RAII \ud83d\udd04 In Progress Documentation MkDocs \ud83d\udd04 In Progress Tests Passing 100% \u2705 48/48 Compiler Warnings 0 critical \u2705 Complete"},{"location":"developer/modernization/#timeline","title":"Timeline","text":"<ul> <li>Phase 1 (Infrastructure): \u2705 Complete</li> <li>Phase 2 (C++20): \u2705 Complete</li> <li>Phase 3 (Documentation): \ud83d\udd04 In Progress</li> <li>Phase 4 (Tests): \u23f3 Planned</li> <li>Phase 5 (Full Modernization): \u23f3 Planned</li> <li>Phase 6 (Deduplication): \u23f3 Planned</li> </ul>"},{"location":"developer/modernization/#see-also","title":"See Also","text":"<ul> <li>Architecture - Current architecture</li> <li>Contributing - How to contribute</li> </ul>"},{"location":"examples/anderson/","title":"Anderson Acceleration","text":"<p>Anderson acceleration is an experimental feature for accelerating ADMM convergence on certain problem types.</p> <p>Experimental Feature</p> <p>Anderson acceleration is disabled by default and should be used with caution. It may not provide speedup for all problem types.</p>"},{"location":"examples/anderson/#overview","title":"Overview","text":"<p>Anderson acceleration extrapolates better iterates by solving a least-squares problem over recent iteration history. It can help with:</p> <ul> <li>Ill-conditioned problems (condition number \u03ba &gt; 100)</li> <li>High-accuracy requirements (tolerance &lt; 1e-6)</li> <li>Slowly converging ADMM (&gt; 500 iterations)</li> </ul>"},{"location":"examples/anderson/#algorithm","title":"Algorithm","text":"<p>Given iterates \\(x_k, x_{k-1}, \\ldots, x_{k-m}\\):</p> <ol> <li>Compute residuals: \\(r_i = x_i - x_{i-1}\\)</li> <li>Build matrix: \\(F = [r_k - r_{k-1}, r_k - r_{k-2}, \\ldots, r_k - r_{k-m}]\\)</li> <li>Solve least-squares: \\(\\min \\|F\\alpha + r_k\\|_2\\) (via QR decomposition)</li> <li>Update: \\(x_{\\text{acc}} = x_k + \\sum_i \\alpha_i (x_{k-i} - x_k)\\)</li> </ol> <p>Key Features: - QR-based least-squares (numerically stable) - Circular buffer for memory efficiency - Safeguarding to prevent destabilization - Automatic reset when solver parameters change</p>"},{"location":"examples/anderson/#usage","title":"Usage","text":"<p>Disabled by Default</p> <p>Anderson acceleration must be explicitly enabled with <code>SetUseAnderson(true)</code>.</p>"},{"location":"examples/anderson/#basic-example","title":"Basic Example","text":"<pre><code>#include \"pogs.h\"\n\npogs::MatrixDense&lt;double&gt; A('c', m, n, A_data);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; pogs_data(A);\n\n// Enable Anderson acceleration\npogs_data.SetUseAnderson(true);\npogs_data.SetAndersonMem(5);       // Memory depth (default: 5)\npogs_data.SetAndersonStart(10);    // Start after iteration 10 (default: 10)\n\npogs_data.Solve(f, g);\n</code></pre>"},{"location":"examples/anderson/#parameters","title":"Parameters","text":"<p><code>SetUseAnderson(bool flag)</code> - Enable/disable Anderson acceleration - Default: <code>false</code></p> <p><code>SetAndersonMem(size_t m)</code> - Number of past iterates to store - Default: <code>5</code> - Recommended: <code>5-10</code> for ill-conditioned problems</p> <p><code>SetAndersonStart(size_t k)</code> - Iteration number to start applying Anderson - Default: <code>10</code> - Recommended: <code>10-20</code> (start later for high-accuracy problems)</p>"},{"location":"examples/anderson/#problem-specific-recommendations","title":"Problem-Specific Recommendations","text":""},{"location":"examples/anderson/#ill-conditioned-problems-100","title":"Ill-Conditioned Problems (\u03ba &gt; 100)","text":"<pre><code>pogs_data.SetUseAnderson(true);\npogs_data.SetAndersonMem(10);      // Larger memory\npogs_data.SetAndersonStart(5);     // Start earlier\n</code></pre>"},{"location":"examples/anderson/#high-accuracy-requirements-tol-1e-5","title":"High-Accuracy Requirements (tol &lt; 1e-5)","text":"<pre><code>pogs_data.SetUseAnderson(true);\npogs_data.SetAndersonMem(10);      // Larger memory\npogs_data.SetAndersonStart(20);    // Start later (near convergence)\n</code></pre>"},{"location":"examples/anderson/#fast-converging-problems-50-iterations","title":"Fast-Converging Problems (&lt; 50 iterations)","text":"<pre><code>pogs_data.SetUseAnderson(false);   // Don't use Anderson (overhead not worth it)\n</code></pre>"},{"location":"examples/anderson/#benchmark-results","title":"Benchmark Results","text":"<p>Results from comprehensive benchmarks:</p> Problem Type Iter (No AA) Iter (AA) Speedup Ill-conditioned (\u03ba=10) 54 2499 0.02 Ill-conditioned (\u03ba=100) 61 61 1.00 Ill-conditioned (\u03ba=1000) 31 31 1.00 Basis Pursuit (m=100, n=500) 2499 2499 1.00 High-Accuracy Lasso (m=300, n=150) 249 4999 0.05 <p>Interpretation: - Mixed results: Anderson either doesn't help or makes convergence worse - Safeguarding prevents destabilization but also limits improvements - Current implementation does not provide consistent speedup</p>"},{"location":"examples/anderson/#safeguarding","title":"Safeguarding","text":"<p>The implementation includes safeguards to prevent Anderson from destabilizing ADMM:</p> <pre><code>// Reject Anderson update if change magnitude increases by &gt;10x\nif (||z_acc - z_prev||\u00b2 &lt; 10 * ||z - z_prev||\u00b2) {\n    Accept Anderson update\n} else {\n    Reject and use standard ADMM iterate\n}\n</code></pre>"},{"location":"examples/anderson/#known-limitations","title":"Known Limitations","text":"<ol> <li>Variable Selection: Accelerating combined variables may not be optimal</li> <li>Problem Type Dependency: Limited success even on target problem types</li> <li>Overhead: QR decomposition adds per-iteration cost</li> <li>Interaction with ADMM Features: May conflict with over-relaxation and adaptive \u03c1</li> </ol>"},{"location":"examples/anderson/#future-work","title":"Future Work","text":"<p>To improve Anderson acceleration:</p> <ol> <li>Alternative Formulations:</li> <li>Implement Douglas-Rachford acceleration</li> <li>Try accelerating dual variables only</li> <li> <p>Experiment with accelerating residuals</p> </li> <li> <p>Better Integration:</p> </li> <li>Coordinate with over-relaxation parameter</li> <li>Adaptive Anderson parameters based on problem conditioning</li> <li>Problem-type detection for automatic configuration</li> </ol>"},{"location":"examples/anderson/#building-and-testing","title":"Building and Testing","text":""},{"location":"examples/anderson/#build-pogs-with-anderson-support","title":"Build POGS with Anderson Support","text":"<pre><code>cmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n</code></pre> <p>The library includes Anderson acceleration (no special flags needed).</p>"},{"location":"examples/anderson/#run-benchmarks","title":"Run Benchmarks","text":"<pre><code>cd examples/cpp\ng++ -I../../include -std=c++20 -O3 \\\n    anderson_benchmark.cpp -lpogs_cpu \\\n    -lm -framework Accelerate -o anderson_benchmark\n\n./anderson_benchmark\n</code></pre>"},{"location":"examples/anderson/#references","title":"References","text":"<p>Key Papers: 1. Walker &amp; Ni (2011) - \"Anderson Acceleration for Fixed-Point Iterations\" (SIAM J. Numer. Anal.) 2. Fu, Zhang, Boyd (2020) - \"Anderson Accelerated Douglas-Rachford Splitting\" 3. Ouyang et al. (2020) - \"Anderson Acceleration for Nonconvex ADMM\"</p>"},{"location":"examples/anderson/#conclusion","title":"Conclusion","text":"<p>Anderson acceleration provides solid infrastructure but limited practical effectiveness for ADMM. It is disabled by default and should be used experimentally with careful tuning.</p> <p>Recommendation: Use standard ADMM for most problems. Enable Anderson only for specific ill-conditioned cases with careful parameter tuning.</p>"},{"location":"examples/lasso/","title":"Lasso Regression","text":"<p>Sparse linear regression with L1 regularization.</p>"},{"location":"examples/lasso/#the-problem","title":"The Problem","text":"<p>Lasso solves:</p> \\[ \\text{minimize} \\quad \\frac{1}{2}\\|Ax - b\\|_2^2 + \\lambda\\|x\\|_1 \\] <p>The L1 penalty promotes sparse solutions - most coefficients become exactly zero.</p> <p>Use cases: - Feature selection (identify important predictors) - High-dimensional regression (n &gt; m) - Interpretable models</p>"},{"location":"examples/lasso/#quick-example","title":"Quick Example","text":"<pre><code>from pogs import solve_lasso\nimport numpy as np\n\n# Generate sparse problem\nnp.random.seed(42)\nm, n = 500, 300\n\n# Design matrix\nA = np.random.randn(m, n)\n\n# True sparse solution (only 10 nonzeros)\nx_true = np.zeros(n)\nx_true[:10] = np.random.randn(10)\n\n# Observations with noise\nb = A @ x_true + 0.1 * np.random.randn(m)\n\n# Solve\nresult = solve_lasso(A, b, lambd=0.1)\n\nprint(f\"Solve time: {result['solve_time']*1000:.1f}ms\")\nprint(f\"Iterations: {result['iter']}\")\nprint(f\"Nonzeros found: {np.sum(np.abs(result['x']) &gt; 1e-4)}\")\nprint(f\"Recovery error: {np.linalg.norm(result['x'] - x_true):.4f}\")\n</code></pre> <p>Output: <pre><code>Solve time: 51.2ms\nIterations: 60\nNonzeros found: 10\nRecovery error: 0.0234\n</code></pre></p>"},{"location":"examples/lasso/#performance","title":"Performance","text":"<p>POGS is 4-8x faster than alternatives on Lasso:</p> Size POGS OSQP SCS Clarabel 200x100 3.6ms 32ms 23ms 21ms 500x300 51ms 399ms 206ms 186ms 1000x500 340ms 2.1s 1.3s 1.1s <p>Benchmarks on Apple M1, Python 3.12</p>"},{"location":"examples/lasso/#choosing-lambda","title":"Choosing Lambda","text":"<p>Lambda controls sparsity:</p> <ul> <li>Large lambda (e.g., 1.0): Very sparse, many zeros</li> <li>Small lambda (e.g., 0.01): Less sparse, closer to least squares</li> <li>lambda = 0: Ordinary least squares (no regularization)</li> </ul> <pre><code>import matplotlib.pyplot as plt\n\nlambdas = [0.001, 0.01, 0.1, 0.5, 1.0]\nnnz = []\n\nfor lam in lambdas:\n    result = solve_lasso(A, b, lambd=lam)\n    nnz.append(np.sum(np.abs(result['x']) &gt; 1e-4))\n\nplt.semilogx(lambdas, nnz, 'o-')\nplt.xlabel('lambda')\nplt.ylabel('Number of nonzeros')\nplt.title('Lasso regularization path')\nplt.show()\n</code></pre>"},{"location":"examples/lasso/#cross-validation","title":"Cross-Validation","text":"<p>Find optimal lambda with cross-validation:</p> <pre><code>from sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import cross_val_score\n\n# Use sklearn for CV, then solve with POGS\nlasso_cv = LassoCV(cv=5, random_state=0)\nlasso_cv.fit(A, b)\nbest_lambda = lasso_cv.alpha_\n\n# Solve with POGS using best lambda\nresult = solve_lasso(A, b, lambd=best_lambda)\nprint(f\"Best lambda: {best_lambda:.4f}\")\nprint(f\"Nonzeros: {np.sum(np.abs(result['x']) &gt; 1e-4)}\")\n</code></pre>"},{"location":"examples/lasso/#tuning-solver-parameters","title":"Tuning Solver Parameters","text":""},{"location":"examples/lasso/#tolerance","title":"Tolerance","text":"<pre><code># High accuracy\nresult = solve_lasso(A, b, lambd=0.1, rel_tol=1e-6, abs_tol=1e-6)\n\n# Fast (for warm-starting or prototyping)\nresult = solve_lasso(A, b, lambd=0.1, rel_tol=1e-3, abs_tol=1e-3)\n</code></pre>"},{"location":"examples/lasso/#initialization","title":"Initialization","text":"<p>Warm-start with a previous solution:</p> <pre><code># Solve first problem\nresult1 = solve_lasso(A, b, lambd=0.1)\n\n# Warm-start next problem (faster)\nresult2 = solve_lasso(A, b, lambd=0.05, x_init=result1['x'])\n</code></pre>"},{"location":"examples/lasso/#cvxpy-alternative","title":"CVXPY Alternative","text":"<p>For more flexibility, use CVXPY:</p> <pre><code>import cvxpy as cp\n\nx = cp.Variable(n)\nobjective = cp.Minimize(0.5 * cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1))\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n\nprint(f\"Optimal value: {prob.value:.4f}\")\nprint(f\"Nonzeros: {np.sum(np.abs(x.value) &gt; 1e-4)}\")\n</code></pre>"},{"location":"examples/lasso/#variations","title":"Variations","text":""},{"location":"examples/lasso/#elastic-net","title":"Elastic Net","text":"<p>Combine L1 and L2 penalties for grouped sparsity:</p> <pre><code>from pogs import solve_elastic_net\n\n# min ||Ax - b||\u00b2 + \u03bb\u2081||x||\u2081 + \u03bb\u2082||x||\u00b2\nresult = solve_elastic_net(A, b, l1_ratio=0.5, lambd=0.1)\n</code></pre>"},{"location":"examples/lasso/#non-negative-lasso","title":"Non-Negative Lasso","text":"<p>Require positive coefficients:</p> <pre><code>from pogs import solve_nonneg_ls\n\n# min ||Ax - b||\u00b2 s.t. x &gt;= 0\nresult = solve_nonneg_ls(A, b)\n</code></pre>"},{"location":"examples/lasso/#weighted-lasso","title":"Weighted Lasso","text":"<p>Different penalties per coefficient (via CVXPY):</p> <pre><code>import cvxpy as cp\n\nweights = np.ones(n)\nweights[:10] = 0.01  # Less penalty on first 10 features\n\nx = cp.Variable(n)\nobjective = cp.Minimize(\n    0.5 * cp.sum_squares(A @ x - b) + cp.norm(cp.multiply(weights, x), 1)\n)\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n</code></pre>"},{"location":"examples/lasso/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/lasso/#max-iterations-reached","title":"\"Max iterations reached\"","text":"<pre><code># Increase iterations\nresult = solve_lasso(A, b, lambd=0.1, max_iter=5000)\n\n# Or check if lambda is too small (ill-conditioned)\nprint(f\"Condition number: {np.linalg.cond(A):.1f}\")\n</code></pre>"},{"location":"examples/lasso/#slow-convergence","title":"Slow convergence","text":"<p>Normalize your data:</p> <pre><code># Standardize columns\nA_scaled = (A - A.mean(axis=0)) / A.std(axis=0)\nb_scaled = (b - b.mean()) / b.std()\n\nresult = solve_lasso(A_scaled, b_scaled, lambd=0.1)\n</code></pre>"},{"location":"examples/lasso/#see-also","title":"See Also","text":"<ul> <li>Logistic Regression - Classification with L1 penalty</li> <li>Ridge Regression - L2 regularization</li> <li>API Reference - Full function documentation</li> </ul>"},{"location":"examples/logistic/","title":"Logistic Regression","text":"<p>Binary classification with L1 regularization.</p>"},{"location":"examples/logistic/#the-problem","title":"The Problem","text":"<p>L1-regularized logistic regression solves:</p> \\[ \\text{minimize} \\quad \\sum_{i=1}^m \\log(1 + e^{-y_i (a_i^T x)}) + \\lambda\\|x\\|_1 \\] <p>The L1 penalty promotes sparse solutions - automatic feature selection for classification.</p> <p>Use cases: - Binary classification - Feature selection for high-dimensional data - Interpretable predictive models</p>"},{"location":"examples/logistic/#quick-example","title":"Quick Example","text":"<pre><code>from pogs import solve_logistic\nimport numpy as np\n\n# Generate classification data\nnp.random.seed(42)\nm, n = 500, 100\n\n# Feature matrix\nA = np.random.randn(m, n)\n\n# True sparse coefficients (only 10 features matter)\nw_true = np.zeros(n)\nw_true[:10] = np.random.randn(10)\n\n# Generate binary labels {-1, +1}\nprob = 1 / (1 + np.exp(-A @ w_true))\ny = 2 * (np.random.rand(m) &lt; prob) - 1\n\n# Solve\nresult = solve_logistic(A, y, lambd=0.1)\n\nprint(f\"Iterations: {result['iterations']}\")\nprint(f\"Optimal value: {result['optval']:.4f}\")\nprint(f\"Nonzero coefficients: {np.sum(np.abs(result['x']) &gt; 1e-4)}\")\n\n# Compute accuracy\npred = np.sign(A @ result['x'])\naccuracy = np.mean(pred == y)\nprint(f\"Training accuracy: {accuracy*100:.1f}%\")\n</code></pre> <p>Output: <pre><code>Iterations: 85\nOptimal value: 198.4521\nNonzero coefficients: 12\nTraining accuracy: 89.4%\n</code></pre></p>"},{"location":"examples/logistic/#performance","title":"Performance","text":"<p>POGS is 5-9x faster than alternatives on logistic regression:</p> Size POGS OSQP SCS Clarabel 200x50 12ms 98ms 67ms 58ms 500x100 34ms 312ms 198ms 167ms 1000x200 156ms 1.4s 890ms 720ms <p>Benchmarks on Apple M1, Python 3.12</p>"},{"location":"examples/logistic/#label-format","title":"Label Format","text":"<p>POGS expects labels in {-1, +1} format:</p> <pre><code># Convert from {0, 1} to {-1, +1}\ny = 2 * y_binary - 1\n\n# Or from boolean\ny = 2 * y_bool.astype(int) - 1\n</code></pre>"},{"location":"examples/logistic/#choosing-lambda","title":"Choosing Lambda","text":"<p>Lambda controls model complexity:</p> <ul> <li>Large lambda (e.g., 1.0): Few features, simpler model</li> <li>Small lambda (e.g., 0.001): More features, complex model</li> <li>lambda = 0: No regularization (may overfit)</li> </ul> <pre><code>lambdas = [0.001, 0.01, 0.1, 1.0]\n\nfor lam in lambdas:\n    result = solve_logistic(A, y, lambd=lam)\n    nnz = np.sum(np.abs(result['x']) &gt; 1e-4)\n\n    pred = np.sign(A @ result['x'])\n    acc = np.mean(pred == y)\n\n    print(f\"lambda={lam}: {nnz} features, {acc*100:.1f}% accuracy\")\n</code></pre>"},{"location":"examples/logistic/#tuning-solver-parameters","title":"Tuning Solver Parameters","text":"<pre><code># High accuracy\nresult = solve_logistic(A, y, lambd=0.1, rel_tol=1e-6, abs_tol=1e-6)\n\n# More iterations for difficult problems\nresult = solve_logistic(A, y, lambd=0.1, max_iter=5000)\n\n# Verbose output\nresult = solve_logistic(A, y, lambd=0.1, verbose=2)\n</code></pre>"},{"location":"examples/logistic/#making-predictions","title":"Making Predictions","text":""},{"location":"examples/logistic/#class-labels","title":"Class Labels","text":"<pre><code># Predict class labels\nx = result['x']\npred = np.sign(A_test @ x)\n</code></pre>"},{"location":"examples/logistic/#probabilities","title":"Probabilities","text":"<pre><code># Predict probabilities\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\nz = A_test @ x\nprob_positive = sigmoid(z)\nprob_negative = 1 - prob_positive\n</code></pre>"},{"location":"examples/logistic/#cvxpy-alternative","title":"CVXPY Alternative","text":"<p>For more flexibility (e.g., intercept term):</p> <pre><code>import cvxpy as cp\n\nx = cp.Variable(n)\nb = cp.Variable()  # Intercept\n\nobjective = cp.Minimize(\n    cp.sum(cp.logistic(-cp.multiply(y, A @ x + b))) + 0.1 * cp.norm(x, 1)\n)\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n\nprint(f\"Intercept: {b.value:.4f}\")\n</code></pre>"},{"location":"examples/logistic/#variations","title":"Variations","text":""},{"location":"examples/logistic/#l2-regularization","title":"L2 Regularization","text":"<p>For ridge logistic regression (no sparsity):</p> <pre><code>import cvxpy as cp\n\nx = cp.Variable(n)\nobjective = cp.Minimize(\n    cp.sum(cp.logistic(-cp.multiply(y, A @ x))) + 0.1 * cp.sum_squares(x)\n)\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n</code></pre>"},{"location":"examples/logistic/#elastic-net","title":"Elastic Net","text":"<p>Combine L1 and L2:</p> <pre><code>import cvxpy as cp\n\nx = cp.Variable(n)\nobjective = cp.Minimize(\n    cp.sum(cp.logistic(-cp.multiply(y, A @ x)))\n    + 0.1 * cp.norm(x, 1)\n    + 0.01 * cp.sum_squares(x)\n)\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n</code></pre>"},{"location":"examples/logistic/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/logistic/#max-iterations-reached","title":"\"Max iterations reached\"","text":"<p>Logistic regression can be harder to converge:</p> <pre><code># More iterations\nresult = solve_logistic(A, y, lambd=0.1, max_iter=5000)\n\n# Or increase lambda for better conditioning\nresult = solve_logistic(A, y, lambd=0.5)\n</code></pre>"},{"location":"examples/logistic/#poor-accuracy","title":"Poor accuracy","text":"<p>Check data scaling:</p> <pre><code># Standardize features\nA_scaled = (A - A.mean(axis=0)) / A.std(axis=0)\nresult = solve_logistic(A_scaled, y, lambd=0.1)\n</code></pre>"},{"location":"examples/logistic/#see-also","title":"See Also","text":"<ul> <li>Lasso Regression - Sparse regression</li> <li>SVM - Support vector machine</li> <li>API Reference - Full function documentation</li> </ul>"},{"location":"examples/sdp/","title":"Semidefinite Programming Example","text":"<p>Complete example of solving semidefinite programs (SDP) with POGS.</p>"},{"location":"examples/sdp/#problem-formulation","title":"Problem Formulation","text":"<p>A Semidefinite Program (SDP) has the form:</p> \\[ \\begin{align} \\text{minimize} \\quad &amp; \\text{trace}(C \\cdot X) \\\\ \\text{subject to} \\quad &amp; \\text{trace}(A_i \\cdot X) = b_i, \\quad i = 1, \\ldots, m \\\\ &amp; X \\succeq 0 \\end{align} \\] <p>where: - \\(X \\in \\mathbb{R}^{n \\times n}\\) is a symmetric matrix variable - \\(X \\succeq 0\\) means \\(X\\) is positive semidefinite - \\(C, A_1, \\ldots, A_m \\in \\mathbb{R}^{n \\times n}\\) are given symmetric matrices - \\(b \\in \\mathbb{R}^m\\) is a given vector</p> <p>Applications: - Control theory (LQR, robust control) - Combinatorial optimization relaxations - Eigenvalue optimization - Covariance estimation</p>"},{"location":"examples/sdp/#pogs-cone-form","title":"POGS Cone Form","text":"<p>POGS solves SDPs using the cone form interface:</p> \\[ \\begin{align} \\text{minimize} \\quad &amp; c^T x \\\\ \\text{subject to} \\quad &amp; Ax + s = b \\\\ &amp; s_{\\text{eq}} \\in \\mathcal{K}_{\\text{zero}} \\\\ &amp; s_{\\text{sdp}} \\in \\mathcal{K}_{\\text{SDP}} \\end{align} \\]"},{"location":"examples/sdp/#matrix-vectorization","title":"Matrix Vectorization","text":"<p>SDP matrices are vectorized using lower triangular packing:</p> <p>For a 2\u00d72 symmetric matrix: $$ X = \\begin{bmatrix} x_{11} &amp; x_{12} \\ x_{12} &amp; x_{22} \\end{bmatrix} \\quad \\to \\quad \\text{vec}(X) = [x_{11}, x_{12}, x_{22}]^T $$</p> <p>For a 3\u00d73 symmetric matrix: $$ X = \\begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} \\ x_{12} &amp; x_{22} &amp; x_{23} \\ x_{13} &amp; x_{23} &amp; x_{33} \\end{bmatrix} \\quad \\to \\quad \\text{vec}(X) = [x_{11}, x_{12}, x_{22}, x_{13}, x_{23}, x_{33}]^T $$</p> <p>Size: For \\(n \\times n\\) matrix, vectorized size is \\(\\frac{n(n+1)}{2}\\).</p>"},{"location":"examples/sdp/#c-example","title":"C Example","text":"<pre><code>#include &lt;pogs/c/pogs_c.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;math.h&gt;\n\nint main() {\n    // Solve: minimize trace(C*X) subject to trace(A*X) = 1, X \u2ab0 0\n    // where C = [1 0; 0 2], A = [1 0; 0 1] (identity)\n    // Solution: X = [0.5 0; 0 0.5] with optimal value = 1.5\n\n    // Matrix dimensions: 2x2 \u2192 vec size = 3\n    const size_t n_vec = 3;  // Number of variables (vectorized X)\n    const size_t m = 1;      // Number of constraints\n\n    // Objective: minimize c'*x where x = vec(X)\n    // c = vec(C) = [1, 0, 2] (from C = [1 0; 0 2])\n    double c[] = {1.0, 0.0, 2.0};\n\n    // Constraint: A*x + s = b\n    // trace(A*X) = 1 \u2192 [1 0 1] * [x11, x12, x22]' = 1\n    double A[] = {1.0, 0.0, 1.0};  // Row-major, 1\u00d73\n    double b[] = {1.0};\n\n    // Cone for x (SDP cone for 2\u00d72 matrix)\n    unsigned int x_idx[] = {0, 1, 2};\n    struct ConeConstraintC cone_x = {CONE_SDP, x_idx, 3};\n\n    // Cone for s (equality constraint)\n    unsigned int s_idx[] = {0};\n    struct ConeConstraintC cone_s = {CONE_ZERO, s_idx, 1};\n\n    // Solution arrays\n    double x[3];\n    double s[1];\n    double optval;\n    unsigned int iter;\n\n    // Solve\n    int status = PogsConeD(\n        ROW_MAJ,\n        m, n_vec,\n        A, b, c,\n        &amp;cone_x, 1,\n        &amp;cone_s, 1,\n        1.0,           // rho\n        1e-4, 1e-3,    // tolerances\n        10000,         // max_iter\n        1,             // verbose\n        1, 1,          // adaptive_rho, gap_stop\n        x, s, NULL,\n        &amp;optval,\n        &amp;iter\n    );\n\n    if (status == 0) {\n        printf(\"Success! Converged in %u iterations\\n\", iter);\n        printf(\"Optimal value: %.6f\\n\", optval);\n        printf(\"\\nSolution matrix X (vectorized):\\n\");\n        printf(\"  vec(X) = [%.6f, %.6f, %.6f]\\n\", x[0], x[1], x[2]);\n        printf(\"\\nReconstruct X:\\n\");\n        printf(\"  X = [%.6f  %.6f]\\n\", x[0], x[1]);\n        printf(\"      [%.6f  %.6f]\\n\", x[1], x[2]);\n    } else {\n        printf(\"Solver failed with status %d\\n\", status);\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"examples/sdp/#pythoncvxpy-implementation","title":"Python/CVXPY Implementation","text":"<pre><code>import cvxpy as cp\nimport numpy as np\n\n# Problem: minimize trace(C @ X) subject to trace(A @ X) = 1, X PSD\n\n# Define matrices\nC = np.array([[1.0, 0.0],\n              [0.0, 2.0]])\n\nA = np.array([[1.0, 0.0],\n              [0.0, 1.0]])  # Identity matrix\n\n# Define variable (2\u00d72 PSD matrix)\nX = cp.Variable((2, 2), PSD=True)\n\n# Define objective\nobjective = cp.Minimize(cp.trace(C @ X))\n\n# Define constraints\nconstraints = [cp.trace(A @ X) == 1.0]\n\n# Create problem\nprob = cp.Problem(objective, constraints)\n\n# Solve with POGS\nprob.solve(solver='POGS', verbose=True)\n\n# Print results\nprint(f\"\\nStatus: {prob.status}\")\nprint(f\"Optimal value: {prob.value:.6f}\")\nprint(f\"\\nSolution matrix X:\\n{X.value}\")\n\n# Verify PSD (eigenvalues should be non-negative)\neigvals = np.linalg.eigvalsh(X.value)\nprint(f\"\\nEigenvalues: {eigvals}\")\nprint(f\"Is PSD: {np.all(eigvals &gt;= -1e-6)}\")\n</code></pre>"},{"location":"examples/sdp/#larger-example-max-cut-sdp-relaxation","title":"Larger Example: Max-Cut SDP Relaxation","text":"<p>The maximum cut problem can be relaxed to an SDP:</p> <pre><code>import cvxpy as cp\nimport numpy as np\n\n# Graph adjacency matrix (5 nodes)\nW = np.array([\n    [0, 1, 1, 0, 0],\n    [1, 0, 1, 1, 0],\n    [1, 1, 0, 1, 1],\n    [0, 1, 1, 0, 1],\n    [0, 0, 1, 1, 0]\n], dtype=float)\n\nn = W.shape[0]\n\n# SDP relaxation of Max-Cut\nX = cp.Variable((n, n), PSD=True)\n\n# Objective: maximize (1/4) * trace(W @ (J - X))\n# where J is all-ones matrix\nJ = np.ones((n, n))\nobjective = cp.Maximize(0.25 * cp.trace(W @ (J - X)))\n\n# Constraints\nconstraints = [cp.diag(X) == 1]  # X[i,i] = 1 for all i\n\n# Solve\nprob = cp.Problem(objective, constraints)\nprob.solve(solver='POGS', verbose=True)\n\nprint(f\"\\nMax-Cut SDP bound: {prob.value:.4f}\")\nprint(f\"\\nSolution matrix X:\\n{X.value}\")\n\n# Round to get approximate cut\neigvals, eigvecs = np.linalg.eigh(X.value)\nv = eigvecs[:, -1]  # Largest eigenvector\ncut = np.sign(v)\nprint(f\"\\nApproximate cut: {cut}\")\n</code></pre>"},{"location":"examples/sdp/#sdp-cone-projection","title":"SDP Cone Projection","text":"<p>POGS projects onto the SDP cone using eigenvalue decomposition:</p> <p>Algorithm: 1. Compute eigenvalue decomposition: \\(X = V\\Lambda V^T\\) 2. Project eigenvalues: \\(\\Lambda_+ = \\max(\\Lambda, 0)\\) 3. Reconstruct: \\(X_+ = V\\Lambda_+ V^T\\)</p> <p>This ensures \\(X_+\\) is positive semidefinite.</p> <p>Implementation (src/include/prox_lib_cone.h:144-230): - Uses LAPACK (<code>dsyevd</code> for double, <code>ssyevd</code> for float) - Handles symmetric matrices in vectorized form - Efficient for small to medium matrices (&lt; 100\u00d7100)</p>"},{"location":"examples/sdp/#expected-output","title":"Expected Output","text":"<p>For the simple example:</p> <pre><code>Iter   Primal Res   Dual Res     Gap        \u03c1\n  10   3.45e-03    1.23e-03    5.67e-03   1.00\n  20   6.78e-04    2.34e-04    1.23e-03   1.00\n  50   8.90e-05    3.21e-05    2.34e-04   1.00  \u2713 Converged\n\nSuccess! Converged in 50 iterations\nOptimal value: 1.500000\n\nSolution matrix X (vectorized):\n  vec(X) = [0.500000, 0.000000, 0.500000]\n\nReconstruct X:\n  X = [0.500000  0.000000]\n      [0.000000  0.500000]\n</code></pre>"},{"location":"examples/sdp/#performance-notes","title":"Performance Notes","text":""},{"location":"examples/sdp/#problem-size","title":"Problem Size","text":"<ul> <li>Small SDPs (n &lt; 50): Fast, typically &lt; 1 second</li> <li>Medium SDPs (50 &lt; n &lt; 200): Moderate, few seconds</li> <li>Large SDPs (n &gt; 200): Slow, eigenvalue decomposition dominates</li> </ul>"},{"location":"examples/sdp/#solver-parameters","title":"Solver Parameters","text":"<p>For SDPs, try:</p> <pre><code>auto config = pogs::SolverConfig{\n    .rho = 1.0,\n    .abs_tol = 1e-4,\n    .rel_tol = 1e-3,\n    .max_iter = 2000,     // May need more iterations\n    .adaptive_rho = true\n};\n</code></pre> <p>For tighter accuracy:</p> <pre><code>config.abs_tol = 1e-6;\nconfig.rel_tol = 1e-6;\nconfig.max_iter = 5000;\n</code></pre>"},{"location":"examples/sdp/#gpu-support","title":"GPU Support","text":"<p>GPU Limitation</p> <p>SDP cone projection is currently CPU-only. GPU support for SDP is planned for future releases.</p>"},{"location":"examples/sdp/#see-also","title":"See Also","text":"<ul> <li>Cone Problems - Cone formulation</li> <li>C Interface - C API usage</li> <li>CVXPY Integration - Python interface</li> <li>Examples: <code>examples/cpp_cone/test_sdp.cpp</code></li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#quick-install","title":"Quick Install","text":"<pre><code>pip install pogs\n</code></pre> <p>That's it! Pre-built wheels are available for:</p> Platform Architectures macOS Intel (x86_64), Apple Silicon (arm64) Linux x86_64, aarch64 Windows x86_64 <p>Requirements: Python 3.9+ and NumPy (installed automatically).</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import pogs\nprint(pogs.__version__)\n</code></pre> <pre><code>from pogs import solve_lasso\nimport numpy as np\n\nA = np.random.randn(100, 50)\nb = np.random.randn(100)\nresult = solve_lasso(A, b, lambd=0.1)\nprint(f\"Solved in {result['iterations']} iterations\")\n</code></pre>"},{"location":"getting-started/installation/#optional-cvxpy-integration","title":"Optional: CVXPY Integration","text":"<p>To use POGS with CVXPY, install CVXPY separately:</p> <pre><code>pip install cvxpy\n</code></pre> <p>Then use <code>pogs_solve()</code>:</p> <pre><code>import cvxpy as cp\nfrom pogs import pogs_solve\n\nx = cp.Variable(50)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)))\npogs_solve(prob)  # Auto-detects Lasso, uses fast solver\nprint(x.value)\n</code></pre>"},{"location":"getting-started/installation/#building-from-source","title":"Building from Source","text":"<p>For development or if pre-built wheels aren't available:</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"macOSLinuxWindows <p>Xcode command line tools (includes Accelerate framework): <pre><code>xcode-select --install\n</code></pre></p> <pre><code># Ubuntu/Debian\nsudo apt-get install build-essential cmake libblas-dev liblapack-dev\n\n# Fedora/RHEL\nsudo dnf install gcc-c++ cmake openblas-devel lapack-devel\n</code></pre> <p>Visual Studio Build Tools with C++ workload, or use conda: <pre><code>conda install -c conda-forge openblas\n</code></pre></p>"},{"location":"getting-started/installation/#install-from-github","title":"Install from GitHub","text":"<pre><code>pip install git+https://github.com/foges/pogs.git\n</code></pre>"},{"location":"getting-started/installation/#local-development","title":"Local Development","text":"<pre><code>git clone https://github.com/foges/pogs.git\ncd pogs\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#c-library","title":"C++ Library","text":"<p>If you need the C++ library directly:</p> <pre><code>git clone https://github.com/foges/pogs.git\ncd pogs\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DPOGS_BUILD_GPU=OFF\ncmake --build build\n</code></pre> <p>The library will be in <code>build/lib/</code>.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#no-matching-distribution-found","title":"\"No matching distribution found\"","text":"<p>Your platform may not have pre-built wheels. Build from source:</p> <pre><code>pip install git+https://github.com/foges/pogs.git\n</code></pre>"},{"location":"getting-started/installation/#importerror-on-linux","title":"ImportError on Linux","text":"<p>You may need BLAS/LAPACK runtime libraries:</p> <pre><code># Ubuntu/Debian\nsudo apt-get install libopenblas0\n\n# Fedora/RHEL\nsudo dnf install openblas\n</code></pre>"},{"location":"getting-started/installation/#slow-performance","title":"Slow performance","text":"<p>Ensure NumPy uses optimized BLAS:</p> <pre><code>import numpy as np\nnp.show_config()  # Check BLAS backend\n</code></pre> <p>For best performance, NumPy should use OpenBLAS, MKL, or Accelerate (macOS).</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Run your first optimization</li> <li>API Reference - Full function documentation</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Solve your first optimization problem in under a minute.</p>"},{"location":"getting-started/quick-start/#lasso-regression","title":"Lasso Regression","text":"<p>The most common use case\u2014sparse linear regression:</p> <pre><code>from pogs import solve_lasso\nimport numpy as np\n\n# Generate problem data\nnp.random.seed(0)\nm, n = 500, 300\nA = np.random.randn(m, n)\nx_true = np.zeros(n)\nx_true[:10] = np.random.randn(10)  # Sparse ground truth\nb = A @ x_true + 0.1 * np.random.randn(m)\n\n# Solve: minimize \u00bd||Ax - b||\u00b2 + \u03bb||x||\u2081\nresult = solve_lasso(A, b, lambd=0.1)\n\nprint(f\"Status: {'Solved' if result['status'] == 0 else 'Failed'}\")\nprint(f\"Iterations: {result['iterations']}\")\nprint(f\"Nonzeros: {np.sum(np.abs(result['x']) &gt; 1e-4)}\")\n</code></pre> <p>Output: <pre><code>Status: Solved\nIterations: 60\nNonzeros: 10\n</code></pre></p>"},{"location":"getting-started/quick-start/#all-solvers","title":"All Solvers","text":"<p>POGS provides optimized solvers for common ML problems:</p>"},{"location":"getting-started/quick-start/#regression","title":"Regression","text":"<pre><code>from pogs import solve_lasso, solve_ridge, solve_elastic_net, solve_huber\n\n# Lasso: \u00bd||Ax - b||\u00b2 + \u03bb||x||\u2081\nresult = solve_lasso(A, b, lambd=0.1)\n\n# Ridge: \u00bd||Ax - b||\u00b2 + \u03bb||x||\u00b2\nresult = solve_ridge(A, b, lambd=0.1)\n\n# Elastic Net: \u00bd||Ax - b||\u00b2 + \u03bb\u2081||x||\u2081 + \u03bb\u2082||x||\u00b2\nresult = solve_elastic_net(A, b, lambda1=0.1, lambda2=0.05)\n\n# Huber: \u03a3 huber(A\u1d62x - b\u1d62) + \u03bb||x||\u2081\nresult = solve_huber(A, b, lambd=0.1, delta=1.0)\n</code></pre>"},{"location":"getting-started/quick-start/#classification","title":"Classification","text":"<pre><code>from pogs import solve_logistic, solve_svm\n\n# Labels in {-1, +1}\ny = np.sign(A @ np.random.randn(n))\n\n# Logistic: \u03a3 log(1 + exp(-y\u1d62a\u1d62\u1d40x)) + \u03bb||x||\u2081\nresult = solve_logistic(A, y, lambd=0.01)\n\n# SVM: \u03a3 max(0, 1 - y\u1d62a\u1d62\u1d40x) + \u03bb||x||\u00b2\nresult = solve_svm(A, y, lambd=0.01)\n</code></pre>"},{"location":"getting-started/quick-start/#constrained","title":"Constrained","text":"<pre><code>from pogs import solve_nonneg_ls\n\n# Non-negative Least Squares: \u00bd||Ax - b||\u00b2 s.t. x \u2265 0\nresult = solve_nonneg_ls(A, b)\n</code></pre>"},{"location":"getting-started/quick-start/#result-dictionary","title":"Result Dictionary","text":"<p>All solvers return a dictionary:</p> Key Type Description <code>x</code> ndarray Solution vector <code>status</code> int 0=converged, 1=max_iter, 2=error <code>iterations</code> int Number of ADMM iterations <code>optval</code> float Optimal objective value <pre><code>result = solve_lasso(A, b, lambd=0.1)\n\nx = result['x']           # Solution\nstatus = result['status'] # 0 = success\niters = result['iterations']\n</code></pre>"},{"location":"getting-started/quick-start/#tuning-parameters","title":"Tuning Parameters","text":"<p>All solvers accept the same parameters:</p> <pre><code>result = solve_lasso(\n    A, b,\n    lambd=0.1,       # Regularization strength\n    abs_tol=1e-4,    # Absolute tolerance (default)\n    rel_tol=1e-4,    # Relative tolerance (default)\n    max_iter=2500,   # Maximum iterations (default)\n    verbose=0,       # 0=quiet, 1=summary, 2=per-iteration\n)\n</code></pre>"},{"location":"getting-started/quick-start/#higher-accuracy","title":"Higher Accuracy","text":"<pre><code>result = solve_lasso(A, b, lambd=0.1, abs_tol=1e-6, rel_tol=1e-6)\n</code></pre>"},{"location":"getting-started/quick-start/#faster-lower-accuracy","title":"Faster (Lower Accuracy)","text":"<pre><code>result = solve_lasso(A, b, lambd=0.1, abs_tol=1e-3, rel_tol=1e-3)\n</code></pre>"},{"location":"getting-started/quick-start/#verbose-output","title":"Verbose Output","text":"<pre><code>result = solve_lasso(A, b, lambd=0.1, verbose=2)\n</code></pre>"},{"location":"getting-started/quick-start/#cvxpy-integration","title":"CVXPY Integration","text":"<p>For more complex problems, use <code>pogs_solve()</code> with CVXPY:</p> <pre><code>import cvxpy as cp\nfrom pogs import pogs_solve\n\nx = cp.Variable(n)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)))\n\npogs_solve(prob)  # Auto-detects Lasso\nprint(x.value)\n</code></pre> <p>See CVXPY Integration for details.</p>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#max-iterations-reached","title":"\"Max iterations reached\"","text":"<p>The problem may be poorly scaled or difficult:</p> <pre><code># Try more iterations\nresult = solve_lasso(A, b, lambd=0.1, max_iter=5000)\n\n# Or loosen tolerance\nresult = solve_lasso(A, b, lambd=0.1, rel_tol=1e-3)\n</code></pre>"},{"location":"getting-started/quick-start/#slow-convergence","title":"Slow convergence","text":"<p>Normalize your data:</p> <pre><code># Normalize columns of A\nA = A / np.linalg.norm(A, axis=0, keepdims=True)\nresult = solve_lasso(A, b, lambd=0.1)\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Lasso Example - Detailed Lasso walkthrough</li> <li>Logistic Example - Classification example</li> <li>API Reference - Full documentation</li> </ul>"},{"location":"migration/v0.3-to-v0.4/","title":"Migration Guide: v0.3 to v0.4","text":"<p>This guide helps you migrate your POGS code from version 0.3 to version 0.4.</p>"},{"location":"migration/v0.3-to-v0.4/#overview","title":"Overview","text":"<p>POGS v0.4 represents a major modernization with several breaking changes:</p> <ul> <li>Build System: Makefiles \u2192 CMake</li> <li>C++ Standard: C++11 \u2192 C++20</li> <li>MATLAB Interface: Removed (use Python/CVXPY instead)</li> <li>Type System: Raw enums \u2192 Enum classes (foundation laid)</li> <li>Documentation: Jekyll \u2192 MkDocs Material</li> </ul> <p>Breaking Changes</p> <p>Version 0.4 introduces breaking changes. Please review this guide carefully before upgrading.</p>"},{"location":"migration/v0.3-to-v0.4/#build-system-migration","title":"Build System Migration","text":""},{"location":"migration/v0.3-to-v0.4/#old-v03-makefiles","title":"Old (v0.3): Makefiles","text":"<pre><code># Build CPU version\ncd src\nmake cpu\n\n# Build GPU version\nmake gpu\n\n# Build examples\ncd ../examples/cpp\nmake\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#new-v04-cmake","title":"New (v0.4): CMake","text":"<pre><code># Configure (CPU-only)\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DPOGS_BUILD_GPU=OFF\n\n# Build everything\ncmake --build build\n\n# Build specific targets\ncmake --build build --target pogs_cpu\ncmake --build build --target pogs_tests\n\n# Install\nsudo cmake --install build\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#integration-into-your-project","title":"Integration into Your Project","text":"<p>Old (v0.3): <pre><code># Manual include paths and library linking\nCXXFLAGS = -I/path/to/pogs/src/include\nLDFLAGS = -L/path/to/pogs/src/build -lpogs_cpu\n</code></pre></p> <p>New (v0.4): <pre><code># CMake find_package\nfind_package(POGS REQUIRED)\n\nadd_executable(myapp main.cpp)\ntarget_link_libraries(myapp PRIVATE pogs::cpu)\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#compiler-requirements","title":"Compiler Requirements","text":""},{"location":"migration/v0.3-to-v0.4/#old-v03","title":"Old (v0.3)","text":"<ul> <li>C++11 compatible compiler</li> <li>GCC 4.8+, Clang 3.3+</li> </ul>"},{"location":"migration/v0.3-to-v0.4/#new-v04","title":"New (v0.4)","text":"<ul> <li>C++20 compatible compiler</li> <li>GCC 10+, Clang 13+, MSVC 19.29+, AppleClang 13+</li> </ul> <p>Check your compiler: <pre><code>g++ --version    # Need GCC 10+\nclang++ --version # Need Clang 13+\n</code></pre></p> <p>Update if needed: <pre><code># Ubuntu/Debian\nsudo apt-get install g++-11\n\n# macOS\nbrew install gcc@11\n\n# Specify compiler\ncmake -B build -DCMAKE_CXX_COMPILER=g++-11\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#matlab-interface-removal","title":"MATLAB Interface Removal","text":""},{"location":"migration/v0.3-to-v0.4/#old-v03-matlab-interface","title":"Old (v0.3): MATLAB Interface","text":"<pre><code>% MATLAB code (NO LONGER SUPPORTED)\nA = randn(100, 50);\nb = randn(100, 1);\nlambda = 0.1;\n\nx = pogs_lasso(A, b, lambda);\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#new-v04-pythoncvxpy","title":"New (v0.4): Python/CVXPY","text":"<pre><code>import cvxpy as cp\nimport numpy as np\n\nA = np.random.randn(100, 50)\nb = np.random.randn(100)\nlambda_val = 0.1\n\nx = cp.Variable(50)\nobjective = cp.Minimize(\n    0.5 * cp.sum_squares(A @ x - b) + lambda_val * cp.norm(x, 1)\n)\nprob = cp.Problem(objective)\nprob.solve(solver='POGS', verbose=True)\n\nprint(f\"Solution: {x.value}\")\n</code></pre> <p>Why Python/CVXPY? - More active development - Better ecosystem (NumPy, SciPy, Pandas) - Easier installation (<code>pip install cvxpy</code>) - More expressive modeling language</p>"},{"location":"migration/v0.3-to-v0.4/#c-api-current-legacy","title":"C++ API (Current - Legacy)","text":"<p>The C++ API remains largely unchanged in v0.4. Full modernization will come in future releases.</p>"},{"location":"migration/v0.3-to-v0.4/#graph-form-unchanged","title":"Graph Form (Unchanged)","text":"<pre><code>#include \"pogs.h\"\n#include \"matrix/matrix_dense.h\"\n\n// Problem data\npogs::MatrixDense&lt;double&gt; A('r', m, n, A_data);\n\nstd::vector&lt;FunctionObj&lt;double&gt;&gt; f(m);\nstd::vector&lt;FunctionObj&lt;double&gt;&gt; g(n);\n\n// Define f and g...\nfor (size_t i = 0; i &lt; m; ++i) {\n    f[i].h = kSquare;\n    f[i].c = 0.5;\n}\n\nfor (size_t j = 0; j &lt; n; ++j) {\n    g[j].h = kAbs;\n    g[j].c = lambda;\n}\n\n// Solve\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\nsolver.SetAbsTol(1e-4);\nsolver.SetRelTol(1e-3);\nsolver.SetMaxIter(1000);\nsolver.Solve(f, g);\n\ndouble optval = solver.GetOptval();\nconst double* x = solver.GetX();\n</code></pre> <p>Status: This API still works in v0.4 and will continue to be supported.</p>"},{"location":"migration/v0.3-to-v0.4/#cone-form-unchanged","title":"Cone Form (Unchanged)","text":"<pre><code>#include \"pogs.h\"\n\n// Cone form: min c'x s.t. Ax = b, x in K\nstd::vector&lt;ConeConstraint&gt; Kx = {{kConeNonNeg, {0, 1, 2}}};\nstd::vector&lt;ConeConstraint&gt; Ky = {{kConeZero, {0, 1}}};\n\npogs::PogsDirectCone&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A, Kx, Ky);\nsolver.Solve(b, c);\n</code></pre> <p>Status: This API still works in v0.4.</p>"},{"location":"migration/v0.3-to-v0.4/#future-modern-api-preview","title":"Future Modern API (Preview)","text":"<p>Not Yet Available</p> <p>The following modern API is planned for a future release. This is shown for reference only.</p>"},{"location":"migration/v0.3-to-v0.4/#future-modern-c20-api","title":"Future: Modern C++20 API","text":"<pre><code>#include &lt;pogs/pogs.hpp&gt;\n#include &lt;pogs/types.hpp&gt;\n#include &lt;pogs/config.hpp&gt;\n\n// Modern type system\nauto config = pogs::SolverConfig{\n    .rho = 1.0,\n    .abs_tol = 1e-4,\n    .rel_tol = 1e-3,\n    .max_iter = 1000,\n    .verbose = true\n};\n\n// Smart pointers\nauto A = std::make_unique&lt;pogs::MatrixDense&lt;double&gt;&gt;(m, n);\nauto solver = pogs::make_solver&lt;double&gt;(std::move(A));\nsolver.configure(config);\n\n// Modern function objects\nstd::vector&lt;pogs::FunctionObj&lt;double&gt;&gt; f(m);\nfor (auto&amp; fi : f) {\n    fi.type = pogs::FunctionType::Square;  // Enum class\n    fi.c = 0.5;\n}\n\nauto result = solver.solve(f, g);\n\nif (result.status == pogs::Status::Success) {\n    std::cout &lt;&lt; \"Optimal: \" &lt;&lt; result.primal_obj.value() &lt;&lt; \"\\n\";\n}\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#common-migration-scenarios","title":"Common Migration Scenarios","text":""},{"location":"migration/v0.3-to-v0.4/#scenario-1-simple-lasso-regression","title":"Scenario 1: Simple Lasso Regression","text":"<p>Old (v0.3 - MATLAB): <pre><code>A = randn(100, 50);\nb = randn(100, 1);\nx = pogs_lasso(A, b, 0.1);\n</code></pre></p> <p>New (v0.4 - Python): <pre><code>import cvxpy as cp\nimport numpy as np\n\nA = np.random.randn(100, 50)\nb = np.random.randn(100)\n\nx = cp.Variable(50)\nobjective = cp.Minimize(\n    0.5 * cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)\n)\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n\nprint(f\"Solution: {x.value}\")\n</code></pre></p> <p>New (v0.4 - C++, if needed): <pre><code>// C++ API unchanged from v0.3\n#include \"pogs.h\"\n\npogs::MatrixDense&lt;double&gt; A('r', m, n, A_data);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\n\nstd::vector&lt;FunctionObj&lt;double&gt;&gt; f(m), g(n);\n// ... configure f and g as before ...\n\nsolver.Solve(f, g);\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#scenario-2-custom-problem-in-c","title":"Scenario 2: Custom Problem in C++","text":"<p>Old (v0.3): <pre><code>// Build with Makefile\n// Uses C++11\n\n#include \"pogs.h\"\n\npogs::MatrixDense&lt;double&gt; A('r', m, n, data);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\nsolver.Solve(f, g);\n</code></pre></p> <p>New (v0.4): <pre><code>// Build with CMake\n// Uses C++20 (but legacy API still works)\n\n#include \"pogs.h\"  // Same header\n\npogs::MatrixDense&lt;double&gt; A('r', m, n, data);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\nsolver.Solve(f, g);  // Same API\n</code></pre></p> <p>CMakeLists.txt: <pre><code>cmake_minimum_required(VERSION 3.20)\nproject(MyProject CXX)\n\nset(CMAKE_CXX_STANDARD 20)\n\nfind_package(POGS REQUIRED)\n\nadd_executable(myapp main.cpp)\ntarget_link_libraries(myapp PRIVATE pogs::cpu)\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#scenario-3-logistic-regression","title":"Scenario 3: Logistic Regression","text":"<p>Old (v0.3 - MATLAB): <pre><code>X = randn(200, 50);\ny = sign(randn(200, 1));\nw = pogs_logistic(X, y, 0.1);\n</code></pre></p> <p>New (v0.4 - Python): <pre><code>import cvxpy as cp\nimport numpy as np\n\nX = np.random.randn(200, 50)\ny = np.sign(np.random.randn(200))\n\nw = cp.Variable(50)\nb = cp.Variable()\n\nlosses = cp.sum(cp.logistic(-cp.multiply(y, X @ w + b)))\nregularization = 0.1 * cp.sum_squares(w)\nobjective = cp.Minimize(losses + regularization)\n\nprob = cp.Problem(objective)\nprob.solve(solver='POGS')\n\nprint(f\"Weights: {w.value}\")\nprint(f\"Intercept: {b.value}\")\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#installation-changes","title":"Installation Changes","text":""},{"location":"migration/v0.3-to-v0.4/#old-v03_1","title":"Old (v0.3)","text":"<pre><code>git clone https://github.com/foges/pogs.git\ncd pogs/src\nmake cpu\n# Library at: src/build/pogs.a\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#new-v04_1","title":"New (v0.4)","text":"<pre><code>git clone https://github.com/foges/pogs.git\ncd pogs\n\n# Configure\ncmake -B build -DCMAKE_BUILD_TYPE=Release\n\n# Build\ncmake --build build\n\n# Install (optional)\nsudo cmake --install build\n# Installs to: /usr/local/lib/libpogs_cpu.a\n#              /usr/local/include/pogs/\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#custom-installation-location","title":"Custom Installation Location","text":"<pre><code># Install to $HOME/local\ncmake -B build -DCMAKE_INSTALL_PREFIX=$HOME/local\ncmake --build build\ncmake --install build\n\n# Set environment\nexport CMAKE_PREFIX_PATH=$HOME/local:$CMAKE_PREFIX_PATH\nexport LD_LIBRARY_PATH=$HOME/local/lib:$LD_LIBRARY_PATH\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#documentation-changes","title":"Documentation Changes","text":""},{"location":"migration/v0.3-to-v0.4/#old-v03_2","title":"Old (v0.3)","text":"<ul> <li>Jekyll-based GitHub Pages</li> <li>Outdated content from 2014</li> <li>Limited navigation</li> <li>No search</li> </ul>"},{"location":"migration/v0.3-to-v0.4/#new-v04_2","title":"New (v0.4)","text":"<ul> <li>MkDocs Material</li> <li>Modern, comprehensive documentation</li> <li>Full-text search</li> <li>Mobile-friendly</li> <li>Dark mode support</li> </ul> <p>Access: - Online: https://foges.github.io/pogs/ - Local: <code>mkdocs serve</code> (requires <code>pip install mkdocs-material</code>)</p>"},{"location":"migration/v0.3-to-v0.4/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"migration/v0.3-to-v0.4/#macos","title":"macOS","text":"<p>Old (v0.3): <pre><code>make cpu  # Uses Accelerate\n</code></pre></p> <p>New (v0.4): <pre><code># CMake automatically finds Accelerate\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#linux","title":"Linux","text":"<p>Old (v0.3): <pre><code># Manually specify BLAS/LAPACK in Makefile\nmake cpu BLAS_LIBS=-lopenblas\n</code></pre></p> <p>New (v0.4): <pre><code># Install dependencies\nsudo apt-get install libopenblas-dev liblapack-dev\n\n# CMake finds them automatically\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#windows","title":"Windows","text":"<p>Old (v0.3): - Limited support - Manual configuration</p> <p>New (v0.4): <pre><code># Visual Studio\ncmake -B build -G \"Visual Studio 17 2022\" -A x64\ncmake --build build --config Release\ncmake --install build\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#troubleshooting","title":"Troubleshooting","text":""},{"location":"migration/v0.3-to-v0.4/#no-such-file-pogsh","title":"\"No such file: pogs.h\"","text":"<p>Problem: Old include path</p> <p>Solution: <pre><code>// Old (v0.3)\n#include \"pogs.h\"\n\n// New (v0.4) - Same!\n#include \"pogs.h\"  // Works if installed correctly\n\n// Or use full path\n#include \"pogs/pogs.h\"  // Future modern API\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#undefined-reference-to-pogs-functions","title":"\"Undefined reference to POGS functions\"","text":"<p>Problem: Not linking against library</p> <p>Solution: <pre><code># CMakeLists.txt\nfind_package(POGS REQUIRED)\ntarget_link_libraries(myapp PRIVATE pogs::cpu)\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#matlab-interface-not-found","title":"\"MATLAB interface not found\"","text":"<p>Problem: MATLAB interface removed</p> <p>Solution: Migrate to Python/CVXPY (see examples above)</p>"},{"location":"migration/v0.3-to-v0.4/#compiler-doesnt-support-c20","title":"\"Compiler doesn't support C++20\"","text":"<p>Problem: Old compiler</p> <p>Solution: <pre><code># Check version\ng++ --version\n\n# Update compiler\nsudo apt-get install g++-11  # Linux\nbrew install gcc@11          # macOS\n\n# Specify compiler\ncmake -B build -DCMAKE_CXX_COMPILER=g++-11\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#cmake-cant-find-pogs","title":"\"CMake can't find POGS\"","text":"<p>Problem: POGS not installed or not in CMake search path</p> <p>Solution: <pre><code># Option 1: Install POGS\nsudo cmake --install build\n\n# Option 2: Set CMAKE_PREFIX_PATH\ncmake -B build -DCMAKE_PREFIX_PATH=/path/to/pogs/install\n\n# Option 3: Use environment variable\nexport CMAKE_PREFIX_PATH=/path/to/pogs/install\n</code></pre></p>"},{"location":"migration/v0.3-to-v0.4/#performance-notes","title":"Performance Notes","text":""},{"location":"migration/v0.3-to-v0.4/#no-performance-regression","title":"No Performance Regression","text":"<p>Version 0.4 uses the same core ADMM algorithm as v0.3. Performance should be identical for the same problems.</p>"},{"location":"migration/v0.3-to-v0.4/#compiler-optimizations","title":"Compiler Optimizations","text":"<p>C++20 compilers may provide better optimizations:</p> <pre><code># Enable LTO (Link Time Optimization)\ncmake -B build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON\n</code></pre>"},{"location":"migration/v0.3-to-v0.4/#deprecation-timeline","title":"Deprecation Timeline","text":"Feature v0.3 v0.4 Future MATLAB Interface \u2705 Supported \u274c Removed \u274c Not returning R Interface \u2705 Supported \u274c Removed \u274c Not returning Makefile Build \u2705 Primary \u274c Removed \u274c Not returning CMake Build \u274c Not available \u2705 Primary \u2705 Continued C++11 API \u2705 Primary \u2705 Compatible \ud83d\udfe1 Legacy C++20 API \u274c Not available \ud83d\udfe1 Foundation \u2705 Primary Python/CVXPY \ud83d\udfe1 Experimental \u2705 Supported \u2705 Primary"},{"location":"migration/v0.3-to-v0.4/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: https://foges.github.io/pogs/</li> <li>Examples: https://foges.github.io/pogs/examples/</li> <li>Issues: https://github.com/foges/pogs/issues</li> <li>Discussions: GitHub Discussions (coming soon)</li> </ul>"},{"location":"migration/v0.3-to-v0.4/#summary-checklist","title":"Summary Checklist","text":"<p>Migration checklist for v0.3 \u2192 v0.4:</p> <ul> <li> Update build system from Makefile to CMake</li> <li> Ensure compiler supports C++20 (GCC 10+, Clang 13+)</li> <li> Migrate MATLAB code to Python/CVXPY</li> <li> Update include paths if needed</li> <li> Update link flags to use <code>find_package(POGS)</code></li> <li> Test your code with v0.4</li> <li> Review new documentation</li> <li> Update CI/CD pipelines if applicable</li> </ul>"},{"location":"migration/v0.3-to-v0.4/#next-steps","title":"Next Steps","text":"<p>After migration:</p> <ol> <li>Explore new documentation: Modern guides and examples</li> <li>Try Python/CVXPY: Easier problem formulation</li> <li>Contribute: Help improve POGS</li> <li>Stay updated: Watch for v0.5 with full modern API</li> </ol>"},{"location":"migration/v0.3-to-v0.4/#questions","title":"Questions?","text":"<p>If you encounter issues during migration:</p> <ol> <li>Check this guide</li> <li>Review examples</li> <li>Search existing issues</li> <li>Open a new issue with:</li> <li>Version: v0.3 \u2192 v0.4</li> <li>Platform: OS and compiler</li> <li>Error message</li> <li>Minimal reproducible example</li> </ol>"},{"location":"user-guide/advanced-features/","title":"Advanced Features","text":"<p>This guide covers advanced POGS features for power users.</p>"},{"location":"user-guide/advanced-features/#warm-starting","title":"Warm Starting","text":"<p>Warm starting can significantly reduce solve time when solving a sequence of related problems.</p>"},{"location":"user-guide/advanced-features/#basic-warm-start","title":"Basic Warm Start","text":"<pre><code>#include \"pogs.h\"\n#include \"matrix/matrix_dense.h\"\n\npogs::MatrixDense&lt;double&gt; A('r', m, n, A_data);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\n\n// Solve first problem\nPogsStatus status1 = solver.Solve(f1, g1);\n\n// Get solution\nconst double* x_sol = solver.GetX();\nconst double* lambda_sol = solver.GetLambda();\n\n// Copy for warm start\nstd::vector&lt;double&gt; x_init(x_sol, x_sol + n);\nstd::vector&lt;double&gt; lambda_init(lambda_sol, lambda_sol + m);\n\n// Warm start for next problem\nsolver.SetInitX(x_init.data());\nsolver.SetInitLambda(lambda_init.data());\n\n// Solve similar problem (faster!)\nPogsStatus status2 = solver.Solve(f2, g2);\n</code></pre>"},{"location":"user-guide/advanced-features/#use-cases","title":"Use Cases","text":"<ul> <li>Parameter sweeps: Solving problems with varying lambda</li> <li>Online optimization: Updating solutions as new data arrives</li> <li>Iterative refinement: Solving with increasing accuracy</li> </ul>"},{"location":"user-guide/advanced-features/#custom-penalty-parameter-rho","title":"Custom Penalty Parameter (rho)","text":"<p>The penalty parameter rho controls the ADMM convergence behavior.</p>"},{"location":"user-guide/advanced-features/#manual-rho-selection","title":"Manual rho Selection","text":"<pre><code>solver.SetRho(10.0);           // Larger for faster convergence\nsolver.SetAdaptiveRho(false);  // Disable adaptive adjustment\n</code></pre>"},{"location":"user-guide/advanced-features/#when-to-adjust-rho","title":"When to Adjust rho","text":"<p>Increase rho (larger values like 5.0-100.0): - When primal residual &gt;&gt; dual residual - For well-conditioned problems - When you want faster convergence (may sacrifice accuracy)</p> <p>Decrease rho (smaller values like 0.01-0.5): - When dual residual &gt;&gt; primal residual - For ill-conditioned problems - When you need high accuracy</p>"},{"location":"user-guide/advanced-features/#adaptive-rho-recommended","title":"Adaptive rho (Recommended)","text":"<pre><code>solver.SetRho(1.0);\nsolver.SetAdaptiveRho(true);  // Automatically adjust rho\n</code></pre> <p>The solver will automatically increase/decrease rho based on residual balance.</p>"},{"location":"user-guide/advanced-features/#anderson-acceleration","title":"Anderson Acceleration","text":"<p>Anderson acceleration can speed up convergence by 20-50% on well-conditioned problems.</p>"},{"location":"user-guide/advanced-features/#enabling-anderson-acceleration","title":"Enabling Anderson Acceleration","text":"<pre><code>solver.SetUseAnderson(true);\nsolver.SetAndersonMem(5);     // Number of past iterates to store\nsolver.SetAndersonStart(10);  // Start after 10 iterations\n</code></pre>"},{"location":"user-guide/advanced-features/#when-to-use","title":"When to Use","text":"<ul> <li>Well-conditioned problems</li> <li>Problems that converge slowly without it</li> <li>When iterations are the bottleneck (not matrix operations)</li> </ul>"},{"location":"user-guide/advanced-features/#when-to-avoid","title":"When to Avoid","text":"<ul> <li>Ill-conditioned problems (may be unstable)</li> <li>When each iteration is expensive</li> <li>Very easy problems (overhead not worth it)</li> </ul>"},{"location":"user-guide/advanced-features/#function-parameterization","title":"Function Parameterization","text":""},{"location":"user-guide/advanced-features/#general-function-form","title":"General Function Form","text":"<p>Each function has the form:</p> \\[ c \\cdot h(ax - b) + d \\cdot x + e \\cdot x^2 \\] <p>where: - <code>a</code>: Input scaling - <code>b</code>: Input shift - <code>c</code>: Output scaling - <code>d</code>: Linear term coefficient - <code>e</code>: Quadratic term coefficient - <code>h</code>: Base function type</p>"},{"location":"user-guide/advanced-features/#example-scaled-huber-loss","title":"Example: Scaled Huber Loss","text":"<pre><code>FunctionObj&lt;double&gt; f;\nf.h = kHuber;\nf.a = 2.0;     // Scale input\nf.c = 0.5;     // Scale output\nf.d = -b[i];   // Linear term (for data fitting)\n</code></pre> <p>This creates: \\(f(x) = 0.5 \\cdot \\text{huber}(2x) - b_i \\cdot x\\)</p>"},{"location":"user-guide/advanced-features/#sparse-matrix-operations","title":"Sparse Matrix Operations","text":""},{"location":"user-guide/advanced-features/#creating-sparse-matrices","title":"Creating Sparse Matrices","text":"<pre><code>#include \"pogs.h\"\n#include \"matrix/matrix_sparse.h\"\n\n// CSR format (row-major sparse)\n// ptr: row pointers (size m+1)\n// ind: column indices (size nnz)\n// val: values (size nnz)\n\npogs::MatrixSparse&lt;double&gt; A('r', m, n, nnz, val, ptr, ind);\npogs::PogsCgls&lt;double, pogs::MatrixSparse&lt;double&gt;&gt; solver(A);\n</code></pre>"},{"location":"user-guide/advanced-features/#sparse-format-benefits","title":"Sparse Format Benefits","text":"<ul> <li>Memory: O(nnz) instead of O(m*n)</li> <li>Speed: Faster matrix-vector products when sparse</li> <li>Scalability: Enables much larger problems</li> </ul>"},{"location":"user-guide/advanced-features/#when-to-use-sparse","title":"When to Use Sparse","text":"<p>Use sparse format when: - Sparsity &gt; 90% (fewer than 10% non-zeros) - Problem size &gt; 1000 variables - Memory is constrained</p>"},{"location":"user-guide/advanced-features/#gpu-acceleration","title":"GPU Acceleration","text":"<p>GPU support requires CUDA and is built separately.</p>"},{"location":"user-guide/advanced-features/#building-with-gpu-support","title":"Building with GPU Support","text":"<pre><code>cmake -B build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DPOGS_BUILD_GPU=ON \\\n    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda\n\ncmake --build build\n</code></pre>"},{"location":"user-guide/advanced-features/#using-gpu-solver","title":"Using GPU Solver","text":"<p>The GPU solver uses the same API as CPU:</p> <pre><code>// Include GPU-specific headers\n#include \"pogs.h\"\n#include \"matrix/matrix_dense.h\"\n\n// Create solver (GPU version if built with CUDA)\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\nsolver.Solve(f, g);\n</code></pre>"},{"location":"user-guide/advanced-features/#gpu-limitations","title":"GPU Limitations","text":"<ul> <li>SDP cones not yet supported on GPU</li> <li>Requires CUDA 11.0+</li> <li>Best for large dense problems (&gt; 10,000 variables)</li> </ul>"},{"location":"user-guide/advanced-features/#precision-control","title":"Precision Control","text":""},{"location":"user-guide/advanced-features/#single-vs-double-precision","title":"Single vs. Double Precision","text":"<pre><code>// Double precision (default)\npogs::MatrixDense&lt;double&gt; A_d('r', m, n, A_data_d);\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver_d(A_d);\n\n// Single precision (faster, less accurate)\npogs::MatrixDense&lt;float&gt; A_f('r', m, n, A_data_f);\npogs::PogsDirect&lt;float, pogs::MatrixDense&lt;float&gt;&gt; solver_f(A_f);\n</code></pre> <p>Use single precision when: - Speed is critical - Problem is well-conditioned - You don't need &lt; 1e-5 accuracy</p> <p>Use double precision when: - High accuracy required - Problem is ill-conditioned - Working with financial data</p>"},{"location":"user-guide/advanced-features/#monitoring-convergence","title":"Monitoring Convergence","text":""},{"location":"user-guide/advanced-features/#verbose-output","title":"Verbose Output","text":"<pre><code>solver.SetVerbose(2);  // 0=quiet, 1=summary, 2=progress, 3=detailed\n</code></pre> <p>Output shows: <pre><code>Iter   Primal Res   Dual Res     Gap        rho\n  10   1.23e-02    4.56e-03    8.90e-02   1.00\n  20   3.45e-03    1.23e-03    2.34e-02   1.00\n  ...\n 186   9.12e-05    3.45e-05    1.23e-04   1.00\n</code></pre></p>"},{"location":"user-guide/advanced-features/#extracting-results","title":"Extracting Results","text":"<pre><code>PogsStatus status = solver.Solve(f, g);\n\n// Result information\nprintf(\"Iterations: %u\\n\", solver.GetFinalIter());\nprintf(\"Optimal value: %f\\n\", solver.GetOptval());\nprintf(\"Final rho: %f\\n\", solver.GetRho());\n\n// Solution vectors\nconst double* x = solver.GetX();\nconst double* y = solver.GetY();\nconst double* lambda = solver.GetLambda();\nconst double* mu = solver.GetMu();\n</code></pre>"},{"location":"user-guide/advanced-features/#problem-scaling","title":"Problem Scaling","text":"<p>Proper scaling can dramatically improve convergence.</p>"},{"location":"user-guide/advanced-features/#data-matrix-scaling","title":"Data Matrix Scaling","text":"<pre><code>// Normalize columns of A to have unit norm\nfor (size_t j = 0; j &lt; n; ++j) {\n    double norm = compute_column_norm(A, j);\n    scale_column(A, j, 1.0 / norm);\n}\n\n// Normalize rows of A\nfor (size_t i = 0; i &lt; m; ++i) {\n    double norm = compute_row_norm(A, i);\n    scale_row(A, i, 1.0 / norm);\n}\n</code></pre>"},{"location":"user-guide/advanced-features/#objective-scaling","title":"Objective Scaling","text":"<p>Scale objectives to have similar magnitudes:</p> <pre><code>// If ||Ax - b||^2 ~ 1000 and ||x||_1 ~ 10\n// Scale the L1 term:\ndouble scale = 100.0;  // Balance the terms\nfor (size_t j = 0; j &lt; n; ++j) {\n    g[j].c = lambda * scale;\n}\n</code></pre>"},{"location":"user-guide/advanced-features/#handling-infeasibility","title":"Handling Infeasibility","text":"<p>If the solver reports infeasibility:</p> <ol> <li>Check constraints: Are they mutually compatible?</li> <li>Relax tolerances: Some \"infeasible\" problems are just hard</li> <li>Scale the problem: Poor scaling can cause numerical issues</li> <li>Check for unboundedness: Add bounds if needed</li> </ol> <pre><code>if (status == POGS_INFEASIBLE || status == POGS_UNBOUNDED) {\n    // Try with relaxed tolerances\n    solver.SetAbsTol(1e-3);\n    solver.SetRelTol(1e-2);\n    solver.SetMaxIter(5000);\n\n    PogsStatus status2 = solver.Solve(f, g);\n}\n</code></pre>"},{"location":"user-guide/advanced-features/#custom-stopping-criteria","title":"Custom Stopping Criteria","text":"<p>The solver uses both absolute and relative stopping criteria:</p> \\[ \\text{stop when } \\|r\\|_2 \\leq \\epsilon_{\\text{abs}} + \\epsilon_{\\text{rel}} \\cdot \\max(\\|Ax\\|_2, \\|y\\|_2) \\] <p>Adjust based on problem:</p> <pre><code>// High accuracy\nsolver.SetAbsTol(1e-6);\nsolver.SetRelTol(1e-6);\n\n// Fast approximate solution\nsolver.SetAbsTol(1e-2);\nsolver.SetRelTol(1e-2);\nsolver.SetMaxIter(100);\n</code></pre>"},{"location":"user-guide/advanced-features/#performance-tips","title":"Performance Tips","text":""},{"location":"user-guide/advanced-features/#for-fastest-solve-time","title":"For Fastest Solve Time","text":"<ol> <li>Use sparse matrices when applicable</li> <li>Enable adaptive rho</li> <li>Use single precision if accuracy permits</li> <li>Warm start for sequences of problems</li> <li>Scale your data properly</li> <li>Try Anderson acceleration</li> </ol>"},{"location":"user-guide/advanced-features/#for-highest-accuracy","title":"For Highest Accuracy","text":"<ol> <li>Use double precision</li> <li>Tighten tolerances (1e-6 or better)</li> <li>Increase max iterations</li> <li>Disable early stopping (<code>SetGapStop(false)</code>)</li> <li>Start with smaller rho</li> </ol>"},{"location":"user-guide/advanced-features/#see-also","title":"See Also","text":"<ul> <li>Basic Usage - Fundamentals</li> <li>Cone Problems - LP, QP, SOCP, SDP</li> <li>Examples - Complete examples</li> </ul>"},{"location":"user-guide/basic-usage/","title":"Basic Usage","text":"<p>This guide covers the fundamental usage patterns for POGS.</p>"},{"location":"user-guide/basic-usage/#problem-formulation","title":"Problem Formulation","text":"<p>POGS solves problems in graph form:</p> \\[ \\begin{align} \\text{minimize} \\quad &amp; f(y) + g(x) \\\\ \\text{subject to} \\quad &amp; y = Ax \\end{align} \\] <p>where: - \\(f:\\mathbb{R}^m \\to \\mathbb{R}\\) and \\(g:\\mathbb{R}^n \\to \\mathbb{R}\\) are convex, separable functions - \\(A \\in \\mathbb{R}^{m \\times n}\\) is the data matrix - \\(x \\in \\mathbb{R}^n\\) are the optimization variables - \\(y \\in \\mathbb{R}^m\\) are auxiliary variables</p> <p>Separability means: $$ f(y) = \\sum_{i=1}^m f_i(y_i), \\quad g(x) = \\sum_{j=1}^n g_j(x_j) $$</p>"},{"location":"user-guide/basic-usage/#c-interface","title":"C++ Interface","text":""},{"location":"user-guide/basic-usage/#1-include-headers-and-create-matrix","title":"1. Include Headers and Create Matrix","text":"<pre><code>#include \"pogs.h\"\n#include \"matrix/matrix_dense.h\"\n\nconst size_t m = 100;  // Number of samples\nconst size_t n = 50;   // Number of features\n\n// Create matrix A (row-major, m x n)\nstd::vector&lt;double&gt; A_data(m * n);\n// ... fill A_data ...\n\npogs::MatrixDense&lt;double&gt; A('r', m, n, A_data.data());\n</code></pre>"},{"location":"user-guide/basic-usage/#2-create-the-solver","title":"2. Create the Solver","text":"<pre><code>// PogsDirect - uses direct factorization (dense problems)\npogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\n\n// Alternative: PogsCgls - uses iterative method (large/sparse problems)\n// pogs::PogsCgls&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\n</code></pre>"},{"location":"user-guide/basic-usage/#3-define-objective-functions","title":"3. Define Objective Functions","text":"<pre><code>// f_i(y_i) and g_j(x_j) are defined using FunctionObj\nstd::vector&lt;FunctionObj&lt;double&gt;&gt; f(m);\nstd::vector&lt;FunctionObj&lt;double&gt;&gt; g(n);\n\n// Example: Lasso (least squares + L1 regularization)\n// f_i(y_i) = (1/2) * y_i^2 - b_i * y_i  (for ||Ax - b||^2)\nfor (size_t i = 0; i &lt; m; ++i) {\n    f[i].h = kSquare;   // Base function: (1/2) x^2\n    f[i].c = 1.0;       // Scaling\n    f[i].d = -b[i];     // Linear term: creates ||y - b||^2\n}\n\n// g_j(x_j) = lambda * |x_j|  (L1 regularization)\ndouble lambda = 0.1;\nfor (size_t j = 0; j &lt; n; ++j) {\n    g[j].h = kAbs;      // Base function: |x|\n    g[j].c = lambda;    // Regularization weight\n}\n</code></pre>"},{"location":"user-guide/basic-usage/#4-configure-the-solver","title":"4. Configure the Solver","text":"<pre><code>solver.SetRho(1.0);           // ADMM penalty parameter\nsolver.SetAbsTol(1e-4);       // Absolute tolerance\nsolver.SetRelTol(1e-3);       // Relative tolerance\nsolver.SetMaxIter(1000);      // Maximum iterations\nsolver.SetVerbose(2);         // Show progress\nsolver.SetAdaptiveRho(true);  // Enable adaptive rho\n</code></pre>"},{"location":"user-guide/basic-usage/#5-solve-and-get-results","title":"5. Solve and Get Results","text":"<pre><code>PogsStatus status = solver.Solve(f, g);\n\nif (status == POGS_SUCCESS) {\n    printf(\"Converged in %u iterations\\n\", solver.GetFinalIter());\n    printf(\"Optimal value: %f\\n\", solver.GetOptval());\n\n    // Access solution\n    const double* x = solver.GetX();\n    for (size_t j = 0; j &lt; n; ++j) {\n        printf(\"x[%zu] = %f\\n\", j, x[j]);\n    }\n}\n</code></pre>"},{"location":"user-guide/basic-usage/#complete-example","title":"Complete Example","text":"<pre><code>#include \"pogs.h\"\n#include \"matrix/matrix_dense.h\"\n#include &lt;vector&gt;\n#include &lt;cstdio&gt;\n#include &lt;cstdlib&gt;\n\nint main() {\n    const size_t m = 100;  // samples\n    const size_t n = 50;   // features\n    const double lambda = 0.1;\n\n    // Generate random data\n    std::vector&lt;double&gt; A_data(m * n);\n    std::vector&lt;double&gt; b(m);\n    for (size_t i = 0; i &lt; m * n; ++i)\n        A_data[i] = (double)rand() / RAND_MAX - 0.5;\n    for (size_t i = 0; i &lt; m; ++i)\n        b[i] = (double)rand() / RAND_MAX - 0.5;\n\n    // Create matrix and solver\n    pogs::MatrixDense&lt;double&gt; A('r', m, n, A_data.data());\n    pogs::PogsDirect&lt;double, pogs::MatrixDense&lt;double&gt;&gt; solver(A);\n\n    // Configure\n    solver.SetAbsTol(1e-4);\n    solver.SetRelTol(1e-3);\n    solver.SetMaxIter(1000);\n    solver.SetVerbose(2);\n\n    // Define objective functions\n    std::vector&lt;FunctionObj&lt;double&gt;&gt; f(m), g(n);\n    for (size_t i = 0; i &lt; m; ++i) {\n        f[i].h = kSquare;\n        f[i].d = -b[i];\n    }\n    for (size_t j = 0; j &lt; n; ++j) {\n        g[j].h = kAbs;\n        g[j].c = lambda;\n    }\n\n    // Solve\n    PogsStatus status = solver.Solve(f, g);\n\n    if (status == POGS_SUCCESS) {\n        printf(\"Converged! Optimal value: %f\\n\", solver.GetOptval());\n    } else {\n        printf(\"Failed with status: %d\\n\", status);\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"user-guide/basic-usage/#function-types","title":"Function Types","text":"<p>POGS supports many common functions via the <code>Function</code> enum:</p>"},{"location":"user-guide/basic-usage/#norms-and-regularization","title":"Norms and Regularization","text":"Enum Mathematical Form Use Case <code>kAbs</code> \\(\\|x\\|\\) L1 regularization (Lasso) <code>kSquare</code> \\((1/2)x^2\\) Least squares, L2 penalty <code>kHuber</code> Huber loss Robust regression"},{"location":"user-guide/basic-usage/#indicator-functions-constraints","title":"Indicator Functions (Constraints)","text":"Enum Mathematical Form Use Case <code>kIndBox01</code> \\(I_{[0,1]}(x)\\) Box constraints <code>kIndEq0</code> \\(I_{\\{0\\}}(x)\\) Equality to zero <code>kIndGe0</code> \\(I_{[0,\\infty)}(x)\\) Non-negativity <code>kIndLe0</code> \\(I_{(-\\infty,0]}(x)\\) Non-positivity"},{"location":"user-guide/basic-usage/#nonlinear-functions","title":"Nonlinear Functions","text":"Enum Mathematical Form Use Case <code>kLogistic</code> \\(\\log(1 + e^x)\\) Logistic regression <code>kNegLog</code> \\(-\\log(x)\\) Barrier functions <code>kExp</code> \\(e^x\\) Exponential objectives <code>kIdentity</code> \\(x\\) Linear terms <code>kZero</code> \\(0\\) Unconstrained"},{"location":"user-guide/basic-usage/#functionobj-parameters","title":"FunctionObj Parameters","text":"<p>Each <code>FunctionObj&lt;T&gt;</code> represents:</p> \\[ c \\cdot h(ax - b) + d \\cdot x + e \\cdot x^2 \\] Field Default Description <code>h</code> <code>kZero</code> Base function type <code>a</code> <code>1.0</code> Input scaling <code>b</code> <code>0.0</code> Input shift <code>c</code> <code>1.0</code> Output scaling <code>d</code> <code>0.0</code> Linear term coefficient <code>e</code> <code>0.0</code> Quadratic term coefficient <p>Example: <pre><code>FunctionObj&lt;double&gt; obj;\nobj.h = kSquare;  // h(x) = (1/2)x^2\nobj.c = 0.5;      // Scale by 0.5\nobj.d = -b[i];    // Add linear term -b[i]*x\n// Result: 0.5 * (1/2) * x^2 - b[i] * x = (1/4)x^2 - b[i]*x\n</code></pre></p>"},{"location":"user-guide/basic-usage/#common-problem-types","title":"Common Problem Types","text":""},{"location":"user-guide/basic-usage/#lasso-regression","title":"Lasso Regression","text":"\\[ \\text{minimize} \\quad \\frac{1}{2}\\|Ax - b\\|_2^2 + \\lambda\\|x\\|_1 \\] <pre><code>for (size_t i = 0; i &lt; m; ++i) {\n    f[i].h = kSquare;\n    f[i].d = -b[i];\n}\nfor (size_t j = 0; j &lt; n; ++j) {\n    g[j].h = kAbs;\n    g[j].c = lambda;\n}\n</code></pre>"},{"location":"user-guide/basic-usage/#ridge-regression","title":"Ridge Regression","text":"\\[ \\text{minimize} \\quad \\|Ax - b\\|_2^2 + \\lambda\\|x\\|_2^2 \\] <pre><code>for (size_t i = 0; i &lt; m; ++i) {\n    f[i].h = kSquare;\n    f[i].d = -2.0 * b[i];\n}\nfor (size_t j = 0; j &lt; n; ++j) {\n    g[j].h = kSquare;\n    g[j].c = lambda;\n}\n</code></pre>"},{"location":"user-guide/basic-usage/#non-negative-least-squares","title":"Non-Negative Least Squares","text":"\\[ \\begin{align} \\text{minimize} \\quad &amp; \\|Ax - b\\|_2^2 \\\\ \\text{subject to} \\quad &amp; x \\geq 0 \\end{align} \\] <pre><code>for (size_t i = 0; i &lt; m; ++i) {\n    f[i].h = kSquare;\n    f[i].d = -2.0 * b[i];\n}\nfor (size_t j = 0; j &lt; n; ++j) {\n    g[j].h = kIndGe0;  // Non-negativity constraint\n}\n</code></pre>"},{"location":"user-guide/basic-usage/#status-codes","title":"Status Codes","text":"Status Meaning <code>POGS_SUCCESS</code> Converged successfully <code>POGS_MAX_ITER</code> Maximum iterations reached <code>POGS_NAN_FOUND</code> Numerical error (NaN) <code>POGS_INFEASIBLE</code> Problem likely infeasible <code>POGS_UNBOUNDED</code> Problem likely unbounded <code>POGS_ERROR</code> Generic error"},{"location":"user-guide/basic-usage/#solver-parameters","title":"Solver Parameters","text":""},{"location":"user-guide/basic-usage/#penalty-parameter-rho","title":"Penalty Parameter (rho)","text":"<ul> <li>Controls the weight of the augmented Lagrangian term</li> <li>Default: <code>1.0</code></li> <li>Larger rho: Faster convergence but potentially less accurate</li> <li>Smaller rho: More accurate but slower convergence</li> </ul>"},{"location":"user-guide/basic-usage/#tolerances","title":"Tolerances","text":"<p>Absolute tolerance (<code>abs_tol</code>): Default <code>1e-4</code></p> <p>Relative tolerance (<code>rel_tol</code>): Default <code>1e-3</code></p> <p>The solver stops when primal and dual residuals satisfy: $$ |r|2 \\leq \\epsilon \\cdot \\max(|Ax|_2, |y|_2) $$}} + \\epsilon_{\\text{rel}</p>"},{"location":"user-guide/basic-usage/#adaptive-rho","title":"Adaptive Rho","text":"<p>When <code>SetAdaptiveRho(true)</code>, rho is automatically adjusted: - If primal residual &gt;&gt; dual residual: increase rho - If dual residual &gt;&gt; primal residual: decrease rho</p>"},{"location":"user-guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Advanced Features - Warm starting, Anderson acceleration</li> <li>Cone Problems - LP, QP, SOCP, SDP formulations</li> <li>Examples - Complete working examples</li> </ul>"},{"location":"user-guide/c-interface/","title":"C Interface","text":"<p>POGS provides a C interface for maximum compatibility with other languages and systems.</p>"},{"location":"user-guide/c-interface/#overview","title":"Overview","text":"<p>The C interface supports cone form problems, allowing you to solve:</p> <ul> <li>Linear programs (LP)</li> <li>Quadratic programs (QP)</li> <li>Second-order cone programs (SOCP)</li> <li>Semidefinite programs (SDP)</li> </ul>"},{"location":"user-guide/c-interface/#basic-example","title":"Basic Example","text":"<pre><code>#include &lt;pogs/c/pogs_c.h&gt;\n#include &lt;stdio.h&gt;\n\nint main() {\n    // Problem: minimize x[0] subject to x[0] + x[1] = 2, x &gt;= 0\n    double A[] = {1.0, 1.0};  // 1x2 matrix (row-major)\n    double b[] = {2.0};       // RHS\n    double c[] = {1.0, 0.0};  // Objective coefficients\n\n    // Define cones for variables (x)\n    unsigned int x_indices[] = {0, 1};\n    struct ConeConstraintC cone_x = {CONE_NON_NEG, x_indices, 2};\n\n    // Define cones for slack variables (y = Ax - b)\n    unsigned int y_indices[] = {0};\n    struct ConeConstraintC cone_y = {CONE_ZERO, y_indices, 1};\n\n    // Solution arrays\n    double x[2], y[1], optval;\n    unsigned int final_iter;\n\n    // Solve\n    int status = PogsConeD(\n        ROW_MAJ,           // Matrix order\n        1, 2,              // m, n (dimensions)\n        A, b, c,           // Problem data\n        &amp;cone_x, 1,        // x cones and count\n        &amp;cone_y, 1,        // y cones and count\n        1.0,               // rho\n        1e-4, 1e-3,        // abs_tol, rel_tol\n        10000,             // max_iter\n        0,                 // verbose (0=quiet, 1=verbose)\n        1, 1,              // adaptive_rho, gap_stop\n        x, y, NULL,        // Solutions (lambda can be NULL)\n        &amp;optval,           // Optimal value\n        &amp;final_iter        // Final iteration count\n    );\n\n    if (status == 0) {\n        printf(\"Success!\\n\");\n        printf(\"Solution: x = [%.6f, %.6f]\\n\", x[0], x[1]);\n        printf(\"Optimal value: %.6f\\n\", optval);\n        printf(\"Iterations: %u\\n\", final_iter);\n    } else {\n        printf(\"Solver failed with status %d\\n\", status);\n    }\n\n    return 0;\n}\n</code></pre>"},{"location":"user-guide/c-interface/#api-reference","title":"API Reference","text":""},{"location":"user-guide/c-interface/#main-function","title":"Main Function","text":"<pre><code>int PogsConeD(\n    enum ORD ord,\n    size_t m, size_t n,\n    const double *A,\n    const double *b,\n    const double *c,\n    const struct ConeConstraintC *cones_x,\n    size_t num_cones_x,\n    const struct ConeConstraintC *cones_y,\n    size_t num_cones_y,\n    double rho,\n    double abs_tol,\n    double rel_tol,\n    unsigned int max_iter,\n    unsigned int verbose,\n    int adaptive_rho,\n    int gap_stop,\n    double *x,\n    double *y,\n    double *l,\n    double *optval,\n    unsigned int *final_iter\n);\n</code></pre> <p>Parameters:</p> <ul> <li><code>ord</code>: Matrix order (<code>ROW_MAJ</code> or <code>COL_MAJ</code>)</li> <li><code>m</code>, <code>n</code>: Problem dimensions</li> <li><code>A</code>: Constraint matrix (size m\u00d7n)</li> <li><code>b</code>: RHS vector (size m)</li> <li><code>c</code>: Objective vector (size n)</li> <li><code>cones_x</code>: Array of cone constraints for x</li> <li><code>num_cones_x</code>: Number of x cone constraints</li> <li><code>cones_y</code>: Array of cone constraints for y</li> <li><code>num_cones_y</code>: Number of y cone constraints</li> <li><code>rho</code>: Penalty parameter (try 1.0)</li> <li><code>abs_tol</code>: Absolute tolerance (try 1e-4)</li> <li><code>rel_tol</code>: Relative tolerance (try 1e-3)</li> <li><code>max_iter</code>: Maximum iterations (try 10000)</li> <li><code>verbose</code>: Verbosity level (0=quiet, 1=verbose)</li> <li><code>adaptive_rho</code>: Enable adaptive \u03c1 (1=yes, 0=no)</li> <li><code>gap_stop</code>: Enable duality gap stopping (1=yes, 0=no)</li> <li><code>x</code>: [Output] Primal solution (size n)</li> <li><code>y</code>: [Output] Slack variables (size m)</li> <li><code>l</code>: [Output] Dual variables (size m, can be NULL)</li> <li><code>optval</code>: [Output] Optimal objective value</li> <li><code>final_iter</code>: [Output] Final iteration count</li> </ul> <p>Returns: 0 on success, non-zero on failure</p>"},{"location":"user-guide/c-interface/#cone-types","title":"Cone Types","text":""},{"location":"user-guide/c-interface/#available-cones","title":"Available Cones","text":"<pre><code>enum Cone {\n    CONE_ZERO,        // {x : x = 0} - Equality constraints\n    CONE_NON_NEG,     // {x : x &gt;= 0} - Non-negativity\n    CONE_NON_POS,     // {x : x &lt;= 0} - Non-positivity\n    CONE_SOC,         // {(t,x) : ||x||_2 &lt;= t} - Second-order cone\n    CONE_SDP,         // {X : X \u2ab0 0} - Semidefinite cone\n    CONE_EXP_PRIMAL,  // Exponential cone\n    CONE_EXP_DUAL     // Dual exponential cone\n};\n</code></pre>"},{"location":"user-guide/c-interface/#cone-constraint-structure","title":"Cone Constraint Structure","text":"<pre><code>struct ConeConstraintC {\n    enum Cone cone;           // Cone type\n    unsigned int *indices;    // Indices of variables in this cone\n    size_t size;              // Number of variables\n};\n</code></pre>"},{"location":"user-guide/c-interface/#matrix-ordering","title":"Matrix Ordering","text":""},{"location":"user-guide/c-interface/#row-major-c-style","title":"Row-Major (C-style)","text":"<pre><code>// A = [1 2 3]\n//     [4 5 6]\ndouble A[] = {1, 2, 3, 4, 5, 6};  // Row-major\nenum ORD ord = ROW_MAJ;\n</code></pre> <p>Element <code>A[i,j]</code> is at index <code>i*n + j</code>.</p>"},{"location":"user-guide/c-interface/#column-major-fortran-style","title":"Column-Major (Fortran-style)","text":"<pre><code>// A = [1 2 3]\n//     [4 5 6]\ndouble A[] = {1, 4, 2, 5, 3, 6};  // Column-major\nenum ORD ord = COL_MAJ;\n</code></pre> <p>Element <code>A[i,j]</code> is at index <code>j*m + i</code>.</p>"},{"location":"user-guide/c-interface/#examples","title":"Examples","text":""},{"location":"user-guide/c-interface/#linear-program","title":"Linear Program","text":"<p>Solve: $$ \\begin{align} \\text{minimize} \\quad &amp; x_1 + 2x_2 \\ \\text{subject to} \\quad &amp; x_1 + x_2 = 3 \\ &amp; x \\geq 0 \\end{align} $$</p> <pre><code>double A[] = {1.0, 1.0};\ndouble b[] = {3.0};\ndouble c[] = {1.0, 2.0};\n\nunsigned int x_idx[] = {0, 1};\nstruct ConeConstraintC cx = {CONE_NON_NEG, x_idx, 2};\n\nunsigned int y_idx[] = {0};\nstruct ConeConstraintC cy = {CONE_ZERO, y_idx, 1};\n\ndouble x[2], y[1], opt;\nunsigned int iter;\n\nint status = PogsConeD(ROW_MAJ, 1, 2, A, b, c,\n                       &amp;cx, 1, &amp;cy, 1,\n                       1.0, 1e-4, 1e-3, 10000, 0, 1, 1,\n                       x, y, NULL, &amp;opt, &amp;iter);\n</code></pre>"},{"location":"user-guide/c-interface/#quadratic-program","title":"Quadratic Program","text":"<p>For quadratic objectives, reformulate using auxiliary variables.</p>"},{"location":"user-guide/c-interface/#compiling","title":"Compiling","text":""},{"location":"user-guide/c-interface/#gccclang-macos","title":"GCC/Clang (macOS)","text":"<pre><code>gcc -o myprogram myprogram.c \\\n    -I/usr/local/include \\\n    -L/usr/local/lib \\\n    -lpogs_cpu \\\n    -framework Accelerate \\\n    -lm\n</code></pre>"},{"location":"user-guide/c-interface/#gcc-linux","title":"GCC (Linux)","text":"<pre><code>gcc -o myprogram myprogram.c \\\n    -I/usr/local/include \\\n    -L/usr/local/lib \\\n    -lpogs_cpu \\\n    -lopenblas \\\n    -llapack \\\n    -lm\n</code></pre>"},{"location":"user-guide/c-interface/#cmake-integration","title":"CMake Integration","text":"<pre><code>find_package(POGS REQUIRED)\n\nadd_executable(myprogram myprogram.c)\ntarget_link_libraries(myprogram PRIVATE pogs::cpu)\n</code></pre>"},{"location":"user-guide/c-interface/#error-handling","title":"Error Handling","text":"<pre><code>int status = PogsConeD(...);\n\nif (status == 0) {\n    printf(\"Success: converged\\n\");\n} else if (status == 1) {\n    printf(\"Warning: maximum iterations reached\\n\");\n} else if (status == 2) {\n    printf(\"Error: numerical error\\n\");\n} else {\n    printf(\"Error: unknown status %d\\n\", status);\n}\n</code></pre>"},{"location":"user-guide/c-interface/#float-precision","title":"Float Precision","text":"<p>Single precision version:</p> <pre><code>int PogsConeF(\n    enum ORD ord,\n    size_t m, size_t n,\n    const float *A,\n    const float *b,\n    const float *c,\n    // ... same parameters but with float ...\n);\n</code></pre> <p>Use <code>PogsConeF</code> for faster but less accurate solutions.</p>"},{"location":"user-guide/c-interface/#see-also","title":"See Also","text":"<ul> <li>Cone Problems - Cone formulation details</li> <li>API Reference - Complete C API documentation</li> <li>Examples: <code>examples/cpp_cone/test_c_interface.c</code></li> </ul>"},{"location":"user-guide/cone-problems/","title":"Cone Form Problems","text":"<p>POGS supports cone form problems, which provide a unified framework for expressing linear programs, quadratic programs, second-order cone programs, and semidefinite programs.</p>"},{"location":"user-guide/cone-problems/#standard-cone-form","title":"Standard Cone Form","text":"<p>A cone form problem has the structure:</p> \\[ \\begin{align} \\text{minimize} \\quad &amp; c^T x \\\\ \\text{subject to} \\quad &amp; Ax + s = b \\\\ &amp; s \\in \\mathcal{K} \\end{align} \\] <p>where \\(\\mathcal{K}\\) is a product of convex cones (zero, non-negative, SOC, SDP, exponential).</p>"},{"location":"user-guide/cone-problems/#supported-cone-types","title":"Supported Cone Types","text":""},{"location":"user-guide/cone-problems/#zero-cone","title":"Zero Cone","text":"\\[ \\mathcal{K}_\\text{zero} = \\{x : x = 0\\} \\] <p>Used for equality constraints.</p> <p>Example: \\(Ax = b\\) becomes \\(Ax - b \\in \\mathcal{K}_\\text{zero}\\)</p>"},{"location":"user-guide/cone-problems/#non-negative-cone","title":"Non-Negative Cone","text":"\\[ \\mathcal{K}_+ = \\{x : x \\geq 0\\} \\] <p>Used for inequality constraints.</p> <p>Example: \\(x \\geq 0\\) becomes \\(x \\in \\mathcal{K}_+\\)</p>"},{"location":"user-guide/cone-problems/#non-positive-cone","title":"Non-Positive Cone","text":"\\[ \\mathcal{K}_- = \\{x : x \\leq 0\\} \\] <p>Used for upper bound constraints.</p>"},{"location":"user-guide/cone-problems/#second-order-cone-soc","title":"Second-Order Cone (SOC)","text":"\\[ \\mathcal{K}_\\text{SOC} = \\{(t, x) : \\|x\\|_2 \\leq t\\} \\] <p>Used for quadratic constraints.</p> <p>Example: \\(\\|x\\|_2 \\leq t\\) becomes \\((t, x) \\in \\mathcal{K}_\\text{SOC}\\)</p>"},{"location":"user-guide/cone-problems/#semidefinite-cone-sdp","title":"Semidefinite Cone (SDP)","text":"\\[ \\mathcal{K}_\\text{SDP} = \\{X : X \\succeq 0\\} \\] <p>where \\(X \\succeq 0\\) means \\(X\\) is positive semidefinite.</p> <p>Used for matrix constraints.</p> <p>Example: Matrix \\(X\\) must be PSD becomes \\(X \\in \\mathcal{K}_\\text{SDP}\\)</p>"},{"location":"user-guide/cone-problems/#exponential-cone","title":"Exponential Cone","text":"\\[ \\mathcal{K}_\\text{exp} = \\{(x, y, z) : y &gt; 0, ye^{x/y} \\leq z\\} \\cup \\{(x, y, z) : x \\leq 0, y = 0, z \\geq 0\\} \\] <p>Used for exponential and logarithmic constraints.</p> <p>The dual exponential cone is also supported: $$ \\mathcal{K}_\\text{exp}^* = {(u, v, w) : u &lt; 0, -ue^{v/u} \\leq ew} \\cup {(u, v, w) : u = 0, v \\geq 0, w \\geq 0} $$</p>"},{"location":"user-guide/cone-problems/#c-interface","title":"C Interface","text":""},{"location":"user-guide/cone-problems/#basic-usage","title":"Basic Usage","text":"<pre><code>#include &lt;pogs/c/pogs_c.h&gt;\n\n// Problem data\ndouble A[] = {1.0, 1.0};  // 1x2 matrix\ndouble b[] = {2.0};       // m=1\ndouble c[] = {1.0, 0.0};  // n=2\n\n// Define cones for variables (x)\nunsigned int x_indices[] = {0, 1};\nstruct ConeConstraintC cone_x = {CONE_NON_NEG, x_indices, 2};\n\n// Define cones for slack variables (y = Ax - b)\nunsigned int y_indices[] = {0};\nstruct ConeConstraintC cone_y = {CONE_ZERO, y_indices, 1};\n\n// Solution arrays\ndouble x[2], y[1], optval;\nunsigned int final_iter;\n\n// Solve\nint status = PogsConeD(\n    ROW_MAJ,           // Matrix order\n    1, 2,              // m, n (dimensions)\n    A, b, c,           // Problem data\n    &amp;cone_x, 1,        // x cones\n    &amp;cone_y, 1,        // y cones\n    1.0,               // rho\n    1e-4, 1e-3,        // abs_tol, rel_tol\n    10000,             // max_iter\n    0,                 // verbose\n    1, 1,              // adaptive_rho, gap_stop\n    x, y, NULL,        // Solutions\n    &amp;optval,           // Optimal value\n    &amp;final_iter        // Iterations\n);\n\nprintf(\"Status: %d\\n\", status);\nprintf(\"Solution: x = [%.6f, %.6f]\\n\", x[0], x[1]);\nprintf(\"Optimal value: %.6f\\n\", optval);\n</code></pre>"},{"location":"user-guide/cone-problems/#cone-types-in-c","title":"Cone Types in C","text":"<pre><code>enum Cone {\n    CONE_ZERO,        // {x : x = 0}\n    CONE_NON_NEG,     // {x : x &gt;= 0}\n    CONE_NON_POS,     // {x : x &lt;= 0}\n    CONE_SOC,         // {(p,x) : ||x||\u2082 \u2264 p}\n    CONE_SDP,         // {X : X \u2ab0 0}\n    CONE_EXP_PRIMAL,  // Exponential cone\n    CONE_EXP_DUAL     // Dual exponential cone\n};\n</code></pre>"},{"location":"user-guide/cone-problems/#examples","title":"Examples","text":""},{"location":"user-guide/cone-problems/#linear-program","title":"Linear Program","text":"<p>Solve: $$ \\begin{align} \\text{minimize} \\quad &amp; x_1 \\ \\text{subject to} \\quad &amp; x_1 + x_2 = 2 \\ &amp; x \\geq 0 \\end{align} $$</p> <p>Solution: \\(x = [0, 2]^T\\), optimal value = 0</p> <p>See <code>examples/cpp_cone/test_c_interface.c</code> for complete code.</p>"},{"location":"user-guide/cone-problems/#quadratic-program","title":"Quadratic Program","text":"<p>Solve: $$ \\text{minimize} \\quad \\frac{1}{2}|Ax - b|_2^2 + \\lambda|x|_1 $$</p> <p>This can be reformulated in cone form using auxiliary variables.</p>"},{"location":"user-guide/cone-problems/#sdp-problem","title":"SDP Problem","text":"<p>Solve: $$ \\begin{align} \\text{minimize} \\quad &amp; \\text{trace}(CX) \\ \\text{subject to} \\quad &amp; \\text{trace}(A_i X) = b_i, \\quad i=1,\\ldots,m \\ &amp; X \\succeq 0 \\end{align} $$</p> <p>See <code>examples/cpp_cone/test_sdp.cpp</code> for implementation.</p>"},{"location":"user-guide/cone-problems/#implementation-details","title":"Implementation Details","text":""},{"location":"user-guide/cone-problems/#sdp-cone-projection","title":"SDP Cone Projection","text":"<p>POGS implements SDP cone projection using eigenvalue decomposition:</p> <ol> <li>Compute eigenvalue decomposition: \\(X = V\\Lambda V^T\\)</li> <li>Project eigenvalues onto non-negative orthant: \\(\\Lambda_+ = \\max(\\Lambda, 0)\\)</li> <li>Reconstruct: \\(X_+ = V\\Lambda_+ V^T\\)</li> </ol> <p>This uses LAPACK routines (<code>dsyevd</code> for double precision) for numerical stability.</p>"},{"location":"user-guide/cone-problems/#sparse-matrix-support","title":"Sparse Matrix Support","text":"<p>The cone interface supports both dense and sparse matrices. For sparse problems, use the sparse matrix format for better performance.</p>"},{"location":"user-guide/cone-problems/#performance-notes","title":"Performance Notes","text":"<ul> <li>Dense problems: POGS uses optimized BLAS/LAPACK routines</li> <li>Sparse problems: CSR/CSC formats supported</li> <li>SDP cones: CPU-only (GPU support planned)</li> <li>Typical convergence: 100-1000 iterations</li> </ul>"},{"location":"user-guide/cone-problems/#see-also","title":"See Also","text":"<ul> <li>C API Reference - Complete C interface documentation</li> <li>CVXPY Integration - Using POGS with CVXPY</li> <li>Examples - SDP problem examples</li> </ul>"},{"location":"user-guide/cvxpy-integration/","title":"CVXPY Integration","text":"<p>POGS can solve CVXPY problems directly using <code>pogs_solve()</code>. It auto-detects supported problem patterns and uses the fast graph-form solver.</p>"},{"location":"user-guide/cvxpy-integration/#basic-usage","title":"Basic Usage","text":"<pre><code>import cvxpy as cp\nimport numpy as np\nfrom pogs import pogs_solve\n\n# Problem data\nA = np.random.randn(100, 50)\nb = np.random.randn(100)\n\n# Define CVXPY problem\nx = cp.Variable(50)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)))\n\n# Solve with POGS\npogs_solve(prob)\n\nprint(f\"Status: {prob.status}\")\nprint(f\"Optimal value: {prob.value}\")\nprint(f\"Solution: {x.value}\")\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#how-it-works","title":"How It Works","text":"<p><code>pogs_solve()</code> inspects the CVXPY problem structure and detects if it matches a supported pattern:</p> Pattern CVXPY Expression POGS Solver Lasso <code>sum_squares(A @ x - b) + \u03bb * norm(x, 1)</code> <code>solve_lasso</code> Ridge <code>sum_squares(A @ x - b) + \u03bb * sum_squares(x)</code> <code>solve_ridge</code> NNLS <code>sum_squares(A @ x - b)</code> with <code>x &gt;= 0</code> <code>solve_nonneg_ls</code> <p>If a pattern is detected, POGS uses its fast graph-form solver. Otherwise, it falls back to CVXPY's default solver.</p>"},{"location":"user-guide/cvxpy-integration/#registering-as-a-solve-method","title":"Registering as a Solve Method","text":"<p>You can register <code>pogs_solve</code> as a named method:</p> <pre><code>import cvxpy as cp\nfrom pogs import pogs_solve\n\n# Register once\ncp.Problem.register_solve(\"POGS\", pogs_solve)\n\n# Now use like any other solver\nprob.solve(method=\"POGS\")\n</code></pre> <p>This lets you use the familiar <code>solve(method=...)</code> syntax.</p>"},{"location":"user-guide/cvxpy-integration/#examples","title":"Examples","text":""},{"location":"user-guide/cvxpy-integration/#lasso","title":"Lasso","text":"<pre><code>import cvxpy as cp\nimport numpy as np\nfrom pogs import pogs_solve\n\nm, n = 500, 300\nA = np.random.randn(m, n)\nb = np.random.randn(m)\n\nx = cp.Variable(n)\nlambd = 0.1\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + lambd * cp.norm(x, 1)))\n\npogs_solve(prob, verbose=True)\n# Output: POGS: Detected lasso pattern, using fast graph-form solver\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#ridge","title":"Ridge","text":"<pre><code>x = cp.Variable(n)\nlambd = 0.1\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + lambd * cp.sum_squares(x)))\n\npogs_solve(prob, verbose=True)\n# Output: POGS: Detected ridge pattern, using fast graph-form solver\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#non-negative-least-squares","title":"Non-negative Least Squares","text":"<pre><code>x = cp.Variable(n)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b)), [x &gt;= 0])\n\npogs_solve(prob, verbose=True)\n# Output: POGS: Detected nonneg_ls pattern, using fast graph-form solver\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#unsupported-problems","title":"Unsupported Problems","text":"<p>For problems that don't match a supported pattern:</p> <pre><code>x = cp.Variable(n)\nprob = cp.Problem(cp.Minimize(cp.norm(A @ x - b, 1)))  # L1 loss, not L2\n\npogs_solve(prob, verbose=True)\n# Output: POGS: No graph-form pattern detected, using default solver\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#solver-options","title":"Solver Options","text":"<p>Pass solver options to <code>pogs_solve()</code>:</p> <pre><code>pogs_solve(\n    prob,\n    verbose=True,      # Print solver output\n    abs_tol=1e-6,      # Absolute tolerance\n    rel_tol=1e-6,      # Relative tolerance\n    max_iter=5000,     # Maximum iterations\n    rho=1.0,           # ADMM penalty parameter\n)\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#when-to-use-pogs-vs-direct-solvers","title":"When to Use POGS vs Direct Solvers","text":""},{"location":"user-guide/cvxpy-integration/#use-pogs_solve-when","title":"Use <code>pogs_solve()</code> when:","text":"<ul> <li>You have existing CVXPY code</li> <li>You want automatic pattern detection</li> <li>You're not sure which solver function to use</li> </ul>"},{"location":"user-guide/cvxpy-integration/#use-direct-solvers-solve_lasso-etc-when","title":"Use direct solvers (<code>solve_lasso</code>, etc.) when:","text":"<ul> <li>You know the exact problem type</li> <li>You want maximum performance</li> <li>You're writing new code</li> </ul> <p>Direct solvers are slightly faster because they skip pattern detection:</p> <pre><code># Direct (faster)\nfrom pogs import solve_lasso\nresult = solve_lasso(A, b, lambd=0.1)\nx = result['x']\n\n# Via CVXPY (convenient)\nfrom pogs import pogs_solve\nx = cp.Variable(n)\nprob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b) + 0.1 * cp.norm(x, 1)))\npogs_solve(prob)\nx_val = x.value\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#supported-patterns","title":"Supported Patterns","text":"<p>POGS detects these specific CVXPY expression patterns:</p>"},{"location":"user-guide/cvxpy-integration/#lasso_1","title":"Lasso","text":"<pre><code># minimize \u00bd||Ax - b||\u00b2 + \u03bb||x||\u2081\ncp.Minimize(cp.sum_squares(A @ x - b) + lambd * cp.norm(x, 1))\ncp.Minimize(0.5 * cp.sum_squares(A @ x - b) + lambd * cp.norm1(x))\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#ridge_1","title":"Ridge","text":"<pre><code># minimize \u00bd||Ax - b||\u00b2 + \u03bb||x||\u00b2\ncp.Minimize(cp.sum_squares(A @ x - b) + lambd * cp.sum_squares(x))\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#non-negative-least-squares_1","title":"Non-negative Least Squares","text":"<pre><code># minimize \u00bd||Ax - b||\u00b2 s.t. x &gt;= 0\ncp.Minimize(cp.sum_squares(A @ x - b)), constraints=[x &gt;= 0]\n</code></pre>"},{"location":"user-guide/cvxpy-integration/#limitations","title":"Limitations","text":"<ul> <li>Single variable: Only problems with one optimization variable are supported</li> <li>Minimization: Must be a minimization problem</li> <li>Specific patterns: Only Lasso, Ridge, and NNLS patterns are detected</li> <li>Dense matrices: Works best with dense matrices A</li> </ul> <p>For problems outside these patterns, POGS falls back to CVXPY's default solver, which may be slower but handles general convex problems.</p>"}]}